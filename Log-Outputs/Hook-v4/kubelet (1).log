Running as unit: kubelet-20241009T094422.service; invocation ID: 75f70b65a31543b8983405a1c1abbe75
Flag --container-runtime-endpoint has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Flag --cluster-domain has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
I1009 09:44:22.833050  106124 flags.go:64] FLAG: --address="0.0.0.0"
I1009 09:44:22.833090  106124 flags.go:64] FLAG: --allowed-unsafe-sysctls="[]"
I1009 09:44:22.833103  106124 flags.go:64] FLAG: --anonymous-auth="true"
I1009 09:44:22.833110  106124 flags.go:64] FLAG: --application-metrics-count-limit="100"
I1009 09:44:22.833117  106124 flags.go:64] FLAG: --authentication-token-webhook="false"
I1009 09:44:22.833122  106124 flags.go:64] FLAG: --authentication-token-webhook-cache-ttl="2m0s"
I1009 09:44:22.833128  106124 flags.go:64] FLAG: --authorization-mode="AlwaysAllow"
I1009 09:44:22.833135  106124 flags.go:64] FLAG: --authorization-webhook-cache-authorized-ttl="5m0s"
I1009 09:44:22.833141  106124 flags.go:64] FLAG: --authorization-webhook-cache-unauthorized-ttl="30s"
I1009 09:44:22.833146  106124 flags.go:64] FLAG: --boot-id-file="/proc/sys/kernel/random/boot_id"
I1009 09:44:22.833152  106124 flags.go:64] FLAG: --bootstrap-kubeconfig=""
I1009 09:44:22.833156  106124 flags.go:64] FLAG: --cert-dir="/var/lib/kubelet/pki"
I1009 09:44:22.833162  106124 flags.go:64] FLAG: --cgroup-driver="cgroupfs"
I1009 09:44:22.833166  106124 flags.go:64] FLAG: --cgroup-root=""
I1009 09:44:22.833172  106124 flags.go:64] FLAG: --cgroups-per-qos="true"
I1009 09:44:22.833176  106124 flags.go:64] FLAG: --client-ca-file=""
I1009 09:44:22.833188  106124 flags.go:64] FLAG: --cloud-config=""
I1009 09:44:22.833192  106124 flags.go:64] FLAG: --cloud-provider=""
I1009 09:44:22.833196  106124 flags.go:64] FLAG: --cluster-dns="[]"
I1009 09:44:22.833201  106124 flags.go:64] FLAG: --cluster-domain="cluster.local"
I1009 09:44:22.833204  106124 flags.go:64] FLAG: --config="/home/ubuntu/kubernetes/_output/local/go/bin/kubelet-config"
I1009 09:44:22.833209  106124 flags.go:64] FLAG: --config-dir="/home/ubuntu/kubernetes/_output/local/go/bin/kubelet.conf.d"
I1009 09:44:22.833217  106124 flags.go:64] FLAG: --container-hints="/etc/cadvisor/container_hints.json"
I1009 09:44:22.833227  106124 flags.go:64] FLAG: --container-log-max-files="5"
I1009 09:44:22.833234  106124 flags.go:64] FLAG: --container-log-max-size="10Mi"
I1009 09:44:22.833239  106124 flags.go:64] FLAG: --container-runtime-endpoint="unix:///run/containerd/containerd.sock"
I1009 09:44:22.833245  106124 flags.go:64] FLAG: --containerd="/run/containerd/containerd.sock"
I1009 09:44:22.833251  106124 flags.go:64] FLAG: --containerd-namespace="k8s.io"
I1009 09:44:22.833257  106124 flags.go:64] FLAG: --contention-profiling="false"
I1009 09:44:22.833262  106124 flags.go:64] FLAG: --cpu-cfs-quota="true"
I1009 09:44:22.833267  106124 flags.go:64] FLAG: --cpu-cfs-quota-period="100ms"
I1009 09:44:22.833271  106124 flags.go:64] FLAG: --cpu-manager-policy="none"
I1009 09:44:22.833275  106124 flags.go:64] FLAG: --cpu-manager-policy-options=""
I1009 09:44:22.833288  106124 flags.go:64] FLAG: --cpu-manager-reconcile-period="10s"
I1009 09:44:22.833292  106124 flags.go:64] FLAG: --enable-controller-attach-detach="true"
I1009 09:44:22.833296  106124 flags.go:64] FLAG: --enable-debugging-handlers="true"
I1009 09:44:22.833300  106124 flags.go:64] FLAG: --enable-load-reader="false"
I1009 09:44:22.833304  106124 flags.go:64] FLAG: --enable-server="true"
I1009 09:44:22.833308  106124 flags.go:64] FLAG: --enforce-node-allocatable="[pods]"
I1009 09:44:22.833314  106124 flags.go:64] FLAG: --event-burst="100"
I1009 09:44:22.833319  106124 flags.go:64] FLAG: --event-qps="50"
I1009 09:44:22.833326  106124 flags.go:64] FLAG: --event-storage-age-limit="default=0"
I1009 09:44:22.833336  106124 flags.go:64] FLAG: --event-storage-event-limit="default=0"
I1009 09:44:22.833359  106124 flags.go:64] FLAG: --eviction-hard=""
I1009 09:44:22.833373  106124 flags.go:64] FLAG: --eviction-max-pod-grace-period="0"
I1009 09:44:22.833380  106124 flags.go:64] FLAG: --eviction-minimum-reclaim=""
I1009 09:44:22.833384  106124 flags.go:64] FLAG: --eviction-pressure-transition-period="5m0s"
I1009 09:44:22.833388  106124 flags.go:64] FLAG: --eviction-soft=""
I1009 09:44:22.833391  106124 flags.go:64] FLAG: --eviction-soft-grace-period=""
I1009 09:44:22.833394  106124 flags.go:64] FLAG: --exit-on-lock-contention="false"
I1009 09:44:22.833398  106124 flags.go:64] FLAG: --experimental-allocatable-ignore-eviction="false"
I1009 09:44:22.833401  106124 flags.go:64] FLAG: --experimental-mounter-path=""
I1009 09:44:22.833404  106124 flags.go:64] FLAG: --fail-cgroupv1="false"
I1009 09:44:22.833407  106124 flags.go:64] FLAG: --fail-swap-on="true"
I1009 09:44:22.833411  106124 flags.go:64] FLAG: --feature-gates=""
I1009 09:44:22.833415  106124 flags.go:64] FLAG: --file-check-frequency="20s"
I1009 09:44:22.833419  106124 flags.go:64] FLAG: --global-housekeeping-interval="1m0s"
I1009 09:44:22.833431  106124 flags.go:64] FLAG: --hairpin-mode="promiscuous-bridge"
I1009 09:44:22.833435  106124 flags.go:64] FLAG: --healthz-bind-address="127.0.0.1"
I1009 09:44:22.833438  106124 flags.go:64] FLAG: --healthz-port="10248"
I1009 09:44:22.833443  106124 flags.go:64] FLAG: --help="false"
I1009 09:44:22.833447  106124 flags.go:64] FLAG: --hostname-override="srv579909"
I1009 09:44:22.833465  106124 flags.go:64] FLAG: --housekeeping-interval="10s"
I1009 09:44:22.833471  106124 flags.go:64] FLAG: --http-check-frequency="20s"
I1009 09:44:22.833474  106124 flags.go:64] FLAG: --image-credential-provider-bin-dir=""
I1009 09:44:22.833476  106124 flags.go:64] FLAG: --image-credential-provider-config=""
I1009 09:44:22.833479  106124 flags.go:64] FLAG: --image-gc-high-threshold="85"
I1009 09:44:22.833481  106124 flags.go:64] FLAG: --image-gc-low-threshold="80"
I1009 09:44:22.833484  106124 flags.go:64] FLAG: --image-service-endpoint=""
I1009 09:44:22.833486  106124 flags.go:64] FLAG: --kernel-memcg-notification="false"
I1009 09:44:22.833489  106124 flags.go:64] FLAG: --kube-api-burst="100"
I1009 09:44:22.833492  106124 flags.go:64] FLAG: --kube-api-content-type="application/vnd.kubernetes.protobuf"
I1009 09:44:22.833495  106124 flags.go:64] FLAG: --kube-api-qps="50"
I1009 09:44:22.833497  106124 flags.go:64] FLAG: --kube-reserved=""
I1009 09:44:22.833500  106124 flags.go:64] FLAG: --kube-reserved-cgroup=""
I1009 09:44:22.833502  106124 flags.go:64] FLAG: --kubeconfig="/home/ubuntu/kubernetes/_output/local/go/bin/kubeconfig"
I1009 09:44:22.833505  106124 flags.go:64] FLAG: --kubelet-cgroups=""
I1009 09:44:22.833507  106124 flags.go:64] FLAG: --local-storage-capacity-isolation="true"
I1009 09:44:22.833510  106124 flags.go:64] FLAG: --lock-file=""
I1009 09:44:22.833512  106124 flags.go:64] FLAG: --log-cadvisor-usage="false"
I1009 09:44:22.833515  106124 flags.go:64] FLAG: --log-flush-frequency="5s"
I1009 09:44:22.833518  106124 flags.go:64] FLAG: --log-json-info-buffer-size="0"
I1009 09:44:22.833522  106124 flags.go:64] FLAG: --log-json-split-stream="false"
I1009 09:44:22.833524  106124 flags.go:64] FLAG: --log-text-info-buffer-size="0"
I1009 09:44:22.833527  106124 flags.go:64] FLAG: --log-text-split-stream="false"
I1009 09:44:22.833529  106124 flags.go:64] FLAG: --logging-format="text"
I1009 09:44:22.833533  106124 flags.go:64] FLAG: --machine-id-file="/etc/machine-id,/var/lib/dbus/machine-id"
I1009 09:44:22.833536  106124 flags.go:64] FLAG: --make-iptables-util-chains="true"
I1009 09:44:22.833538  106124 flags.go:64] FLAG: --manifest-url=""
I1009 09:44:22.833540  106124 flags.go:64] FLAG: --manifest-url-header=""
I1009 09:44:22.833544  106124 flags.go:64] FLAG: --max-open-files="1000000"
I1009 09:44:22.833547  106124 flags.go:64] FLAG: --max-pods="110"
I1009 09:44:22.833550  106124 flags.go:64] FLAG: --maximum-dead-containers="-1"
I1009 09:44:22.833553  106124 flags.go:64] FLAG: --maximum-dead-containers-per-container="1"
I1009 09:44:22.833561  106124 flags.go:64] FLAG: --memory-manager-policy="None"
I1009 09:44:22.833564  106124 flags.go:64] FLAG: --minimum-container-ttl-duration="0s"
I1009 09:44:22.833566  106124 flags.go:64] FLAG: --minimum-image-ttl-duration="2m0s"
I1009 09:44:22.833569  106124 flags.go:64] FLAG: --node-ip=""
I1009 09:44:22.833571  106124 flags.go:64] FLAG: --node-labels=""
I1009 09:44:22.833575  106124 flags.go:64] FLAG: --node-status-max-images="50"
I1009 09:44:22.833577  106124 flags.go:64] FLAG: --node-status-update-frequency="10s"
I1009 09:44:22.833580  106124 flags.go:64] FLAG: --oom-score-adj="-999"
I1009 09:44:22.833583  106124 flags.go:64] FLAG: --pod-cidr=""
I1009 09:44:22.833585  106124 flags.go:64] FLAG: --pod-infra-container-image="registry.k8s.io/pause:3.10"
I1009 09:44:22.833588  106124 flags.go:64] FLAG: --pod-manifest-path=""
I1009 09:44:22.833590  106124 flags.go:64] FLAG: --pod-max-pids="-1"
I1009 09:44:22.833593  106124 flags.go:64] FLAG: --pods-per-core="0"
I1009 09:44:22.833595  106124 flags.go:64] FLAG: --port="10250"
I1009 09:44:22.833598  106124 flags.go:64] FLAG: --protect-kernel-defaults="false"
I1009 09:44:22.833600  106124 flags.go:64] FLAG: --provider-id=""
I1009 09:44:22.833603  106124 flags.go:64] FLAG: --qos-reserved=""
I1009 09:44:22.833605  106124 flags.go:64] FLAG: --read-only-port="10255"
I1009 09:44:22.833608  106124 flags.go:64] FLAG: --register-node="true"
I1009 09:44:22.833610  106124 flags.go:64] FLAG: --register-schedulable="true"
I1009 09:44:22.833612  106124 flags.go:64] FLAG: --register-with-taints=""
I1009 09:44:22.833616  106124 flags.go:64] FLAG: --registry-burst="10"
I1009 09:44:22.833618  106124 flags.go:64] FLAG: --registry-qps="5"
I1009 09:44:22.833621  106124 flags.go:64] FLAG: --reserved-cpus=""
I1009 09:44:22.833623  106124 flags.go:64] FLAG: --reserved-memory=""
I1009 09:44:22.833634  106124 flags.go:64] FLAG: --resolv-conf="/etc/resolv.conf"
I1009 09:44:22.833636  106124 flags.go:64] FLAG: --root-dir="/var/lib/kubelet"
I1009 09:44:22.833639  106124 flags.go:64] FLAG: --rotate-certificates="false"
I1009 09:44:22.833641  106124 flags.go:64] FLAG: --rotate-server-certificates="false"
I1009 09:44:22.833644  106124 flags.go:64] FLAG: --runonce="false"
I1009 09:44:22.833646  106124 flags.go:64] FLAG: --runtime-cgroups=""
I1009 09:44:22.833649  106124 flags.go:64] FLAG: --runtime-request-timeout="2m0s"
I1009 09:44:22.833651  106124 flags.go:64] FLAG: --seccomp-default="false"
I1009 09:44:22.833654  106124 flags.go:64] FLAG: --serialize-image-pulls="true"
I1009 09:44:22.833657  106124 flags.go:64] FLAG: --storage-driver-buffer-duration="1m0s"
I1009 09:44:22.833659  106124 flags.go:64] FLAG: --storage-driver-db="cadvisor"
I1009 09:44:22.833662  106124 flags.go:64] FLAG: --storage-driver-host="localhost:8086"
I1009 09:44:22.833665  106124 flags.go:64] FLAG: --storage-driver-password="root"
I1009 09:44:22.833667  106124 flags.go:64] FLAG: --storage-driver-secure="false"
I1009 09:44:22.833670  106124 flags.go:64] FLAG: --storage-driver-table="stats"
I1009 09:44:22.833674  106124 flags.go:64] FLAG: --storage-driver-user="root"
I1009 09:44:22.833681  106124 flags.go:64] FLAG: --streaming-connection-idle-timeout="4h0m0s"
I1009 09:44:22.833687  106124 flags.go:64] FLAG: --sync-frequency="1m0s"
I1009 09:44:22.833692  106124 flags.go:64] FLAG: --system-cgroups=""
I1009 09:44:22.833695  106124 flags.go:64] FLAG: --system-reserved=""
I1009 09:44:22.833699  106124 flags.go:64] FLAG: --system-reserved-cgroup=""
I1009 09:44:22.833702  106124 flags.go:64] FLAG: --tls-cert-file=""
I1009 09:44:22.833706  106124 flags.go:64] FLAG: --tls-cipher-suites="[]"
I1009 09:44:22.833711  106124 flags.go:64] FLAG: --tls-min-version=""
I1009 09:44:22.833715  106124 flags.go:64] FLAG: --tls-private-key-file=""
I1009 09:44:22.833717  106124 flags.go:64] FLAG: --topology-manager-policy="none"
I1009 09:44:22.833720  106124 flags.go:64] FLAG: --topology-manager-policy-options=""
I1009 09:44:22.833722  106124 flags.go:64] FLAG: --topology-manager-scope="container"
I1009 09:44:22.833730  106124 flags.go:64] FLAG: --v="4"
I1009 09:44:22.833734  106124 flags.go:64] FLAG: --version="false"
I1009 09:44:22.833738  106124 flags.go:64] FLAG: --vmodule=""
I1009 09:44:22.833742  106124 flags.go:64] FLAG: --volume-plugin-dir="/usr/libexec/kubernetes/kubelet-plugins/volume/exec/"
I1009 09:44:22.833744  106124 flags.go:64] FLAG: --volume-stats-agg-period="1m0s"
I1009 09:44:22.833810  106124 feature_gate.go:387] feature gates: {map[]}
I1009 09:44:22.836110  106124 mount_linux.go:334] Detected umount with safe 'not mounted' behavior
I1009 09:44:22.837858  106124 server.go:519] "Kubelet version" kubeletVersion="v1.32.0-alpha.1.139+b2031b3cb46e94-dirty"
I1009 09:44:22.837882  106124 server.go:521] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I1009 09:44:22.837933  106124 feature_gate.go:387] feature gates: {map[]}
I1009 09:44:22.838043  106124 feature_gate.go:387] feature gates: {map[]}
I1009 09:44:22.839144  106124 log.go:25] "Connecting to runtime service" endpoint="unix:///run/containerd/containerd.sock"
I1009 09:44:22.839706  106124 log.go:25] "Validating the CRI v1 API runtime version"
I1009 09:44:22.841903  106124 log.go:25] "Validated CRI v1 runtime API"
I1009 09:44:22.841919  106124 log.go:25] "Connecting to image service" endpoint="unix:///run/containerd/containerd.sock"
I1009 09:44:22.842116  106124 log.go:25] "Validating the CRI v1 API image version"
I1009 09:44:22.842822  106124 log.go:25] "Validated CRI v1 image API"
I1009 09:44:22.842839  106124 server.go:1411] "Getting CRI runtime configuration information"
E1009 09:44:22.843038  106124 log.go:32] "RuntimeConfig from runtime service failed" err="rpc error: code = Unimplemented desc = unknown method RuntimeConfig for service runtime.v1.RuntimeService"
I1009 09:44:22.843057  106124 server.go:1431] "CRI implementation should be updated to support RuntimeConfig when KubeletCgroupDriverFromCRI feature gate has been enabled. Falling back to using cgroupDriver from kubelet config."
I1009 09:44:22.843494  106124 fs.go:135] Filesystem UUIDs: map[2024-10-08-21-39-49-00:/dev/sr0 9c6b3b5d-0247-404e-ac9c-39dd8b38829c:/dev/sda16 E9A4-DC35:/dev/sda15 b2679cb7-040c-47fb-9459-f477977bb9de:/dev/sda1]
I1009 09:44:22.843512  106124 fs.go:136] Filesystem partitions: map[/dev/sda1:{mountpoint:/ major:8 minor:1 fsType:ext4 blockSize:0} /dev/sda16:{mountpoint:/boot major:259 minor:0 fsType:ext4 blockSize:0} /dev/shm:{mountpoint:/dev/shm major:0 minor:26 fsType:tmpfs blockSize:0} /run:{mountpoint:/run major:0 minor:25 fsType:tmpfs blockSize:0} /run/lock:{mountpoint:/run/lock major:0 minor:27 fsType:tmpfs blockSize:0} /run/user/0:{mountpoint:/run/user/0 major:0 minor:45 fsType:tmpfs blockSize:0}]
I1009 09:44:22.847931  106124 manager.go:217] Machine: {Timestamp:2024-10-09 09:44:22.847723627 +0000 UTC m=+0.053238143 CPUVendorID:AuthenticAMD NumCores:4 NumPhysicalCores:4 NumSockets:1 CpuFrequency:3250002 MemoryCapacity:16769191936 SwapCapacity:0 MemoryByType:map[] NVMInfo:{MemoryModeCapacity:0 AppDirectModeCapacity:0 AvgPowerBudget:0} HugePages:[{PageSize:1048576 NumPages:0} {PageSize:2048 NumPages:0}] MachineID:65d73cbc71b379cac4b549bd3ecc1c0b SystemUUID:dc915252-0eda-409d-8edd-32fc3569d64c BootID:81bf9d73-a8f3-4d59-a976-bcbb950c48b1 Filesystems:[{Device:/dev/sda1 DeviceMajor:8 DeviceMinor:1 Capacity:206900281344 Type:vfs Inodes:26083328 HasInodes:true} {Device:/dev/shm DeviceMajor:0 DeviceMinor:26 Capacity:8384593920 Type:vfs Inodes:2047020 HasInodes:true} {Device:/run/lock DeviceMajor:0 DeviceMinor:27 Capacity:5242880 Type:vfs Inodes:2047020 HasInodes:true} {Device:/dev/sda16 DeviceMajor:259 DeviceMinor:0 Capacity:923156480 Type:vfs Inodes:58496 HasInodes:true} {Device:/run/user/0 DeviceMajor:0 DeviceMinor:45 Capacity:1676918784 Type:vfs Inodes:409404 HasInodes:true} {Device:/run DeviceMajor:0 DeviceMinor:25 Capacity:1676922880 Type:vfs Inodes:2047020 HasInodes:true}] DiskMap:map[8:0:{Name:sda Major:8 Minor:0 Size:214748364800 Scheduler:mq-deadline}] NetworkDevices:[{Name:eth0 MacAddress:bc:24:11:5a:b1:d8 Speed:-1 Mtu:1500} {Name:mynet0 MacAddress:7a:33:1f:8c:40:2d Speed:-1 Mtu:1500}] Topology:[{Id:0 Memory:16769191936 HugePages:[{PageSize:1048576 NumPages:0} {PageSize:2048 NumPages:0}] Cores:[{Id:0 Threads:[0] Caches:[{Id:0 Size:65536 Type:Data Level:1} {Id:0 Size:65536 Type:Instruction Level:1} {Id:0 Size:524288 Type:Unified Level:2}] UncoreCaches:[] SocketID:0 BookID: DrawerID:} {Id:1 Threads:[1] Caches:[{Id:1 Size:65536 Type:Data Level:1} {Id:1 Size:65536 Type:Instruction Level:1} {Id:1 Size:524288 Type:Unified Level:2}] UncoreCaches:[] SocketID:0 BookID: DrawerID:} {Id:2 Threads:[2] Caches:[{Id:2 Size:65536 Type:Data Level:1} {Id:2 Size:65536 Type:Instruction Level:1} {Id:2 Size:524288 Type:Unified Level:2}] UncoreCaches:[] SocketID:0 BookID: DrawerID:} {Id:3 Threads:[3] Caches:[{Id:3 Size:65536 Type:Data Level:1} {Id:3 Size:65536 Type:Instruction Level:1} {Id:3 Size:524288 Type:Unified Level:2}] UncoreCaches:[] SocketID:0 BookID: DrawerID:}] Caches:[{Id:0 Size:16777216 Type:Unified Level:3} {Id:1 Size:16777216 Type:Unified Level:3} {Id:2 Size:16777216 Type:Unified Level:3} {Id:3 Size:16777216 Type:Unified Level:3}] Distances:[10]}] CloudProvider:Unknown InstanceType:Unknown InstanceID:None}
I1009 09:44:22.848098  106124 manager_no_libpfm.go:29] cAdvisor is build without cgo and/or libpfm support. Perf event counters are not available.
I1009 09:44:22.848120  106124 manager.go:226] Cannot gather resctrl metrics: unable to initialize resctrl: Intel RDT not available
I1009 09:44:22.848152  106124 manager.go:233] Version: {KernelVersion:6.8.0-45-generic ContainerOsVersion:Ubuntu 24.04.1 LTS DockerVersion: DockerAPIVersion: CadvisorVersion: CadvisorRevision:}
I1009 09:44:22.848236  106124 server.go:567] "Sending events to api server"
I1009 09:44:22.848547  106124 container_manager_linux.go:264] "Container manager verified user specified cgroup-root exists" cgroupRoot=[]
I1009 09:44:22.848572  106124 container_manager_linux.go:269] "Creating Container Manager object based on Node Config" nodeConfig={"NodeName":"srv579909","RuntimeCgroupsName":"","SystemCgroupsName":"","KubeletCgroupsName":"/kubelet.slice","KubeletOOMScoreAdj":-999,"ContainerRuntime":"","CgroupsPerQOS":true,"CgroupRoot":"/","CgroupDriver":"cgroupfs","KubeletRootDir":"/var/lib/kubelet","ProtectKernelDefaults":false,"KubeReservedCgroupName":"","SystemReservedCgroupName":"","ReservedSystemCPUs":{},"EnforceNodeAllocatable":{"pods":{}},"KubeReserved":null,"SystemReserved":null,"HardEvictionThresholds":[{"Signal":"nodefs.available","Operator":"LessThan","Value":{"Quantity":null,"Percentage":0.1},"GracePeriod":0,"MinReclaim":null},{"Signal":"nodefs.inodesFree","Operator":"LessThan","Value":{"Quantity":null,"Percentage":0.05},"GracePeriod":0,"MinReclaim":null},{"Signal":"memory.available","Operator":"LessThan","Value":{"Quantity":"250Mi","Percentage":0},"GracePeriod":0,"MinReclaim":null}],"QOSReserved":{},"CPUManagerPolicy":"none","CPUManagerPolicyOptions":null,"TopologyManagerScope":"container","CPUManagerReconcilePeriod":10000000000,"ExperimentalMemoryManagerPolicy":"None","ExperimentalMemoryManagerReservedMemory":null,"PodPidsLimit":-1,"EnforceCPULimits":true,"CPUCFSQuotaPeriod":100000000,"TopologyManagerPolicy":"none","TopologyManagerPolicyOptions":null,"CgroupVersion":2}
I1009 09:44:22.848757  106124 topology_manager.go:138] "Creating topology manager with none policy"
I1009 09:44:22.848766  106124 container_manager_linux.go:300] "Creating device plugin manager"
I1009 09:44:22.848773  106124 manager.go:143] "Creating Device Plugin manager" path="/var/lib/kubelet/device-plugins/kubelet.sock"
I1009 09:44:22.848796  106124 server.go:66] "Creating device plugin registration server" version="v1beta1" socket="/var/lib/kubelet/device-plugins/kubelet.sock"
I1009 09:44:22.848819  106124 state_mem.go:36] "Initialized new in-memory state store"
I1009 09:44:22.848838  106124 oom_linux.go:65] attempting to set "/proc/self/oom_score_adj" to "-999"
I1009 09:44:22.848878  106124 server.go:1262] "Using root directory" path="/var/lib/kubelet"
I1009 09:44:22.848935  106124 kubelet.go:408] "Attempting to sync node with API server"
I1009 09:44:22.848952  106124 kubelet.go:303] "Adding static pod path" path="/home/ubuntu/kubernetes/_output/local/go/bin/static-pods2420371793"
I1009 09:44:22.848970  106124 file.go:68] "Watching path" path="/home/ubuntu/kubernetes/_output/local/go/bin/static-pods2420371793"
I1009 09:44:22.848980  106124 kubelet.go:314] "Adding apiserver pod source"
I1009 09:44:22.848990  106124 apiserver.go:42] "Waiting for node sync before watching apiserver pods"
I1009 09:44:22.849182  106124 reflector.go:305] Starting reflector *v1.Service (0s) from k8s.io/client-go/informers/factory.go:160
I1009 09:44:22.849191  106124 reflector.go:341] Listing and watching *v1.Service from k8s.io/client-go/informers/factory.go:160
I1009 09:44:22.849245  106124 config.go:292] "Setting pods for source" source="file"
I1009 09:44:22.849248  106124 reflector.go:305] Starting reflector *v1.Node (0s) from k8s.io/client-go/informers/factory.go:160
I1009 09:44:22.849270  106124 reflector.go:341] Listing and watching *v1.Node from k8s.io/client-go/informers/factory.go:160
I1009 09:44:22.849478  106124 kuberuntime_manager.go:262] "Container runtime initialized" containerRuntime="containerd" version="1.7.12" apiVersion="v1"
I1009 09:44:22.849495  106124 plugins.go:65] Registering credential provider: .dockercfg
I1009 09:44:22.849528  106124 kuberuntime_manager.go:1635] "Updating runtime config through cri with podcidr" CIDR="10.100.0.0/24"
I1009 09:44:22.849919  106124 kubelet_network.go:61] "Updating Pod CIDR" originalPodCIDR="" newPodCIDR="10.100.0.0/24"
I1009 09:44:22.850206  106124 dynamic_serving_content.go:116] "Loaded a new cert/key pair" name="kubelet-server-cert-files::/var/lib/kubelet/pki/kubelet.crt::/var/lib/kubelet/pki/kubelet.key"
I1009 09:44:22.850313  106124 kubelet.go:292] "loaded certificate and key pair in kubelet server certificate manager" certFile="/var/lib/kubelet/pki/kubelet.crt" keyFile="/var/lib/kubelet/pki/kubelet.key"
I1009 09:44:22.850366  106124 kubelet.go:837] "Not starting ClusterTrustBundle informer because we are in static kubelet mode"
I1009 09:44:22.850490  106124 plugins.go:606] "Loaded volume plugin" pluginName="kubernetes.io/portworx-volume"
I1009 09:44:22.850514  106124 plugins.go:606] "Loaded volume plugin" pluginName="kubernetes.io/empty-dir"
I1009 09:44:22.850521  106124 plugins.go:606] "Loaded volume plugin" pluginName="kubernetes.io/git-repo"
I1009 09:44:22.850527  106124 plugins.go:606] "Loaded volume plugin" pluginName="kubernetes.io/host-path"
I1009 09:44:22.850532  106124 plugins.go:606] "Loaded volume plugin" pluginName="kubernetes.io/nfs"
I1009 09:44:22.850538  106124 plugins.go:606] "Loaded volume plugin" pluginName="kubernetes.io/secret"
I1009 09:44:22.850544  106124 plugins.go:606] "Loaded volume plugin" pluginName="kubernetes.io/iscsi"
I1009 09:44:22.850549  106124 plugins.go:606] "Loaded volume plugin" pluginName="kubernetes.io/downward-api"
I1009 09:44:22.850555  106124 plugins.go:606] "Loaded volume plugin" pluginName="kubernetes.io/fc"
I1009 09:44:22.850561  106124 plugins.go:606] "Loaded volume plugin" pluginName="kubernetes.io/configmap"
I1009 09:44:22.850592  106124 plugins.go:606] "Loaded volume plugin" pluginName="kubernetes.io/projected"
I1009 09:44:22.850604  106124 plugins.go:606] "Loaded volume plugin" pluginName="kubernetes.io/local-volume"
I1009 09:44:22.850633  106124 plugins.go:606] "Loaded volume plugin" pluginName="kubernetes.io/csi"
I1009 09:44:22.850939  106124 server.go:1297] "Started kubelet"
I1009 09:44:22.851307  106124 server.go:201] "Starting to listen read-only" address="0.0.0.0" port=10255
I1009 09:44:22.851355  106124 server.go:163] "Starting to listen" address="0.0.0.0" port=10250
I1009 09:44:22.851849  106124 ratelimit.go:55] "Setting rate limiting for endpoint" service="podresources" qps=100 burstTokens=10
I1009 09:44:22.852629  106124 server.go:236] "Starting to serve the podresources API" endpoint="unix:/var/lib/kubelet/pod-resources/kubelet.sock"
I1009 09:44:22.852837  106124 hostutil_linux.go:216] Directory /var/lib/kubelet is already on a shared mount
I1009 09:44:22.852929  106124 fs_resource_analyzer.go:67] "Starting FS ResourceAnalyzer"
I1009 09:44:22.853370  106124 dynamic_serving_content.go:135] "Starting controller" name="kubelet-server-cert-files::/var/lib/kubelet/pki/kubelet.crt::/var/lib/kubelet/pki/kubelet.key"
I1009 09:44:22.853526  106124 volume_manager.go:295] "The desired_state_of_world populator starts"
I1009 09:44:22.853540  106124 volume_manager.go:297] "Starting Kubelet Volume Manager"
I1009 09:44:22.853618  106124 desired_state_of_world_populator.go:147] "Desired state populator starts to run"
I1009 09:44:22.853732  106124 reconstruct.go:97] "Volume reconstruction finished"
I1009 09:44:22.853737  106124 reconciler.go:26] "Reconciler: start to sync state"
I1009 09:44:22.853775  106124 reflector.go:305] Starting reflector *v1.CSIDriver (0s) from k8s.io/client-go/informers/factory.go:160
I1009 09:44:22.853783  106124 reflector.go:341] Listing and watching *v1.CSIDriver from k8s.io/client-go/informers/factory.go:160
I1009 09:44:22.853920  106124 event.go:389] "Event occurred" object="srv579909" fieldPath="" kind="Node" apiVersion="" type="Normal" reason="Starting" message="Starting kubelet."
E1009 09:44:22.854149  106124 kubelet_node_status.go:465] "Error getting the current node from lister" err="node \"srv579909\" not found"
I1009 09:44:22.854835  106124 server.go:460] "Adding debug handlers to kubelet server"
I1009 09:44:22.856696  106124 kubelet.go:2898] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:; Handlers: , Features: nil"
I1009 09:44:22.856724  106124 factory.go:55] Registering systemd factory
I1009 09:44:22.856733  106124 factory.go:221] Registration of the systemd container factory successfully
I1009 09:44:22.857013  106124 factory.go:219] Registration of the crio container factory failed: Get "http://%2Fvar%2Frun%2Fcrio%2Fcrio.sock/info": dial unix /var/run/crio/crio.sock: connect: no such file or directory
I1009 09:44:22.859093  106124 kubelet.go:1457] "Container garbage collection succeeded"
I1009 09:44:22.860030  106124 reflector.go:368] Caches populated for *v1.Node from k8s.io/client-go/informers/factory.go:160
I1009 09:44:22.860278  106124 reflector.go:368] Caches populated for *v1.Service from k8s.io/client-go/informers/factory.go:160
I1009 09:44:22.860379  106124 csi_plugin.go:301] Initializing migrated drivers on CSINode
I1009 09:44:22.860673  106124 reflector.go:368] Caches populated for *v1.CSIDriver from k8s.io/client-go/informers/factory.go:160
I1009 09:44:22.860924  106124 factory.go:145] Registering containerd factory
I1009 09:44:22.860934  106124 factory.go:221] Registration of the containerd container factory successfully
I1009 09:44:22.860950  106124 factory.go:103] Registering Raw factory
I1009 09:44:22.861019  106124 manager.go:1196] Started watching for new ooms in manager
I1009 09:44:22.861052  106124 factory.go:279] Factory "systemd" was unable to handle container "/"
I1009 09:44:22.861065  106124 factory.go:279] Factory "containerd" was unable to handle container "/"
I1009 09:44:22.861072  106124 factory.go:275] Using factory "raw" for container "/"
I1009 09:44:22.861255  106124 manager.go:981] Added container: "/" (aliases: [], namespace: "")
I1009 09:44:22.861389  106124 handler.go:325] Added event &{/ 2024-10-08 23:09:41.329920551 +0000 UTC containerCreation {<nil>}}
I1009 09:44:22.861407  106124 manager.go:319] Starting recovery of all containers
E1009 09:44:22.862382  106124 nodelease.go:49] "Failed to get node when trying to set owner ref to the node lease" err="nodes \"srv579909\" not found" node="srv579909"
I1009 09:44:22.862693  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:44:22.864482  106124 container.go:529] Start housekeeping for container "/"
I1009 09:44:22.864752  106124 nodeinfomanager.go:402] Failed to publish CSINode: nodes "srv579909" not found
I1009 09:44:22.864872  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:44:22.866986  106124 kubelet.go:1489] "Image garbage collection succeeded"
I1009 09:44:22.867665  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/system-modprobe.slice"
I1009 09:44:22.867679  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/system-modprobe.slice"
I1009 09:44:22.867687  106124 factory.go:272] Factory "raw" can handle container "/system.slice/system-modprobe.slice", but ignoring.
I1009 09:44:22.867695  106124 manager.go:929] ignoring container "/system.slice/system-modprobe.slice"
I1009 09:44:22.867701  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/unattended-upgrades.service"
I1009 09:44:22.867706  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/unattended-upgrades.service"
I1009 09:44:22.867711  106124 factory.go:272] Factory "raw" can handle container "/system.slice/unattended-upgrades.service", but ignoring.
I1009 09:44:22.867721  106124 manager.go:929] ignoring container "/system.slice/unattended-upgrades.service"
I1009 09:44:22.867726  106124 factory.go:279] Factory "systemd" was unable to handle container "/user.slice/user-0.slice/user@0.service/app.slice/dbus.socket"
I1009 09:44:22.867731  106124 factory.go:279] Factory "containerd" was unable to handle container "/user.slice/user-0.slice/user@0.service/app.slice/dbus.socket"
I1009 09:44:22.867736  106124 factory.go:272] Factory "raw" can handle container "/user.slice/user-0.slice/user@0.service/app.slice/dbus.socket", but ignoring.
I1009 09:44:22.867743  106124 manager.go:929] ignoring container "/user.slice/user-0.slice/user@0.service/app.slice/dbus.socket"
I1009 09:44:22.867748  106124 factory.go:279] Factory "systemd" was unable to handle container "/user.slice/user-0.slice/user@0.service/init.scope"
I1009 09:44:22.867760  106124 factory.go:279] Factory "containerd" was unable to handle container "/user.slice/user-0.slice/user@0.service/init.scope"
I1009 09:44:22.867772  106124 factory.go:272] Factory "raw" can handle container "/user.slice/user-0.slice/user@0.service/init.scope", but ignoring.
I1009 09:44:22.867778  106124 manager.go:929] ignoring container "/user.slice/user-0.slice/user@0.service/init.scope"
I1009 09:44:22.867786  106124 factory.go:279] Factory "systemd" was unable to handle container "/runtime.slice"
I1009 09:44:22.867790  106124 factory.go:279] Factory "containerd" was unable to handle container "/runtime.slice"
I1009 09:44:22.867795  106124 factory.go:272] Factory "raw" can handle container "/runtime.slice", but ignoring.
I1009 09:44:22.867801  106124 manager.go:929] ignoring container "/runtime.slice"
I1009 09:44:22.867806  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/systemd-udevd.service"
I1009 09:44:22.867810  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/systemd-udevd.service"
I1009 09:44:22.867815  106124 factory.go:272] Factory "raw" can handle container "/system.slice/systemd-udevd.service", but ignoring.
I1009 09:44:22.867821  106124 manager.go:929] ignoring container "/system.slice/systemd-udevd.service"
I1009 09:44:22.867826  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/nginx.service"
I1009 09:44:22.867833  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/nginx.service"
I1009 09:44:22.867838  106124 factory.go:272] Factory "raw" can handle container "/system.slice/nginx.service", but ignoring.
I1009 09:44:22.867844  106124 manager.go:929] ignoring container "/system.slice/nginx.service"
I1009 09:44:22.867849  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/cloud-init-local.service"
I1009 09:44:22.867853  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/cloud-init-local.service"
I1009 09:44:22.867867  106124 factory.go:272] Factory "raw" can handle container "/system.slice/cloud-init-local.service", but ignoring.
I1009 09:44:22.867879  106124 manager.go:929] ignoring container "/system.slice/cloud-init-local.service"
I1009 09:44:22.867884  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/system-getty.slice/getty@tty1.service"
I1009 09:44:22.867888  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/system-getty.slice/getty@tty1.service"
I1009 09:44:22.867897  106124 factory.go:272] Factory "raw" can handle container "/system.slice/system-getty.slice/getty@tty1.service", but ignoring.
I1009 09:44:22.867903  106124 manager.go:929] ignoring container "/system.slice/system-getty.slice/getty@tty1.service"
I1009 09:44:22.867908  106124 factory.go:279] Factory "systemd" was unable to handle container "/runtime.slice/kubelet-20241009T094422.service"
I1009 09:44:22.867912  106124 factory.go:279] Factory "containerd" was unable to handle container "/runtime.slice/kubelet-20241009T094422.service"
I1009 09:44:22.867918  106124 factory.go:272] Factory "raw" can handle container "/runtime.slice/kubelet-20241009T094422.service", but ignoring.
I1009 09:44:22.867923  106124 manager.go:929] ignoring container "/runtime.slice/kubelet-20241009T094422.service"
I1009 09:44:22.867929  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/systemd-networkd.service"
I1009 09:44:22.867933  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/systemd-networkd.service"
I1009 09:44:22.867939  106124 factory.go:272] Factory "raw" can handle container "/system.slice/systemd-networkd.service", but ignoring.
I1009 09:44:22.867948  106124 manager.go:929] ignoring container "/system.slice/systemd-networkd.service"
I1009 09:44:22.867953  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/system-serial\\x2dgetty.slice/serial-getty@ttyS0.service"
I1009 09:44:22.867958  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/system-serial\\x2dgetty.slice/serial-getty@ttyS0.service"
I1009 09:44:22.867964  106124 factory.go:272] Factory "raw" can handle container "/system.slice/system-serial\\x2dgetty.slice/serial-getty@ttyS0.service", but ignoring.
I1009 09:44:22.867970  106124 manager.go:929] ignoring container "/system.slice/system-serial\\x2dgetty.slice/serial-getty@ttyS0.service"
I1009 09:44:22.867976  106124 factory.go:272] Factory "systemd" can handle container "/system.slice/boot.mount", but ignoring.
I1009 09:44:22.867981  106124 manager.go:929] ignoring container "/system.slice/boot.mount"
I1009 09:44:22.867986  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/cloud-final.service"
I1009 09:44:22.867990  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/cloud-final.service"
I1009 09:44:22.867998  106124 factory.go:272] Factory "raw" can handle container "/system.slice/cloud-final.service", but ignoring.
I1009 09:44:22.868003  106124 manager.go:929] ignoring container "/system.slice/cloud-final.service"
I1009 09:44:22.868008  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/dbus.service"
I1009 09:44:22.868012  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/dbus.service"
I1009 09:44:22.868017  106124 factory.go:272] Factory "raw" can handle container "/system.slice/dbus.service", but ignoring.
I1009 09:44:22.868023  106124 manager.go:929] ignoring container "/system.slice/dbus.service"
I1009 09:44:22.868028  106124 factory.go:279] Factory "systemd" was unable to handle container "/kubepods/burstable"
I1009 09:44:22.868032  106124 factory.go:279] Factory "containerd" was unable to handle container "/kubepods/burstable"
I1009 09:44:22.868037  106124 factory.go:275] Using factory "raw" for container "/kubepods/burstable"
I1009 09:44:22.868237  106124 manager.go:981] Added container: "/kubepods/burstable" (aliases: [], namespace: "")
I1009 09:44:22.868466  106124 handler.go:325] Added event &{/kubepods/burstable 2024-10-08 23:09:41.325744408 +0000 UTC containerCreation {<nil>}}
I1009 09:44:22.868514  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/containerd.service"
I1009 09:44:22.868522  106124 container.go:529] Start housekeeping for container "/kubepods/burstable"
I1009 09:44:22.868526  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/containerd.service"
I1009 09:44:22.868532  106124 factory.go:272] Factory "raw" can handle container "/system.slice/containerd.service", but ignoring.
I1009 09:44:22.868538  106124 manager.go:929] ignoring container "/system.slice/containerd.service"
I1009 09:44:22.868561  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/orthanc.service"
I1009 09:44:22.868569  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/orthanc.service"
I1009 09:44:22.868573  106124 factory.go:272] Factory "raw" can handle container "/system.slice/orthanc.service", but ignoring.
I1009 09:44:22.868579  106124 manager.go:929] ignoring container "/system.slice/orthanc.service"
I1009 09:44:22.868584  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/systemd-resolved.service"
I1009 09:44:22.868588  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/systemd-resolved.service"
I1009 09:44:22.868599  106124 factory.go:272] Factory "raw" can handle container "/system.slice/systemd-resolved.service", but ignoring.
I1009 09:44:22.868603  106124 manager.go:929] ignoring container "/system.slice/systemd-resolved.service"
I1009 09:44:22.868608  106124 factory.go:279] Factory "systemd" was unable to handle container "/user.slice/user-0.slice/session-66.scope"
I1009 09:44:22.868619  106124 factory.go:279] Factory "containerd" was unable to handle container "/user.slice/user-0.slice/session-66.scope"
I1009 09:44:22.868624  106124 factory.go:272] Factory "raw" can handle container "/user.slice/user-0.slice/session-66.scope", but ignoring.
I1009 09:44:22.868630  106124 manager.go:929] ignoring container "/user.slice/user-0.slice/session-66.scope"
I1009 09:44:22.868635  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/system-serial\\x2dgetty.slice"
I1009 09:44:22.868643  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/system-serial\\x2dgetty.slice"
I1009 09:44:22.868648  106124 factory.go:272] Factory "raw" can handle container "/system.slice/system-serial\\x2dgetty.slice", but ignoring.
I1009 09:44:22.868651  106124 manager.go:929] ignoring container "/system.slice/system-serial\\x2dgetty.slice"
I1009 09:44:22.868655  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/multipathd.service"
I1009 09:44:22.868658  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/multipathd.service"
I1009 09:44:22.868663  106124 factory.go:272] Factory "raw" can handle container "/system.slice/multipathd.service", but ignoring.
I1009 09:44:22.868667  106124 manager.go:929] ignoring container "/system.slice/multipathd.service"
I1009 09:44:22.868670  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/ModemManager.service"
I1009 09:44:22.868673  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/ModemManager.service"
I1009 09:44:22.868677  106124 factory.go:272] Factory "raw" can handle container "/system.slice/ModemManager.service", but ignoring.
I1009 09:44:22.868681  106124 manager.go:929] ignoring container "/system.slice/ModemManager.service"
I1009 09:44:22.868684  106124 factory.go:272] Factory "systemd" can handle container "/sys-kernel-config.mount", but ignoring.
I1009 09:44:22.868687  106124 manager.go:929] ignoring container "/sys-kernel-config.mount"
I1009 09:44:22.868691  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/systemd-udevd.service/udev"
I1009 09:44:22.868702  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/systemd-udevd.service/udev"
I1009 09:44:22.868706  106124 factory.go:272] Factory "raw" can handle container "/system.slice/systemd-udevd.service/udev", but ignoring.
I1009 09:44:22.868710  106124 manager.go:929] ignoring container "/system.slice/systemd-udevd.service/udev"
I1009 09:44:22.868719  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/cron.service"
I1009 09:44:22.868723  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/cron.service"
I1009 09:44:22.868726  106124 factory.go:272] Factory "raw" can handle container "/system.slice/cron.service", but ignoring.
I1009 09:44:22.868730  106124 manager.go:929] ignoring container "/system.slice/cron.service"
I1009 09:44:22.868734  106124 factory.go:272] Factory "systemd" can handle container "/proc-sys-fs-binfmt_misc.mount", but ignoring.
I1009 09:44:22.868737  106124 manager.go:929] ignoring container "/proc-sys-fs-binfmt_misc.mount"
I1009 09:44:22.868742  106124 factory.go:279] Factory "systemd" was unable to handle container "/user.slice/user-0.slice/user@0.service"
I1009 09:44:22.868745  106124 factory.go:279] Factory "containerd" was unable to handle container "/user.slice/user-0.slice/user@0.service"
I1009 09:44:22.868749  106124 factory.go:272] Factory "raw" can handle container "/user.slice/user-0.slice/user@0.service", but ignoring.
I1009 09:44:22.868761  106124 manager.go:929] ignoring container "/user.slice/user-0.slice/user@0.service"
I1009 09:44:22.868765  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/ssh.socket"
I1009 09:44:22.868768  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/ssh.socket"
I1009 09:44:22.868772  106124 factory.go:272] Factory "raw" can handle container "/system.slice/ssh.socket", but ignoring.
I1009 09:44:22.868775  106124 manager.go:929] ignoring container "/system.slice/ssh.socket"
I1009 09:44:22.868779  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/rsyslog.service"
I1009 09:44:22.868784  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/rsyslog.service"
I1009 09:44:22.868787  106124 factory.go:272] Factory "raw" can handle container "/system.slice/rsyslog.service", but ignoring.
I1009 09:44:22.868791  106124 manager.go:929] ignoring container "/system.slice/rsyslog.service"
I1009 09:44:22.868794  106124 factory.go:279] Factory "systemd" was unable to handle container "/user.slice/user-0.slice/user@0.service/app.slice"
I1009 09:44:22.868798  106124 factory.go:279] Factory "containerd" was unable to handle container "/user.slice/user-0.slice/user@0.service/app.slice"
I1009 09:44:22.868801  106124 factory.go:272] Factory "raw" can handle container "/user.slice/user-0.slice/user@0.service/app.slice", but ignoring.
I1009 09:44:22.868805  106124 manager.go:929] ignoring container "/user.slice/user-0.slice/user@0.service/app.slice"
I1009 09:44:22.868809  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/system-systemd\\x2dfsck.slice"
I1009 09:44:22.868812  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/system-systemd\\x2dfsck.slice"
I1009 09:44:22.868822  106124 factory.go:272] Factory "raw" can handle container "/system.slice/system-systemd\\x2dfsck.slice", but ignoring.
I1009 09:44:22.868826  106124 manager.go:929] ignoring container "/system.slice/system-systemd\\x2dfsck.slice"
I1009 09:44:22.868830  106124 factory.go:272] Factory "systemd" can handle container "/system.slice/boot-efi.mount", but ignoring.
I1009 09:44:22.868833  106124 manager.go:929] ignoring container "/system.slice/boot-efi.mount"
I1009 09:44:22.868837  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/systemd-timesyncd.service"
I1009 09:44:22.868840  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/systemd-timesyncd.service"
I1009 09:44:22.868898  106124 factory.go:272] Factory "raw" can handle container "/system.slice/systemd-timesyncd.service", but ignoring.
I1009 09:44:22.868907  106124 manager.go:929] ignoring container "/system.slice/systemd-timesyncd.service"
I1009 09:44:22.868915  106124 factory.go:279] Factory "systemd" was unable to handle container "/user.slice/user-0.slice/user@0.service/app.slice/gpg-agent-ssh.socket"
I1009 09:44:22.868922  106124 factory.go:279] Factory "containerd" was unable to handle container "/user.slice/user-0.slice/user@0.service/app.slice/gpg-agent-ssh.socket"
I1009 09:44:22.868932  106124 factory.go:272] Factory "raw" can handle container "/user.slice/user-0.slice/user@0.service/app.slice/gpg-agent-ssh.socket", but ignoring.
I1009 09:44:22.868940  106124 manager.go:929] ignoring container "/user.slice/user-0.slice/user@0.service/app.slice/gpg-agent-ssh.socket"
I1009 09:44:22.868946  106124 factory.go:272] Factory "systemd" can handle container "/sys-kernel-tracing.mount", but ignoring.
I1009 09:44:22.868953  106124 manager.go:929] ignoring container "/sys-kernel-tracing.mount"
I1009 09:44:22.868958  106124 factory.go:279] Factory "systemd" was unable to handle container "/init.scope"
I1009 09:44:22.868964  106124 factory.go:279] Factory "containerd" was unable to handle container "/init.scope"
I1009 09:44:22.868969  106124 factory.go:272] Factory "raw" can handle container "/init.scope", but ignoring.
I1009 09:44:22.868975  106124 manager.go:929] ignoring container "/init.scope"
I1009 09:44:22.868980  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice"
I1009 09:44:22.868988  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice"
I1009 09:44:22.868993  106124 factory.go:272] Factory "raw" can handle container "/system.slice", but ignoring.
I1009 09:44:22.868998  106124 manager.go:929] ignoring container "/system.slice"
I1009 09:44:22.869003  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/ssh.service"
I1009 09:44:22.869012  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/ssh.service"
I1009 09:44:22.869018  106124 factory.go:272] Factory "raw" can handle container "/system.slice/ssh.service", but ignoring.
I1009 09:44:22.869023  106124 manager.go:929] ignoring container "/system.slice/ssh.service"
I1009 09:44:22.869028  106124 factory.go:272] Factory "systemd" can handle container "/sys-fs-fuse-connections.mount", but ignoring.
I1009 09:44:22.869032  106124 manager.go:929] ignoring container "/sys-fs-fuse-connections.mount"
I1009 09:44:22.869040  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/lxd-installer.socket"
I1009 09:44:22.869044  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/lxd-installer.socket"
I1009 09:44:22.869050  106124 factory.go:272] Factory "raw" can handle container "/system.slice/lxd-installer.socket", but ignoring.
I1009 09:44:22.869055  106124 manager.go:929] ignoring container "/system.slice/lxd-installer.socket"
I1009 09:44:22.869060  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/cloud-config.service"
I1009 09:44:22.869064  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/cloud-config.service"
I1009 09:44:22.869069  106124 factory.go:272] Factory "raw" can handle container "/system.slice/cloud-config.service", but ignoring.
I1009 09:44:22.869074  106124 manager.go:929] ignoring container "/system.slice/cloud-config.service"
I1009 09:44:22.869079  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/snapd.socket"
I1009 09:44:22.869086  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/snapd.socket"
I1009 09:44:22.869098  106124 factory.go:272] Factory "raw" can handle container "/system.slice/snapd.socket", but ignoring.
I1009 09:44:22.869104  106124 manager.go:929] ignoring container "/system.slice/snapd.socket"
I1009 09:44:22.869113  106124 factory.go:272] Factory "systemd" can handle container "/sys-kernel-debug.mount", but ignoring.
I1009 09:44:22.869119  106124 manager.go:929] ignoring container "/sys-kernel-debug.mount"
I1009 09:44:22.869127  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/qemu-guest-agent.service"
I1009 09:44:22.869131  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/qemu-guest-agent.service"
I1009 09:44:22.869136  106124 factory.go:272] Factory "raw" can handle container "/system.slice/qemu-guest-agent.service", but ignoring.
I1009 09:44:22.869142  106124 manager.go:929] ignoring container "/system.slice/qemu-guest-agent.service"
I1009 09:44:22.869149  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/systemd-logind.service"
I1009 09:44:22.869154  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/systemd-logind.service"
I1009 09:44:22.869159  106124 factory.go:272] Factory "raw" can handle container "/system.slice/systemd-logind.service", but ignoring.
I1009 09:44:22.869165  106124 manager.go:929] ignoring container "/system.slice/systemd-logind.service"
I1009 09:44:22.869170  106124 factory.go:272] Factory "systemd" can handle container "/dev-hugepages.mount", but ignoring.
I1009 09:44:22.869175  106124 manager.go:929] ignoring container "/dev-hugepages.mount"
I1009 09:44:22.869180  106124 factory.go:279] Factory "systemd" was unable to handle container "/kubepods/besteffort"
I1009 09:44:22.869184  106124 factory.go:279] Factory "containerd" was unable to handle container "/kubepods/besteffort"
I1009 09:44:22.869189  106124 factory.go:275] Using factory "raw" for container "/kubepods/besteffort"
I1009 09:44:22.869391  106124 manager.go:981] Added container: "/kubepods/besteffort" (aliases: [], namespace: "")
I1009 09:44:22.869606  106124 kubelet_network_linux.go:50] "Initialized iptables rules." protocol="IPv4"
I1009 09:44:22.870194  106124 handler.go:325] Added event &{/kubepods/besteffort 2024-10-08 23:09:41.326744485 +0000 UTC containerCreation {<nil>}}
I1009 09:44:22.870216  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/polkit.service"
I1009 09:44:22.870222  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/polkit.service"
I1009 09:44:22.870227  106124 factory.go:272] Factory "raw" can handle container "/system.slice/polkit.service", but ignoring.
I1009 09:44:22.870233  106124 manager.go:929] ignoring container "/system.slice/polkit.service"
I1009 09:44:22.870239  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/udisks2.service"
I1009 09:44:22.870244  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/udisks2.service"
I1009 09:44:22.870249  106124 factory.go:272] Factory "raw" can handle container "/system.slice/udisks2.service", but ignoring.
I1009 09:44:22.870255  106124 manager.go:929] ignoring container "/system.slice/udisks2.service"
I1009 09:44:22.870260  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/system-getty.slice"
I1009 09:44:22.870263  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/system-getty.slice"
I1009 09:44:22.870267  106124 factory.go:272] Factory "raw" can handle container "/system.slice/system-getty.slice", but ignoring.
I1009 09:44:22.870271  106124 manager.go:929] ignoring container "/system.slice/system-getty.slice"
I1009 09:44:22.870275  106124 factory.go:279] Factory "systemd" was unable to handle container "/kubelet.slice"
I1009 09:44:22.870278  106124 factory.go:279] Factory "containerd" was unable to handle container "/kubelet.slice"
I1009 09:44:22.870282  106124 factory.go:275] Using factory "raw" for container "/kubelet.slice"
I1009 09:44:22.870566  106124 manager.go:981] Added container: "/kubelet.slice" (aliases: [], namespace: "")
I1009 09:44:22.870766  106124 handler.go:325] Added event &{/kubelet.slice 2024-10-08 23:09:41.32874464 +0000 UTC containerCreation {<nil>}}
I1009 09:44:22.870779  106124 factory.go:272] Factory "systemd" can handle container "/dev-mqueue.mount", but ignoring.
I1009 09:44:22.870784  106124 manager.go:929] ignoring container "/dev-mqueue.mount"
I1009 09:44:22.870788  106124 factory.go:279] Factory "systemd" was unable to handle container "/user.slice"
I1009 09:44:22.870792  106124 factory.go:279] Factory "containerd" was unable to handle container "/user.slice"
I1009 09:44:22.870795  106124 factory.go:272] Factory "raw" can handle container "/user.slice", but ignoring.
I1009 09:44:22.870799  106124 manager.go:929] ignoring container "/user.slice"
I1009 09:44:22.870803  106124 factory.go:279] Factory "systemd" was unable to handle container "/user.slice/user-0.slice"
I1009 09:44:22.870807  106124 factory.go:279] Factory "containerd" was unable to handle container "/user.slice/user-0.slice"
I1009 09:44:22.870811  106124 factory.go:272] Factory "raw" can handle container "/user.slice/user-0.slice", but ignoring.
I1009 09:44:22.870814  106124 manager.go:929] ignoring container "/user.slice/user-0.slice"
I1009 09:44:22.870818  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/cloud-init.service"
I1009 09:44:22.870821  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/cloud-init.service"
I1009 09:44:22.870825  106124 factory.go:272] Factory "raw" can handle container "/system.slice/cloud-init.service", but ignoring.
I1009 09:44:22.870829  106124 manager.go:929] ignoring container "/system.slice/cloud-init.service"
I1009 09:44:22.870832  106124 factory.go:279] Factory "systemd" was unable to handle container "/kubepods"
I1009 09:44:22.870835  106124 factory.go:279] Factory "containerd" was unable to handle container "/kubepods"
I1009 09:44:22.870839  106124 factory.go:275] Using factory "raw" for container "/kubepods"
I1009 09:44:22.870979  106124 manager.go:981] Added container: "/kubepods" (aliases: [], namespace: "")
I1009 09:44:22.871102  106124 handler.go:325] Added event &{/kubepods 2024-10-08 23:09:41.32474433 +0000 UTC containerCreation {<nil>}}
I1009 09:44:22.871109  106124 factory.go:279] Factory "systemd" was unable to handle container "/user.slice/user-0.slice/session-78.scope"
I1009 09:44:22.871112  106124 factory.go:279] Factory "containerd" was unable to handle container "/user.slice/user-0.slice/session-78.scope"
I1009 09:44:22.871116  106124 factory.go:272] Factory "raw" can handle container "/user.slice/user-0.slice/session-78.scope", but ignoring.
I1009 09:44:22.871120  106124 manager.go:929] ignoring container "/user.slice/user-0.slice/session-78.scope"
I1009 09:44:22.871123  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/systemd-journald.service"
I1009 09:44:22.871127  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/systemd-journald.service"
I1009 09:44:22.871130  106124 factory.go:272] Factory "raw" can handle container "/system.slice/systemd-journald.service", but ignoring.
I1009 09:44:22.871134  106124 manager.go:929] ignoring container "/system.slice/systemd-journald.service"
I1009 09:44:22.871138  106124 manager.go:324] Recovery completed
I1009 09:44:22.871323  106124 kubelet_network_linux.go:50] "Initialized iptables rules." protocol="IPv6"
I1009 09:44:22.871357  106124 status_manager.go:217] "Starting to sync pod status with apiserver"
I1009 09:44:22.871384  106124 kubelet.go:2324] "Starting kubelet main sync loop"
E1009 09:44:22.871480  106124 kubelet.go:2348] "Skipping pod synchronization" err="[container runtime status check may not have completed yet, PLEG is not healthy: pleg has yet to be successful]"
I1009 09:44:22.872972  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:44:22.872999  106124 generic.go:187] "GenericPLEG" podUID="c7e58e54-59be-492a-8089-bf628cce8a30" containerID="a4fe23cc464877e9d3bc6c1826e24fa4b80f81e9eb51fd13324ddd4492e45e26" oldState="non-existent" newState="exited"
I1009 09:44:22.873059  106124 generic.go:187] "GenericPLEG" podUID="c7e58e54-59be-492a-8089-bf628cce8a30" containerID="d2140c7c68378b3ca1e26ec4ba9259a41b6f0b815b2c7dfef672e7467f4b897e" oldState="non-existent" newState="exited"
I1009 09:44:22.873397  106124 kuberuntime_manager.go:1537] "getSandboxIDByPodUID got sandbox IDs for pod" podSandboxID=["d2140c7c68378b3ca1e26ec4ba9259a41b6f0b815b2c7dfef672e7467f4b897e"] pod="prestop-hook-test-225/test-pod"
I1009 09:44:22.874850  106124 generic.go:463] "PLEG: Write status" pod="prestop-hook-test-225/test-pod"
I1009 09:44:22.874870  106124 generic.go:338] "Generic (PLEG): container finished" podID="c7e58e54-59be-492a-8089-bf628cce8a30" containerID="a4fe23cc464877e9d3bc6c1826e24fa4b80f81e9eb51fd13324ddd4492e45e26" exitCode=0
I1009 09:44:22.874978  106124 container.go:529] Start housekeeping for container "/kubepods/besteffort"
I1009 09:44:22.875339  106124 container.go:529] Start housekeeping for container "/kubelet.slice"
I1009 09:44:22.875528  106124 container.go:529] Start housekeeping for container "/kubepods"
I1009 09:44:22.875599  106124 reflector.go:305] Starting reflector *v1.RuntimeClass (0s) from k8s.io/client-go/informers/factory.go:160
I1009 09:44:22.875608  106124 reflector.go:341] Listing and watching *v1.RuntimeClass from k8s.io/client-go/informers/factory.go:160
I1009 09:44:22.876345  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/multipathd.service"
I1009 09:44:22.876356  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/multipathd.service"
I1009 09:44:22.876363  106124 factory.go:272] Factory "raw" can handle container "/system.slice/multipathd.service", but ignoring.
I1009 09:44:22.876370  106124 manager.go:929] ignoring container "/system.slice/multipathd.service"
I1009 09:44:22.876375  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/systemd-networkd.service"
I1009 09:44:22.876379  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/systemd-networkd.service"
I1009 09:44:22.876384  106124 factory.go:272] Factory "raw" can handle container "/system.slice/systemd-networkd.service", but ignoring.
I1009 09:44:22.876389  106124 manager.go:929] ignoring container "/system.slice/systemd-networkd.service"
I1009 09:44:22.876394  106124 factory.go:279] Factory "systemd" was unable to handle container "/user.slice"
I1009 09:44:22.876397  106124 factory.go:279] Factory "containerd" was unable to handle container "/user.slice"
I1009 09:44:22.876402  106124 factory.go:272] Factory "raw" can handle container "/user.slice", but ignoring.
I1009 09:44:22.876407  106124 manager.go:929] ignoring container "/user.slice"
I1009 09:44:22.876412  106124 factory.go:279] Factory "systemd" was unable to handle container "/init.scope"
I1009 09:44:22.876416  106124 factory.go:279] Factory "containerd" was unable to handle container "/init.scope"
I1009 09:44:22.876420  106124 factory.go:272] Factory "raw" can handle container "/init.scope", but ignoring.
I1009 09:44:22.876432  106124 manager.go:929] ignoring container "/init.scope"
I1009 09:44:22.876437  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/system-serial\\x2dgetty.slice/serial-getty@ttyS0.service"
I1009 09:44:22.876442  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/system-serial\\x2dgetty.slice/serial-getty@ttyS0.service"
I1009 09:44:22.876448  106124 factory.go:272] Factory "raw" can handle container "/system.slice/system-serial\\x2dgetty.slice/serial-getty@ttyS0.service", but ignoring.
I1009 09:44:22.876476  106124 manager.go:929] ignoring container "/system.slice/system-serial\\x2dgetty.slice/serial-getty@ttyS0.service"
I1009 09:44:22.876480  106124 factory.go:272] Factory "systemd" can handle container "/proc-sys-fs-binfmt_misc.mount", but ignoring.
I1009 09:44:22.876484  106124 manager.go:929] ignoring container "/proc-sys-fs-binfmt_misc.mount"
I1009 09:44:22.876494  106124 factory.go:279] Factory "systemd" was unable to handle container "/user.slice/user-0.slice/session-78.scope"
I1009 09:44:22.876497  106124 factory.go:279] Factory "containerd" was unable to handle container "/user.slice/user-0.slice/session-78.scope"
I1009 09:44:22.876501  106124 factory.go:272] Factory "raw" can handle container "/user.slice/user-0.slice/session-78.scope", but ignoring.
I1009 09:44:22.876504  106124 manager.go:929] ignoring container "/user.slice/user-0.slice/session-78.scope"
I1009 09:44:22.876508  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/nginx.service"
I1009 09:44:22.876511  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/nginx.service"
I1009 09:44:22.876515  106124 factory.go:272] Factory "raw" can handle container "/system.slice/nginx.service", but ignoring.
I1009 09:44:22.876518  106124 manager.go:929] ignoring container "/system.slice/nginx.service"
I1009 09:44:22.876522  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/cloud-final.service"
I1009 09:44:22.876525  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/cloud-final.service"
I1009 09:44:22.876528  106124 factory.go:272] Factory "raw" can handle container "/system.slice/cloud-final.service", but ignoring.
I1009 09:44:22.876532  106124 manager.go:929] ignoring container "/system.slice/cloud-final.service"
I1009 09:44:22.876535  106124 factory.go:279] Factory "systemd" was unable to handle container "/user.slice/user-0.slice/user@0.service/app.slice"
I1009 09:44:22.876538  106124 factory.go:279] Factory "containerd" was unable to handle container "/user.slice/user-0.slice/user@0.service/app.slice"
I1009 09:44:22.876542  106124 factory.go:272] Factory "raw" can handle container "/user.slice/user-0.slice/user@0.service/app.slice", but ignoring.
I1009 09:44:22.876545  106124 manager.go:929] ignoring container "/user.slice/user-0.slice/user@0.service/app.slice"
I1009 09:44:22.876549  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/lxd-installer.socket"
I1009 09:44:22.876552  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/lxd-installer.socket"
I1009 09:44:22.876555  106124 factory.go:272] Factory "raw" can handle container "/system.slice/lxd-installer.socket", but ignoring.
I1009 09:44:22.876559  106124 manager.go:929] ignoring container "/system.slice/lxd-installer.socket"
I1009 09:44:22.876569  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/systemd-udevd.service/udev"
I1009 09:44:22.876573  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/systemd-udevd.service/udev"
I1009 09:44:22.876576  106124 factory.go:272] Factory "raw" can handle container "/system.slice/systemd-udevd.service/udev", but ignoring.
I1009 09:44:22.876579  106124 manager.go:929] ignoring container "/system.slice/systemd-udevd.service/udev"
I1009 09:44:22.876582  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/rsyslog.service"
I1009 09:44:22.876585  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/rsyslog.service"
I1009 09:44:22.876588  106124 factory.go:272] Factory "raw" can handle container "/system.slice/rsyslog.service", but ignoring.
I1009 09:44:22.876592  106124 manager.go:929] ignoring container "/system.slice/rsyslog.service"
I1009 09:44:22.876595  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/systemd-resolved.service"
I1009 09:44:22.876598  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/systemd-resolved.service"
I1009 09:44:22.876601  106124 factory.go:272] Factory "raw" can handle container "/system.slice/systemd-resolved.service", but ignoring.
I1009 09:44:22.876604  106124 manager.go:929] ignoring container "/system.slice/systemd-resolved.service"
I1009 09:44:22.876644  106124 factory.go:279] Factory "systemd" was unable to handle container "/user.slice/user-0.slice"
I1009 09:44:22.876647  106124 factory.go:279] Factory "containerd" was unable to handle container "/user.slice/user-0.slice"
I1009 09:44:22.876651  106124 factory.go:272] Factory "raw" can handle container "/user.slice/user-0.slice", but ignoring.
I1009 09:44:22.876654  106124 manager.go:929] ignoring container "/user.slice/user-0.slice"
I1009 09:44:22.876657  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/system-modprobe.slice"
I1009 09:44:22.876660  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/system-modprobe.slice"
I1009 09:44:22.876664  106124 factory.go:272] Factory "raw" can handle container "/system.slice/system-modprobe.slice", but ignoring.
I1009 09:44:22.876667  106124 manager.go:929] ignoring container "/system.slice/system-modprobe.slice"
I1009 09:44:22.876671  106124 factory.go:279] Factory "systemd" was unable to handle container "/runtime.slice/kubelet-20241009T094422.service"
I1009 09:44:22.876674  106124 factory.go:279] Factory "containerd" was unable to handle container "/runtime.slice/kubelet-20241009T094422.service"
I1009 09:44:22.876677  106124 factory.go:272] Factory "raw" can handle container "/runtime.slice/kubelet-20241009T094422.service", but ignoring.
I1009 09:44:22.876681  106124 manager.go:929] ignoring container "/runtime.slice/kubelet-20241009T094422.service"
I1009 09:44:22.876684  106124 factory.go:279] Factory "systemd" was unable to handle container "/user.slice/user-0.slice/user@0.service/app.slice/gpg-agent-ssh.socket"
I1009 09:44:22.876687  106124 factory.go:279] Factory "containerd" was unable to handle container "/user.slice/user-0.slice/user@0.service/app.slice/gpg-agent-ssh.socket"
I1009 09:44:22.876691  106124 factory.go:272] Factory "raw" can handle container "/user.slice/user-0.slice/user@0.service/app.slice/gpg-agent-ssh.socket", but ignoring.
I1009 09:44:22.876695  106124 manager.go:929] ignoring container "/user.slice/user-0.slice/user@0.service/app.slice/gpg-agent-ssh.socket"
I1009 09:44:22.876698  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/unattended-upgrades.service"
I1009 09:44:22.876701  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/unattended-upgrades.service"
I1009 09:44:22.876705  106124 factory.go:272] Factory "raw" can handle container "/system.slice/unattended-upgrades.service", but ignoring.
I1009 09:44:22.876708  106124 manager.go:929] ignoring container "/system.slice/unattended-upgrades.service"
I1009 09:44:22.876712  106124 factory.go:272] Factory "systemd" can handle container "/sys-fs-fuse-connections.mount", but ignoring.
I1009 09:44:22.876715  106124 manager.go:929] ignoring container "/sys-fs-fuse-connections.mount"
I1009 09:44:22.876718  106124 factory.go:279] Factory "systemd" was unable to handle container "/user.slice/user-0.slice/session-66.scope"
I1009 09:44:22.876721  106124 factory.go:279] Factory "containerd" was unable to handle container "/user.slice/user-0.slice/session-66.scope"
I1009 09:44:22.876725  106124 factory.go:272] Factory "raw" can handle container "/user.slice/user-0.slice/session-66.scope", but ignoring.
I1009 09:44:22.876728  106124 manager.go:929] ignoring container "/user.slice/user-0.slice/session-66.scope"
I1009 09:44:22.876732  106124 factory.go:279] Factory "systemd" was unable to handle container "/user.slice/user-0.slice/user@0.service"
I1009 09:44:22.876734  106124 factory.go:279] Factory "containerd" was unable to handle container "/user.slice/user-0.slice/user@0.service"
I1009 09:44:22.876738  106124 factory.go:272] Factory "raw" can handle container "/user.slice/user-0.slice/user@0.service", but ignoring.
I1009 09:44:22.876741  106124 manager.go:929] ignoring container "/user.slice/user-0.slice/user@0.service"
I1009 09:44:22.876745  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/snapd.socket"
I1009 09:44:22.876752  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/snapd.socket"
I1009 09:44:22.876755  106124 factory.go:272] Factory "raw" can handle container "/system.slice/snapd.socket", but ignoring.
I1009 09:44:22.876759  106124 manager.go:929] ignoring container "/system.slice/snapd.socket"
I1009 09:44:22.876762  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/cloud-init.service"
I1009 09:44:22.876765  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/cloud-init.service"
I1009 09:44:22.876769  106124 factory.go:272] Factory "raw" can handle container "/system.slice/cloud-init.service", but ignoring.
I1009 09:44:22.876773  106124 manager.go:929] ignoring container "/system.slice/cloud-init.service"
I1009 09:44:22.876776  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/systemd-timesyncd.service"
I1009 09:44:22.876779  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/systemd-timesyncd.service"
I1009 09:44:22.876783  106124 factory.go:272] Factory "raw" can handle container "/system.slice/systemd-timesyncd.service", but ignoring.
I1009 09:44:22.876786  106124 manager.go:929] ignoring container "/system.slice/systemd-timesyncd.service"
I1009 09:44:22.876790  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/systemd-logind.service"
I1009 09:44:22.876793  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/systemd-logind.service"
I1009 09:44:22.876796  106124 factory.go:272] Factory "raw" can handle container "/system.slice/systemd-logind.service", but ignoring.
I1009 09:44:22.876800  106124 manager.go:929] ignoring container "/system.slice/systemd-logind.service"
I1009 09:44:22.876803  106124 factory.go:272] Factory "systemd" can handle container "/dev-hugepages.mount", but ignoring.
I1009 09:44:22.876806  106124 manager.go:929] ignoring container "/dev-hugepages.mount"
I1009 09:44:22.876809  106124 factory.go:279] Factory "systemd" was unable to handle container "/runtime.slice"
I1009 09:44:22.876812  106124 factory.go:279] Factory "containerd" was unable to handle container "/runtime.slice"
I1009 09:44:22.876815  106124 factory.go:272] Factory "raw" can handle container "/runtime.slice", but ignoring.
I1009 09:44:22.876819  106124 manager.go:929] ignoring container "/runtime.slice"
I1009 09:44:22.876822  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice"
I1009 09:44:22.876825  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice"
I1009 09:44:22.876829  106124 factory.go:272] Factory "raw" can handle container "/system.slice", but ignoring.
I1009 09:44:22.876832  106124 manager.go:929] ignoring container "/system.slice"
I1009 09:44:22.876836  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/polkit.service"
I1009 09:44:22.876839  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/polkit.service"
I1009 09:44:22.876842  106124 factory.go:272] Factory "raw" can handle container "/system.slice/polkit.service", but ignoring.
I1009 09:44:22.876846  106124 manager.go:929] ignoring container "/system.slice/polkit.service"
I1009 09:44:22.876849  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/systemd-udevd.service"
I1009 09:44:22.876852  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/systemd-udevd.service"
I1009 09:44:22.876855  106124 factory.go:272] Factory "raw" can handle container "/system.slice/systemd-udevd.service", but ignoring.
I1009 09:44:22.876859  106124 manager.go:929] ignoring container "/system.slice/systemd-udevd.service"
I1009 09:44:22.876862  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/systemd-journald.service"
I1009 09:44:22.876868  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/systemd-journald.service"
I1009 09:44:22.876871  106124 factory.go:272] Factory "raw" can handle container "/system.slice/systemd-journald.service", but ignoring.
I1009 09:44:22.876875  106124 manager.go:929] ignoring container "/system.slice/systemd-journald.service"
I1009 09:44:22.876878  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/ssh.service"
I1009 09:44:22.876881  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/ssh.service"
I1009 09:44:22.876885  106124 factory.go:272] Factory "raw" can handle container "/system.slice/ssh.service", but ignoring.
I1009 09:44:22.876888  106124 manager.go:929] ignoring container "/system.slice/ssh.service"
I1009 09:44:22.876891  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/qemu-guest-agent.service"
I1009 09:44:22.876894  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/qemu-guest-agent.service"
I1009 09:44:22.876898  106124 factory.go:272] Factory "raw" can handle container "/system.slice/qemu-guest-agent.service", but ignoring.
I1009 09:44:22.876901  106124 manager.go:929] ignoring container "/system.slice/qemu-guest-agent.service"
I1009 09:44:22.876905  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/system-getty.slice"
I1009 09:44:22.876907  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/system-getty.slice"
I1009 09:44:22.876911  106124 factory.go:272] Factory "raw" can handle container "/system.slice/system-getty.slice", but ignoring.
I1009 09:44:22.876914  106124 manager.go:929] ignoring container "/system.slice/system-getty.slice"
I1009 09:44:22.876917  106124 factory.go:279] Factory "systemd" was unable to handle container "/user.slice/user-0.slice/user@0.service/app.slice/dbus.socket"
I1009 09:44:22.876920  106124 factory.go:279] Factory "containerd" was unable to handle container "/user.slice/user-0.slice/user@0.service/app.slice/dbus.socket"
I1009 09:44:22.876924  106124 factory.go:272] Factory "raw" can handle container "/user.slice/user-0.slice/user@0.service/app.slice/dbus.socket", but ignoring.
I1009 09:44:22.876928  106124 manager.go:929] ignoring container "/user.slice/user-0.slice/user@0.service/app.slice/dbus.socket"
I1009 09:44:22.876931  106124 factory.go:272] Factory "systemd" can handle container "/sys-kernel-tracing.mount", but ignoring.
I1009 09:44:22.876935  106124 manager.go:929] ignoring container "/sys-kernel-tracing.mount"
I1009 09:44:22.876958  106124 factory.go:272] Factory "systemd" can handle container "/system.slice/boot.mount", but ignoring.
I1009 09:44:22.876962  106124 manager.go:929] ignoring container "/system.slice/boot.mount"
I1009 09:44:22.876965  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/system-serial\\x2dgetty.slice"
I1009 09:44:22.876968  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/system-serial\\x2dgetty.slice"
I1009 09:44:22.876972  106124 factory.go:272] Factory "raw" can handle container "/system.slice/system-serial\\x2dgetty.slice", but ignoring.
I1009 09:44:22.876975  106124 manager.go:929] ignoring container "/system.slice/system-serial\\x2dgetty.slice"
I1009 09:44:22.876978  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/orthanc.service"
I1009 09:44:22.876981  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/orthanc.service"
I1009 09:44:22.876984  106124 factory.go:272] Factory "raw" can handle container "/system.slice/orthanc.service", but ignoring.
I1009 09:44:22.876988  106124 manager.go:929] ignoring container "/system.slice/orthanc.service"
I1009 09:44:22.876991  106124 factory.go:279] Factory "systemd" was unable to handle container "/user.slice/user-0.slice/user@0.service/init.scope"
I1009 09:44:22.877009  106124 factory.go:279] Factory "containerd" was unable to handle container "/user.slice/user-0.slice/user@0.service/init.scope"
I1009 09:44:22.877012  106124 factory.go:272] Factory "raw" can handle container "/user.slice/user-0.slice/user@0.service/init.scope", but ignoring.
I1009 09:44:22.877016  106124 manager.go:929] ignoring container "/user.slice/user-0.slice/user@0.service/init.scope"
I1009 09:44:22.877020  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/system-systemd\\x2dfsck.slice"
I1009 09:44:22.877023  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/system-systemd\\x2dfsck.slice"
I1009 09:44:22.877027  106124 factory.go:272] Factory "raw" can handle container "/system.slice/system-systemd\\x2dfsck.slice", but ignoring.
I1009 09:44:22.877031  106124 manager.go:929] ignoring container "/system.slice/system-systemd\\x2dfsck.slice"
I1009 09:44:22.877034  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/containerd.service"
I1009 09:44:22.877037  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/containerd.service"
I1009 09:44:22.877040  106124 factory.go:272] Factory "raw" can handle container "/system.slice/containerd.service", but ignoring.
I1009 09:44:22.877044  106124 manager.go:929] ignoring container "/system.slice/containerd.service"
I1009 09:44:22.877047  106124 factory.go:272] Factory "systemd" can handle container "/dev-mqueue.mount", but ignoring.
I1009 09:44:22.877050  106124 manager.go:929] ignoring container "/dev-mqueue.mount"
I1009 09:44:22.877054  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/system-getty.slice/getty@tty1.service"
I1009 09:44:22.877057  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/system-getty.slice/getty@tty1.service"
I1009 09:44:22.877060  106124 factory.go:272] Factory "raw" can handle container "/system.slice/system-getty.slice/getty@tty1.service", but ignoring.
I1009 09:44:22.877064  106124 manager.go:929] ignoring container "/system.slice/system-getty.slice/getty@tty1.service"
I1009 09:44:22.877067  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/cron.service"
I1009 09:44:22.877070  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/cron.service"
I1009 09:44:22.877073  106124 factory.go:272] Factory "raw" can handle container "/system.slice/cron.service", but ignoring.
I1009 09:44:22.877077  106124 manager.go:929] ignoring container "/system.slice/cron.service"
I1009 09:44:22.877080  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/udisks2.service"
I1009 09:44:22.877084  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/udisks2.service"
I1009 09:44:22.877087  106124 factory.go:272] Factory "raw" can handle container "/system.slice/udisks2.service", but ignoring.
I1009 09:44:22.877091  106124 manager.go:929] ignoring container "/system.slice/udisks2.service"
I1009 09:44:22.877094  106124 factory.go:272] Factory "systemd" can handle container "/system.slice/boot-efi.mount", but ignoring.
I1009 09:44:22.877098  106124 manager.go:929] ignoring container "/system.slice/boot-efi.mount"
I1009 09:44:22.877101  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/cloud-config.service"
I1009 09:44:22.877104  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/cloud-config.service"
I1009 09:44:22.877111  106124 factory.go:272] Factory "raw" can handle container "/system.slice/cloud-config.service", but ignoring.
I1009 09:44:22.877115  106124 manager.go:929] ignoring container "/system.slice/cloud-config.service"
I1009 09:44:22.877119  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/dbus.service"
I1009 09:44:22.877122  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/dbus.service"
I1009 09:44:22.877137  106124 factory.go:272] Factory "raw" can handle container "/system.slice/dbus.service", but ignoring.
I1009 09:44:22.877141  106124 manager.go:929] ignoring container "/system.slice/dbus.service"
I1009 09:44:22.877144  106124 factory.go:272] Factory "systemd" can handle container "/sys-kernel-config.mount", but ignoring.
I1009 09:44:22.877147  106124 manager.go:929] ignoring container "/sys-kernel-config.mount"
I1009 09:44:22.877151  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/ssh.socket"
I1009 09:44:22.877154  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/ssh.socket"
I1009 09:44:22.877157  106124 factory.go:272] Factory "raw" can handle container "/system.slice/ssh.socket", but ignoring.
I1009 09:44:22.877161  106124 manager.go:929] ignoring container "/system.slice/ssh.socket"
I1009 09:44:22.877164  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/cloud-init-local.service"
I1009 09:44:22.877167  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/cloud-init-local.service"
I1009 09:44:22.877170  106124 factory.go:272] Factory "raw" can handle container "/system.slice/cloud-init-local.service", but ignoring.
I1009 09:44:22.877174  106124 manager.go:929] ignoring container "/system.slice/cloud-init-local.service"
I1009 09:44:22.877177  106124 factory.go:272] Factory "systemd" can handle container "/sys-kernel-debug.mount", but ignoring.
I1009 09:44:22.877180  106124 manager.go:929] ignoring container "/sys-kernel-debug.mount"
I1009 09:44:22.877184  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/ModemManager.service"
I1009 09:44:22.877186  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/ModemManager.service"
I1009 09:44:22.877190  106124 factory.go:272] Factory "raw" can handle container "/system.slice/ModemManager.service", but ignoring.
I1009 09:44:22.877193  106124 manager.go:929] ignoring container "/system.slice/ModemManager.service"
I1009 09:44:22.877236  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/orthanc.service"
I1009 09:44:22.877247  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/orthanc.service"
I1009 09:44:22.877254  106124 factory.go:272] Factory "raw" can handle container "/system.slice/orthanc.service", but ignoring.
I1009 09:44:22.877261  106124 manager.go:929] ignoring container "/system.slice/orthanc.service"
I1009 09:44:22.877268  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/systemd-resolved.service"
I1009 09:44:22.877272  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/systemd-resolved.service"
I1009 09:44:22.877278  106124 factory.go:272] Factory "raw" can handle container "/system.slice/systemd-resolved.service", but ignoring.
I1009 09:44:22.877284  106124 manager.go:929] ignoring container "/system.slice/systemd-resolved.service"
I1009 09:44:22.877289  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/polkit.service"
I1009 09:44:22.877293  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/polkit.service"
I1009 09:44:22.877298  106124 factory.go:272] Factory "raw" can handle container "/system.slice/polkit.service", but ignoring.
I1009 09:44:22.877304  106124 manager.go:929] ignoring container "/system.slice/polkit.service"
I1009 09:44:22.877309  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/qemu-guest-agent.service"
I1009 09:44:22.877314  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/qemu-guest-agent.service"
I1009 09:44:22.877319  106124 factory.go:272] Factory "raw" can handle container "/system.slice/qemu-guest-agent.service", but ignoring.
I1009 09:44:22.877331  106124 manager.go:929] ignoring container "/system.slice/qemu-guest-agent.service"
I1009 09:44:22.877345  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/rsyslog.service"
I1009 09:44:22.877349  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/rsyslog.service"
I1009 09:44:22.877355  106124 factory.go:272] Factory "raw" can handle container "/system.slice/rsyslog.service", but ignoring.
I1009 09:44:22.877360  106124 manager.go:929] ignoring container "/system.slice/rsyslog.service"
I1009 09:44:22.877366  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/snapd.socket"
I1009 09:44:22.877370  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/snapd.socket"
I1009 09:44:22.877375  106124 factory.go:272] Factory "raw" can handle container "/system.slice/snapd.socket", but ignoring.
I1009 09:44:22.877381  106124 manager.go:929] ignoring container "/system.slice/snapd.socket"
I1009 09:44:22.877394  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/ssh.service"
I1009 09:44:22.877399  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/ssh.service"
I1009 09:44:22.877405  106124 factory.go:272] Factory "raw" can handle container "/system.slice/ssh.service", but ignoring.
I1009 09:44:22.877410  106124 manager.go:929] ignoring container "/system.slice/ssh.service"
I1009 09:44:22.877415  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/ssh.socket"
I1009 09:44:22.877419  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/ssh.socket"
I1009 09:44:22.877485  106124 factory.go:272] Factory "raw" can handle container "/system.slice/ssh.socket", but ignoring.
I1009 09:44:22.877496  106124 manager.go:929] ignoring container "/system.slice/ssh.socket"
I1009 09:44:22.877501  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/system-getty.slice/getty@tty1.service"
I1009 09:44:22.877506  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/system-getty.slice/getty@tty1.service"
I1009 09:44:22.877511  106124 factory.go:272] Factory "raw" can handle container "/system.slice/system-getty.slice/getty@tty1.service", but ignoring.
I1009 09:44:22.877516  106124 manager.go:929] ignoring container "/system.slice/system-getty.slice/getty@tty1.service"
I1009 09:44:22.877523  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/system-getty.slice"
I1009 09:44:22.877527  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/system-getty.slice"
I1009 09:44:22.877531  106124 factory.go:272] Factory "raw" can handle container "/system.slice/system-getty.slice", but ignoring.
I1009 09:44:22.877537  106124 manager.go:929] ignoring container "/system.slice/system-getty.slice"
I1009 09:44:22.877549  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/system-modprobe.slice"
I1009 09:44:22.877554  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/system-modprobe.slice"
I1009 09:44:22.877560  106124 factory.go:272] Factory "raw" can handle container "/system.slice/system-modprobe.slice", but ignoring.
I1009 09:44:22.877565  106124 manager.go:929] ignoring container "/system.slice/system-modprobe.slice"
I1009 09:44:22.877576  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/system-serial\\x2dgetty.slice/serial-getty@ttyS0.service"
I1009 09:44:22.877581  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/system-serial\\x2dgetty.slice/serial-getty@ttyS0.service"
I1009 09:44:22.877587  106124 factory.go:272] Factory "raw" can handle container "/system.slice/system-serial\\x2dgetty.slice/serial-getty@ttyS0.service", but ignoring.
I1009 09:44:22.877593  106124 manager.go:929] ignoring container "/system.slice/system-serial\\x2dgetty.slice/serial-getty@ttyS0.service"
I1009 09:44:22.877604  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/system-serial\\x2dgetty.slice"
I1009 09:44:22.877609  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/system-serial\\x2dgetty.slice"
I1009 09:44:22.877613  106124 factory.go:272] Factory "raw" can handle container "/system.slice/system-serial\\x2dgetty.slice", but ignoring.
I1009 09:44:22.877619  106124 manager.go:929] ignoring container "/system.slice/system-serial\\x2dgetty.slice"
I1009 09:44:22.877624  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/system-systemd\\x2dfsck.slice"
I1009 09:44:22.877628  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/system-systemd\\x2dfsck.slice"
I1009 09:44:22.877633  106124 factory.go:272] Factory "raw" can handle container "/system.slice/system-systemd\\x2dfsck.slice", but ignoring.
I1009 09:44:22.877639  106124 manager.go:929] ignoring container "/system.slice/system-systemd\\x2dfsck.slice"
I1009 09:44:22.877644  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/systemd-journald.service"
I1009 09:44:22.877648  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/systemd-journald.service"
I1009 09:44:22.877653  106124 factory.go:272] Factory "raw" can handle container "/system.slice/systemd-journald.service", but ignoring.
I1009 09:44:22.877658  106124 manager.go:929] ignoring container "/system.slice/systemd-journald.service"
I1009 09:44:22.877663  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/systemd-logind.service"
I1009 09:44:22.877667  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/systemd-logind.service"
I1009 09:44:22.877672  106124 factory.go:272] Factory "raw" can handle container "/system.slice/systemd-logind.service", but ignoring.
I1009 09:44:22.877684  106124 manager.go:929] ignoring container "/system.slice/systemd-logind.service"
I1009 09:44:22.877690  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/systemd-networkd.service"
I1009 09:44:22.877694  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/systemd-networkd.service"
I1009 09:44:22.877699  106124 factory.go:272] Factory "raw" can handle container "/system.slice/systemd-networkd.service", but ignoring.
I1009 09:44:22.877705  106124 manager.go:929] ignoring container "/system.slice/systemd-networkd.service"
I1009 09:44:22.877710  106124 factory.go:272] Factory "systemd" can handle container "/sys-kernel-debug.mount", but ignoring.
I1009 09:44:22.877715  106124 manager.go:929] ignoring container "/sys-kernel-debug.mount"
I1009 09:44:22.877720  106124 factory.go:272] Factory "systemd" can handle container "/sys-kernel-tracing.mount", but ignoring.
I1009 09:44:22.877725  106124 manager.go:929] ignoring container "/sys-kernel-tracing.mount"
I1009 09:44:22.877731  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/ModemManager.service"
I1009 09:44:22.877736  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/ModemManager.service"
I1009 09:44:22.877740  106124 factory.go:272] Factory "raw" can handle container "/system.slice/ModemManager.service", but ignoring.
I1009 09:44:22.877746  106124 manager.go:929] ignoring container "/system.slice/ModemManager.service"
I1009 09:44:22.877751  106124 factory.go:272] Factory "systemd" can handle container "/system.slice/boot-efi.mount", but ignoring.
I1009 09:44:22.877757  106124 manager.go:929] ignoring container "/system.slice/boot-efi.mount"
I1009 09:44:22.877762  106124 factory.go:272] Factory "systemd" can handle container "/system.slice/boot.mount", but ignoring.
I1009 09:44:22.877766  106124 manager.go:929] ignoring container "/system.slice/boot.mount"
I1009 09:44:22.877775  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/cloud-config.service"
I1009 09:44:22.877780  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/cloud-config.service"
I1009 09:44:22.877784  106124 factory.go:272] Factory "raw" can handle container "/system.slice/cloud-config.service", but ignoring.
I1009 09:44:22.877790  106124 manager.go:929] ignoring container "/system.slice/cloud-config.service"
I1009 09:44:22.877795  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/cloud-final.service"
I1009 09:44:22.877800  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/cloud-final.service"
I1009 09:44:22.877805  106124 factory.go:272] Factory "raw" can handle container "/system.slice/cloud-final.service", but ignoring.
I1009 09:44:22.877810  106124 manager.go:929] ignoring container "/system.slice/cloud-final.service"
I1009 09:44:22.877816  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/cloud-init-local.service"
I1009 09:44:22.877820  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/cloud-init-local.service"
I1009 09:44:22.877822  106124 reflector.go:368] Caches populated for *v1.RuntimeClass from k8s.io/client-go/informers/factory.go:160
I1009 09:44:22.877824  106124 factory.go:272] Factory "raw" can handle container "/system.slice/cloud-init-local.service", but ignoring.
I1009 09:44:22.877929  106124 manager.go:929] ignoring container "/system.slice/cloud-init-local.service"
I1009 09:44:22.877940  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/cloud-init.service"
I1009 09:44:22.877945  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/cloud-init.service"
I1009 09:44:22.877951  106124 factory.go:272] Factory "raw" can handle container "/system.slice/cloud-init.service", but ignoring.
I1009 09:44:22.877958  106124 manager.go:929] ignoring container "/system.slice/cloud-init.service"
I1009 09:44:22.877974  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/containerd.service"
I1009 09:44:22.877979  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/containerd.service"
I1009 09:44:22.877984  106124 factory.go:272] Factory "raw" can handle container "/system.slice/containerd.service", but ignoring.
I1009 09:44:22.877990  106124 manager.go:929] ignoring container "/system.slice/containerd.service"
I1009 09:44:22.877995  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/cron.service"
I1009 09:44:22.878000  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/cron.service"
I1009 09:44:22.878005  106124 factory.go:272] Factory "raw" can handle container "/system.slice/cron.service", but ignoring.
I1009 09:44:22.878016  106124 manager.go:929] ignoring container "/system.slice/cron.service"
I1009 09:44:22.878022  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/dbus.service"
I1009 09:44:22.878027  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/dbus.service"
I1009 09:44:22.878032  106124 factory.go:272] Factory "raw" can handle container "/system.slice/dbus.service", but ignoring.
I1009 09:44:22.878037  106124 manager.go:929] ignoring container "/system.slice/dbus.service"
I1009 09:44:22.878042  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/lxd-installer.socket"
I1009 09:44:22.878047  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/lxd-installer.socket"
I1009 09:44:22.878052  106124 factory.go:272] Factory "raw" can handle container "/system.slice/lxd-installer.socket", but ignoring.
I1009 09:44:22.878057  106124 manager.go:929] ignoring container "/system.slice/lxd-installer.socket"
I1009 09:44:22.878069  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/multipathd.service"
I1009 09:44:22.878073  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/multipathd.service"
I1009 09:44:22.878077  106124 factory.go:272] Factory "raw" can handle container "/system.slice/multipathd.service", but ignoring.
I1009 09:44:22.878082  106124 manager.go:929] ignoring container "/system.slice/multipathd.service"
I1009 09:44:22.878091  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/nginx.service"
I1009 09:44:22.878095  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/nginx.service"
I1009 09:44:22.878100  106124 factory.go:272] Factory "raw" can handle container "/system.slice/nginx.service", but ignoring.
I1009 09:44:22.878106  106124 manager.go:929] ignoring container "/system.slice/nginx.service"
I1009 09:44:22.878112  106124 factory.go:272] Factory "systemd" can handle container "/dev-hugepages.mount", but ignoring.
I1009 09:44:22.878117  106124 manager.go:929] ignoring container "/dev-hugepages.mount"
I1009 09:44:22.878122  106124 factory.go:272] Factory "systemd" can handle container "/dev-mqueue.mount", but ignoring.
I1009 09:44:22.878126  106124 manager.go:929] ignoring container "/dev-mqueue.mount"
I1009 09:44:22.878131  106124 factory.go:279] Factory "systemd" was unable to handle container "/init.scope"
I1009 09:44:22.878135  106124 factory.go:279] Factory "containerd" was unable to handle container "/init.scope"
I1009 09:44:22.878140  106124 factory.go:272] Factory "raw" can handle container "/init.scope", but ignoring.
I1009 09:44:22.878145  106124 manager.go:929] ignoring container "/init.scope"
I1009 09:44:22.878151  106124 factory.go:279] Factory "systemd" was unable to handle container "/user.slice/user-0.slice/session-78.scope"
I1009 09:44:22.878165  106124 factory.go:279] Factory "containerd" was unable to handle container "/user.slice/user-0.slice/session-78.scope"
I1009 09:44:22.878170  106124 factory.go:272] Factory "raw" can handle container "/user.slice/user-0.slice/session-78.scope", but ignoring.
I1009 09:44:22.878175  106124 manager.go:929] ignoring container "/user.slice/user-0.slice/session-78.scope"
I1009 09:44:22.878180  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/systemd-timesyncd.service"
I1009 09:44:22.878185  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/systemd-timesyncd.service"
I1009 09:44:22.878190  106124 factory.go:272] Factory "raw" can handle container "/system.slice/systemd-timesyncd.service", but ignoring.
I1009 09:44:22.878195  106124 manager.go:929] ignoring container "/system.slice/systemd-timesyncd.service"
I1009 09:44:22.878199  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/systemd-udevd.service/udev"
I1009 09:44:22.878203  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/systemd-udevd.service/udev"
I1009 09:44:22.878208  106124 factory.go:272] Factory "raw" can handle container "/system.slice/systemd-udevd.service/udev", but ignoring.
I1009 09:44:22.878213  106124 manager.go:929] ignoring container "/system.slice/systemd-udevd.service/udev"
I1009 09:44:22.878218  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/systemd-udevd.service"
I1009 09:44:22.878222  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/systemd-udevd.service"
I1009 09:44:22.878228  106124 factory.go:272] Factory "raw" can handle container "/system.slice/systemd-udevd.service", but ignoring.
I1009 09:44:22.878232  106124 manager.go:929] ignoring container "/system.slice/systemd-udevd.service"
I1009 09:44:22.878237  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/udisks2.service"
I1009 09:44:22.878241  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/udisks2.service"
I1009 09:44:22.878250  106124 factory.go:272] Factory "raw" can handle container "/system.slice/udisks2.service", but ignoring.
I1009 09:44:22.878256  106124 manager.go:929] ignoring container "/system.slice/udisks2.service"
I1009 09:44:22.878260  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/unattended-upgrades.service"
I1009 09:44:22.878264  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/unattended-upgrades.service"
I1009 09:44:22.878269  106124 factory.go:272] Factory "raw" can handle container "/system.slice/unattended-upgrades.service", but ignoring.
I1009 09:44:22.878274  106124 manager.go:929] ignoring container "/system.slice/unattended-upgrades.service"
I1009 09:44:22.878279  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice"
I1009 09:44:22.878283  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice"
I1009 09:44:22.878288  106124 factory.go:272] Factory "raw" can handle container "/system.slice", but ignoring.
I1009 09:44:22.878293  106124 manager.go:929] ignoring container "/system.slice"
I1009 09:44:22.878298  106124 factory.go:279] Factory "systemd" was unable to handle container "/user.slice/user-0.slice/session-66.scope"
I1009 09:44:22.878302  106124 factory.go:279] Factory "containerd" was unable to handle container "/user.slice/user-0.slice/session-66.scope"
I1009 09:44:22.878307  106124 factory.go:272] Factory "raw" can handle container "/user.slice/user-0.slice/session-66.scope", but ignoring.
I1009 09:44:22.878313  106124 manager.go:929] ignoring container "/user.slice/user-0.slice/session-66.scope"
I1009 09:44:22.878318  106124 factory.go:279] Factory "systemd" was unable to handle container "/runtime.slice/kubelet-20241009T094422.service"
I1009 09:44:22.878322  106124 factory.go:279] Factory "containerd" was unable to handle container "/runtime.slice/kubelet-20241009T094422.service"
I1009 09:44:22.878334  106124 factory.go:272] Factory "raw" can handle container "/runtime.slice/kubelet-20241009T094422.service", but ignoring.
I1009 09:44:22.878339  106124 manager.go:929] ignoring container "/runtime.slice/kubelet-20241009T094422.service"
I1009 09:44:22.878343  106124 factory.go:272] Factory "systemd" can handle container "/proc-sys-fs-binfmt_misc.mount", but ignoring.
I1009 09:44:22.878348  106124 manager.go:929] ignoring container "/proc-sys-fs-binfmt_misc.mount"
I1009 09:44:22.878352  106124 factory.go:272] Factory "systemd" can handle container "/sys-fs-fuse-connections.mount", but ignoring.
I1009 09:44:22.878356  106124 manager.go:929] ignoring container "/sys-fs-fuse-connections.mount"
I1009 09:44:22.878361  106124 factory.go:279] Factory "systemd" was unable to handle container "/runtime.slice"
I1009 09:44:22.878365  106124 factory.go:279] Factory "containerd" was unable to handle container "/runtime.slice"
I1009 09:44:22.878370  106124 factory.go:272] Factory "raw" can handle container "/runtime.slice", but ignoring.
I1009 09:44:22.878375  106124 manager.go:929] ignoring container "/runtime.slice"
I1009 09:44:22.878380  106124 factory.go:272] Factory "systemd" can handle container "/sys-kernel-config.mount", but ignoring.
I1009 09:44:22.878386  106124 manager.go:929] ignoring container "/sys-kernel-config.mount"
I1009 09:44:22.878390  106124 factory.go:279] Factory "systemd" was unable to handle container "/user.slice/user-0.slice/user@0.service/init.scope"
I1009 09:44:22.878395  106124 factory.go:279] Factory "containerd" was unable to handle container "/user.slice/user-0.slice/user@0.service/init.scope"
I1009 09:44:22.878400  106124 factory.go:272] Factory "raw" can handle container "/user.slice/user-0.slice/user@0.service/init.scope", but ignoring.
I1009 09:44:22.878406  106124 manager.go:929] ignoring container "/user.slice/user-0.slice/user@0.service/init.scope"
I1009 09:44:22.878412  106124 factory.go:279] Factory "systemd" was unable to handle container "/user.slice/user-0.slice/user@0.service/app.slice/dbus.socket"
I1009 09:44:22.878480  106124 factory.go:279] Factory "containerd" was unable to handle container "/user.slice/user-0.slice/user@0.service/app.slice/dbus.socket"
I1009 09:44:22.878492  106124 factory.go:272] Factory "raw" can handle container "/user.slice/user-0.slice/user@0.service/app.slice/dbus.socket", but ignoring.
I1009 09:44:22.878498  106124 manager.go:929] ignoring container "/user.slice/user-0.slice/user@0.service/app.slice/dbus.socket"
I1009 09:44:22.878504  106124 factory.go:279] Factory "systemd" was unable to handle container "/user.slice/user-0.slice/user@0.service/app.slice/gpg-agent-ssh.socket"
I1009 09:44:22.878509  106124 factory.go:279] Factory "containerd" was unable to handle container "/user.slice/user-0.slice/user@0.service/app.slice/gpg-agent-ssh.socket"
I1009 09:44:22.878514  106124 factory.go:272] Factory "raw" can handle container "/user.slice/user-0.slice/user@0.service/app.slice/gpg-agent-ssh.socket", but ignoring.
I1009 09:44:22.878520  106124 manager.go:929] ignoring container "/user.slice/user-0.slice/user@0.service/app.slice/gpg-agent-ssh.socket"
I1009 09:44:22.878525  106124 factory.go:279] Factory "systemd" was unable to handle container "/user.slice/user-0.slice/user@0.service/app.slice"
I1009 09:44:22.878529  106124 factory.go:279] Factory "containerd" was unable to handle container "/user.slice/user-0.slice/user@0.service/app.slice"
I1009 09:44:22.878534  106124 factory.go:272] Factory "raw" can handle container "/user.slice/user-0.slice/user@0.service/app.slice", but ignoring.
I1009 09:44:22.878542  106124 manager.go:929] ignoring container "/user.slice/user-0.slice/user@0.service/app.slice"
I1009 09:44:22.878547  106124 factory.go:279] Factory "systemd" was unable to handle container "/user.slice/user-0.slice"
I1009 09:44:22.878554  106124 factory.go:279] Factory "containerd" was unable to handle container "/user.slice/user-0.slice"
I1009 09:44:22.878559  106124 factory.go:272] Factory "raw" can handle container "/user.slice/user-0.slice", but ignoring.
I1009 09:44:22.878564  106124 manager.go:929] ignoring container "/user.slice/user-0.slice"
I1009 09:44:22.878569  106124 factory.go:279] Factory "systemd" was unable to handle container "/user.slice/user-0.slice/user@0.service"
I1009 09:44:22.878583  106124 factory.go:279] Factory "containerd" was unable to handle container "/user.slice/user-0.slice/user@0.service"
I1009 09:44:22.878589  106124 factory.go:272] Factory "raw" can handle container "/user.slice/user-0.slice/user@0.service", but ignoring.
I1009 09:44:22.878594  106124 manager.go:929] ignoring container "/user.slice/user-0.slice/user@0.service"
I1009 09:44:22.878600  106124 factory.go:279] Factory "systemd" was unable to handle container "/user.slice"
I1009 09:44:22.878604  106124 factory.go:279] Factory "containerd" was unable to handle container "/user.slice"
I1009 09:44:22.878608  106124 factory.go:272] Factory "raw" can handle container "/user.slice", but ignoring.
I1009 09:44:22.878613  106124 manager.go:929] ignoring container "/user.slice"
I1009 09:44:22.878894  106124 kubelet_node_status.go:367] "Setting node annotation to enable volume controller attach/detach"
I1009 09:44:22.879519  106124 nodeinfomanager.go:402] Failed to publish CSINode: nodes "srv579909" not found
I1009 09:44:22.879688  106124 interface.go:432] Looking for default routes with IPv4 addresses
I1009 09:44:22.879696  106124 interface.go:437] Default route transits interface "eth0"
I1009 09:44:22.879781  106124 interface.go:209] Interface eth0 is up
I1009 09:44:22.879825  106124 interface.go:257] Interface "eth0" has 3 addresses :[82.112.230.236/24 2a02:4780:12:eebf::1/48 fe80::be24:11ff:fe5a:b1d8/64].
I1009 09:44:22.879864  106124 interface.go:224] Checking addr  82.112.230.236/24.
I1009 09:44:22.879870  106124 interface.go:231] IP found 82.112.230.236
I1009 09:44:22.879887  106124 interface.go:263] Found valid IPv4 address 82.112.230.236 for interface "eth0".
I1009 09:44:22.879892  106124 interface.go:443] Found active IP 82.112.230.236 
I1009 09:44:22.880237  106124 kubelet_node_status.go:686] "Recording event message for node" node="srv579909" event="NodeHasSufficientMemory"
I1009 09:44:22.880268  106124 kubelet_node_status.go:686] "Recording event message for node" node="srv579909" event="NodeHasNoDiskPressure"
I1009 09:44:22.880277  106124 kubelet_node_status.go:686] "Recording event message for node" node="srv579909" event="NodeHasSufficientPID"
I1009 09:44:22.880335  106124 event.go:389] "Event occurred" object="srv579909" fieldPath="" kind="Node" apiVersion="" type="Normal" reason="NodeHasSufficientMemory" message="Node srv579909 status is now: NodeHasSufficientMemory"
I1009 09:44:22.880345  106124 event.go:389] "Event occurred" object="srv579909" fieldPath="" kind="Node" apiVersion="" type="Normal" reason="NodeHasNoDiskPressure" message="Node srv579909 status is now: NodeHasNoDiskPressure"
I1009 09:44:22.880349  106124 event.go:389] "Event occurred" object="srv579909" fieldPath="" kind="Node" apiVersion="" type="Normal" reason="NodeHasSufficientPID" message="Node srv579909 status is now: NodeHasSufficientPID"
I1009 09:44:22.881047  106124 cpu_manager.go:214] "Starting CPU manager" policy="none"
I1009 09:44:22.881059  106124 cpu_manager.go:215] "Reconciling" reconcilePeriod="10s"
I1009 09:44:22.881074  106124 state_mem.go:36] "Initialized new in-memory state store"
I1009 09:44:22.881194  106124 state_mem.go:88] "Updated default CPUSet" cpuSet=""
I1009 09:44:22.881208  106124 state_mem.go:96] "Updated CPUSet assignments" assignments={}
I1009 09:44:22.881227  106124 state_checkpoint.go:136] "State checkpoint: restored state from checkpoint"
I1009 09:44:22.881233  106124 state_checkpoint.go:137] "State checkpoint: defaultCPUSet" defaultCpuSet=""
I1009 09:44:22.881239  106124 policy_none.go:49] "None policy: Start"
I1009 09:44:22.881754  106124 memory_manager.go:170] "Starting memorymanager" policy="None"
I1009 09:44:22.881771  106124 state_mem.go:35] "Initializing new in-memory state store"
I1009 09:44:22.881873  106124 state_mem.go:75] "Updated machine memory state"
I1009 09:44:22.881879  106124 state_checkpoint.go:82] "State checkpoint: restored state from checkpoint"
I1009 09:44:22.882350  106124 node_container_manager_linux.go:80] "Attempting to enforce Node Allocatable" config={"KubeReservedCgroupName":"","SystemReservedCgroupName":"","ReservedSystemCPUs":{},"EnforceNodeAllocatable":{"pods":{}},"KubeReserved":null,"SystemReserved":null,"HardEvictionThresholds":[{"Signal":"nodefs.available","Operator":"LessThan","Value":{"Quantity":null,"Percentage":0.1},"GracePeriod":0,"MinReclaim":null},{"Signal":"nodefs.inodesFree","Operator":"LessThan","Value":{"Quantity":null,"Percentage":0.05},"GracePeriod":0,"MinReclaim":null},{"Signal":"memory.available","Operator":"LessThan","Value":{"Quantity":"250Mi","Percentage":0},"GracePeriod":0,"MinReclaim":null}]}
I1009 09:44:22.882394  106124 manager.go:341] "Starting Device Plugin manager"
I1009 09:44:22.882408  106124 manager.go:520] "Failed to read data from checkpoint" checkpoint="kubelet_internal_checkpoint" err="checkpoint is not found"
I1009 09:44:22.882416  106124 server.go:79] "Starting device plugin registration server"
I1009 09:44:22.882590  106124 eviction_manager.go:189] "Eviction manager: starting control loop"
I1009 09:44:22.882599  106124 container_log_manager.go:189] "Initializing container log rotate workers" workers=1 monitorPeriod="10s"
I1009 09:44:22.882616  106124 kubelet.go:1586] "Starting plugin manager"
I1009 09:44:22.882689  106124 qos_container_manager_linux.go:383] "Updated QoS cgroup configuration"
I1009 09:44:22.882715  106124 eviction_manager.go:251] "Eviction manager: synchronize housekeeping"
I1009 09:44:22.882786  106124 event.go:389] "Event occurred" object="srv579909" fieldPath="" kind="Node" apiVersion="" type="Normal" reason="NodeAllocatableEnforced" message="Updated Node Allocatable limit across pods"
I1009 09:44:22.882798  106124 container_log_manager.go:229] "Starting container log rotation worker" workerID=1
I1009 09:44:22.882826  106124 container_log_manager.go:238] "Starting container log rotation sequence"
I1009 09:44:22.882892  106124 plugin_watcher.go:51] "Plugin Watcher Start" path="/var/lib/kubelet/plugins_registry"
I1009 09:44:22.882898  106124 plugin_watcher.go:100] "Ensuring Plugin directory" path="/var/lib/kubelet/plugins_registry"
I1009 09:44:22.882968  106124 plugin_manager.go:116] "The desired_state_of_world populator (plugin watcher) starts"
I1009 09:44:22.882972  106124 plugin_manager.go:118] "Starting Kubelet Plugin Manager"
I1009 09:44:22.883477  106124 kubelet.go:2898] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:; Handlers: , Features: nil"
I1009 09:44:22.884064  106124 eviction_manager.go:280] "FileSystem detection" DedicatedImageFs=false SplitImageFs=false
E1009 09:44:22.884083  106124 eviction_manager.go:285] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"srv579909\" not found"
I1009 09:44:22.886645  106124 oom_linux.go:65] attempting to set "/proc/106124/oom_score_adj" to "-999"
I1009 09:44:22.937030  106124 nodeinfomanager.go:402] Failed to publish CSINode: nodes "srv579909" not found
I1009 09:44:22.972525  106124 kubelet.go:2410] "SyncLoop ADD" source="file" pods=[]
I1009 09:44:22.972600  106124 kubelet.go:2446] "SyncLoop (PLEG): pod does not exist, ignore irrelevant event" event={"ID":"c7e58e54-59be-492a-8089-bf628cce8a30","Type":"ContainerDied","Data":"a4fe23cc464877e9d3bc6c1826e24fa4b80f81e9eb51fd13324ddd4492e45e26"}
I1009 09:44:22.972706  106124 kubelet.go:2446] "SyncLoop (PLEG): pod does not exist, ignore irrelevant event" event={"ID":"c7e58e54-59be-492a-8089-bf628cce8a30","Type":"ContainerDied","Data":"d2140c7c68378b3ca1e26ec4ba9259a41b6f0b815b2c7dfef672e7467f4b897e"}
I1009 09:44:22.972723  106124 pod_container_deletor.go:80] "Container not found in pod's containers" containerID="d2140c7c68378b3ca1e26ec4ba9259a41b6f0b815b2c7dfef672e7467f4b897e"
I1009 09:44:22.983736  106124 kubelet_node_status.go:367] "Setting node annotation to enable volume controller attach/detach"
I1009 09:44:22.984035  106124 interface.go:432] Looking for default routes with IPv4 addresses
I1009 09:44:22.984046  106124 interface.go:437] Default route transits interface "eth0"
I1009 09:44:22.984162  106124 interface.go:209] Interface eth0 is up
I1009 09:44:22.984222  106124 interface.go:257] Interface "eth0" has 3 addresses :[82.112.230.236/24 2a02:4780:12:eebf::1/48 fe80::be24:11ff:fe5a:b1d8/64].
I1009 09:44:22.984234  106124 interface.go:224] Checking addr  82.112.230.236/24.
I1009 09:44:22.984240  106124 interface.go:231] IP found 82.112.230.236
I1009 09:44:22.984245  106124 interface.go:263] Found valid IPv4 address 82.112.230.236 for interface "eth0".
I1009 09:44:22.984250  106124 interface.go:443] Found active IP 82.112.230.236 
I1009 09:44:22.985242  106124 kubelet_node_status.go:686] "Recording event message for node" node="srv579909" event="NodeHasSufficientMemory"
I1009 09:44:22.985361  106124 kubelet_node_status.go:686] "Recording event message for node" node="srv579909" event="NodeHasNoDiskPressure"
I1009 09:44:22.985375  106124 kubelet_node_status.go:686] "Recording event message for node" node="srv579909" event="NodeHasSufficientPID"
I1009 09:44:22.985410  106124 kubelet_node_status.go:74] "Attempting to register node" node="srv579909"
I1009 09:44:22.986022  106124 event.go:389] "Event occurred" object="srv579909" fieldPath="" kind="Node" apiVersion="" type="Normal" reason="NodeHasSufficientMemory" message="Node srv579909 status is now: NodeHasSufficientMemory"
I1009 09:44:22.986071  106124 event.go:389] "Event occurred" object="srv579909" fieldPath="" kind="Node" apiVersion="" type="Normal" reason="NodeHasNoDiskPressure" message="Node srv579909 status is now: NodeHasNoDiskPressure"
I1009 09:44:22.986077  106124 event.go:389] "Event occurred" object="srv579909" fieldPath="" kind="Node" apiVersion="" type="Normal" reason="NodeHasSufficientPID" message="Node srv579909 status is now: NodeHasSufficientPID"
I1009 09:44:22.988669  106124 kubelet_node_status.go:77] "Successfully registered node" node="srv579909"
I1009 09:44:22.988903  106124 interface.go:432] Looking for default routes with IPv4 addresses
I1009 09:44:22.988911  106124 interface.go:437] Default route transits interface "eth0"
I1009 09:44:22.988991  106124 interface.go:209] Interface eth0 is up
I1009 09:44:22.989038  106124 interface.go:257] Interface "eth0" has 3 addresses :[82.112.230.236/24 2a02:4780:12:eebf::1/48 fe80::be24:11ff:fe5a:b1d8/64].
I1009 09:44:22.989049  106124 interface.go:224] Checking addr  82.112.230.236/24.
I1009 09:44:22.989056  106124 interface.go:231] IP found 82.112.230.236
I1009 09:44:22.989062  106124 interface.go:263] Found valid IPv4 address 82.112.230.236 for interface "eth0".
I1009 09:44:22.989068  106124 interface.go:443] Found active IP 82.112.230.236 
I1009 09:44:22.994252  106124 kubelet.go:2898] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:; Handlers: , Features: nil"
I1009 09:44:22.994536  106124 interface.go:432] Looking for default routes with IPv4 addresses
I1009 09:44:22.994549  106124 interface.go:437] Default route transits interface "eth0"
I1009 09:44:22.994661  106124 interface.go:209] Interface eth0 is up
I1009 09:44:22.994711  106124 interface.go:257] Interface "eth0" has 3 addresses :[82.112.230.236/24 2a02:4780:12:eebf::1/48 fe80::be24:11ff:fe5a:b1d8/64].
I1009 09:44:22.994723  106124 interface.go:224] Checking addr  82.112.230.236/24.
I1009 09:44:22.994731  106124 interface.go:231] IP found 82.112.230.236
I1009 09:44:22.994737  106124 interface.go:263] Found valid IPv4 address 82.112.230.236 for interface "eth0".
I1009 09:44:22.994743  106124 interface.go:443] Found active IP 82.112.230.236 
I1009 09:44:23.096268  106124 kubelet.go:2898] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:; Handlers: , Features: nil"
I1009 09:44:23.097361  106124 interface.go:432] Looking for default routes with IPv4 addresses
I1009 09:44:23.097394  106124 interface.go:437] Default route transits interface "eth0"
I1009 09:44:23.097580  106124 interface.go:209] Interface eth0 is up
I1009 09:44:23.097621  106124 interface.go:257] Interface "eth0" has 3 addresses :[82.112.230.236/24 2a02:4780:12:eebf::1/48 fe80::be24:11ff:fe5a:b1d8/64].
I1009 09:44:23.097643  106124 interface.go:224] Checking addr  82.112.230.236/24.
I1009 09:44:23.097651  106124 interface.go:231] IP found 82.112.230.236
I1009 09:44:23.097656  106124 interface.go:263] Found valid IPv4 address 82.112.230.236 for interface "eth0".
I1009 09:44:23.097660  106124 interface.go:443] Found active IP 82.112.230.236 
I1009 09:44:23.199342  106124 kubelet.go:2898] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:; Handlers: , Features: nil"
I1009 09:44:23.199638  106124 interface.go:432] Looking for default routes with IPv4 addresses
I1009 09:44:23.199650  106124 interface.go:437] Default route transits interface "eth0"
I1009 09:44:23.199748  106124 interface.go:209] Interface eth0 is up
I1009 09:44:23.199785  106124 interface.go:257] Interface "eth0" has 3 addresses :[82.112.230.236/24 2a02:4780:12:eebf::1/48 fe80::be24:11ff:fe5a:b1d8/64].
I1009 09:44:23.199795  106124 interface.go:224] Checking addr  82.112.230.236/24.
I1009 09:44:23.199801  106124 interface.go:231] IP found 82.112.230.236
I1009 09:44:23.199805  106124 interface.go:263] Found valid IPv4 address 82.112.230.236 for interface "eth0".
I1009 09:44:23.199809  106124 interface.go:443] Found active IP 82.112.230.236 
I1009 09:44:23.301404  106124 kubelet.go:2898] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:; Handlers: , Features: nil"
I1009 09:44:23.301728  106124 interface.go:432] Looking for default routes with IPv4 addresses
I1009 09:44:23.301744  106124 interface.go:437] Default route transits interface "eth0"
I1009 09:44:23.301933  106124 interface.go:209] Interface eth0 is up
I1009 09:44:23.301988  106124 interface.go:257] Interface "eth0" has 3 addresses :[82.112.230.236/24 2a02:4780:12:eebf::1/48 fe80::be24:11ff:fe5a:b1d8/64].
I1009 09:44:23.302029  106124 interface.go:224] Checking addr  82.112.230.236/24.
I1009 09:44:23.302048  106124 interface.go:231] IP found 82.112.230.236
I1009 09:44:23.302083  106124 interface.go:263] Found valid IPv4 address 82.112.230.236 for interface "eth0".
I1009 09:44:23.302105  106124 interface.go:443] Found active IP 82.112.230.236 
I1009 09:44:23.302920  106124 kubelet_node_status.go:686] "Recording event message for node" node="srv579909" event="NodeReady"
I1009 09:44:23.303018  106124 kubelet_node_status.go:500] "Fast updating node status as it just became ready"
I1009 09:44:23.303101  106124 event.go:389] "Event occurred" object="srv579909" fieldPath="" kind="Node" apiVersion="" type="Normal" reason="NodeReady" message="Node srv579909 status is now: NodeReady"
I1009 09:44:23.825264  106124 httplog.go:134] "HTTP" verb="GET" URI="/configz" latency="342.384µs" userAgent="Go-http-client/1.1" audit-ID="" srcIP="82.112.230.236:56608" resp=200
I1009 09:44:23.840929  106124 httplog.go:134] "HTTP" verb="GET" URI="/configz" latency="240.681µs" userAgent="Go-http-client/1.1" audit-ID="" srcIP="82.112.230.236:56608" resp=200
I1009 09:44:23.841370  106124 httplog.go:134] "HTTP" verb="GET" URI="/configz" latency="93.33µs" userAgent="Go-http-client/1.1" audit-ID="" srcIP="82.112.230.236:56608" resp=200
I1009 09:44:23.850052  106124 httplog.go:134] "HTTP" verb="GET" URI="/configz" latency="162.59µs" userAgent="Go-http-client/1.1" audit-ID="" srcIP="82.112.230.236:56608" resp=200
I1009 09:44:23.850254  106124 apiserver.go:50] "node sync has not completed yet"
I1009 09:44:23.850284  106124 apiserver.go:46] "node sync completed"
I1009 09:44:23.850288  106124 apiserver.go:52] "Watching apiserver"
I1009 09:44:23.850421  106124 reflector.go:305] Starting reflector *v1.Pod (0s) from pkg/kubelet/config/apiserver.go:66
I1009 09:44:23.850490  106124 reflector.go:341] Listing and watching *v1.Pod from pkg/kubelet/config/apiserver.go:66
I1009 09:44:23.853310  106124 httplog.go:134] "HTTP" verb="GET" URI="/configz" latency="138.851µs" userAgent="Go-http-client/1.1" audit-ID="" srcIP="82.112.230.236:56608" resp=200
I1009 09:44:23.854075  106124 reflector.go:368] Caches populated for *v1.Pod from pkg/kubelet/config/apiserver.go:66
I1009 09:44:23.854177  106124 config.go:292] "Setting pods for source" source="api"
I1009 09:44:23.854252  106124 kubelet.go:2410] "SyncLoop ADD" source="api" pods=[]
I1009 09:44:23.877680  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:44:23.904507  106124 httplog.go:134] "HTTP" verb="GET" URI="/configz" latency="319.002µs" userAgent="Go-http-client/1.1" audit-ID="" srcIP="82.112.230.236:56608" resp=200
I1009 09:44:23.917157  106124 httplog.go:134] "HTTP" verb="GET" URI="/configz" latency="247.252µs" userAgent="Go-http-client/1.1" audit-ID="" srcIP="82.112.230.236:56608" resp=200
I1009 09:44:23.922960  106124 httplog.go:134] "HTTP" verb="GET" URI="/configz" latency="137.241µs" userAgent="Go-http-client/1.1" audit-ID="" srcIP="82.112.230.236:56608" resp=200
I1009 09:44:23.953821  106124 desired_state_of_world_populator.go:155] "Finished populating initial desired state of world"
I1009 09:44:23.965882  106124 config.go:292] "Setting pods for source" source="api"
I1009 09:44:23.965918  106124 config.go:397] "Receiving a new pod" pod="prestop-hook-test-3521/test-pod"
I1009 09:44:23.966051  106124 kubelet.go:2410] "SyncLoop ADD" source="api" pods=["prestop-hook-test-3521/test-pod"]
I1009 09:44:23.966100  106124 manager.go:846] "Looking for needed resources" needed=36700160 resourceName="memory"
I1009 09:44:23.966145  106124 cpu_manager.go:400] "RemoveStaleState: containerMap: removing container" podUID="c7e58e54-59be-492a-8089-bf628cce8a30" containerName="regular-1"
I1009 09:44:23.966154  106124 state_mem.go:107] "Deleted CPUSet assignment" podUID="c7e58e54-59be-492a-8089-bf628cce8a30" containerName="regular-1"
I1009 09:44:23.966173  106124 memory_manager.go:354] "RemoveStaleState removing state" podUID="c7e58e54-59be-492a-8089-bf628cce8a30" containerName="regular-1"
I1009 09:44:23.966276  106124 pod_workers.go:768] "Pod is being synced for the first time" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c" updateType="create"
I1009 09:44:23.966308  106124 pod_workers.go:963] "Notifying pod of pending update" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c" workType="sync"
I1009 09:44:23.966337  106124 pod_workers.go:1233] "Processing pod event" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c" updateType="sync"
I1009 09:44:23.966376  106124 kubelet.go:1761] "SyncPod enter" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c"
I1009 09:44:23.966400  106124 kubelet_pods.go:1774] "Generating pod status" podIsTerminal=false pod="prestop-hook-test-3521/test-pod"
I1009 09:44:23.966488  106124 kubelet_pods.go:1787] "Got phase for pod" pod="prestop-hook-test-3521/test-pod" oldPhase="Pending" phase="Pending"
I1009 09:44:23.966540  106124 util.go:30] "No sandbox for pod can be found. Need to start a new one" pod="prestop-hook-test-3521/test-pod"
I1009 09:44:23.966929  106124 qos_container_manager_linux.go:383] "Updated QoS cgroup configuration"
I1009 09:44:23.967690  106124 volume_manager.go:404] "Waiting for volumes to attach and mount for pod" pod="prestop-hook-test-3521/test-pod"
I1009 09:44:23.967728  106124 status_manager.go:227] "Syncing updated statuses"
I1009 09:44:23.967920  106124 factory.go:279] Factory "systemd" was unable to handle container "/kubepods/burstable/podafd5e56f-a379-49e2-839a-186dcb64715c"
I1009 09:44:23.967943  106124 factory.go:279] Factory "containerd" was unable to handle container "/kubepods/burstable/podafd5e56f-a379-49e2-839a-186dcb64715c"
I1009 09:44:23.967951  106124 factory.go:275] Using factory "raw" for container "/kubepods/burstable/podafd5e56f-a379-49e2-839a-186dcb64715c"
I1009 09:44:23.968264  106124 manager.go:981] Added container: "/kubepods/burstable/podafd5e56f-a379-49e2-839a-186dcb64715c" (aliases: [], namespace: "")
I1009 09:44:23.968489  106124 handler.go:325] Added event &{/kubepods/burstable/podafd5e56f-a379-49e2-839a-186dcb64715c 2024-10-09 09:44:23.965662213 +0000 UTC containerCreation {<nil>}}
I1009 09:44:23.968540  106124 container.go:529] Start housekeeping for container "/kubepods/burstable/podafd5e56f-a379-49e2-839a-186dcb64715c"
I1009 09:44:23.985355  106124 config.go:292] "Setting pods for source" source="api"
I1009 09:44:23.985475  106124 status_manager.go:872] "Patch status for pod" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c" patch="{\"metadata\":{\"uid\":\"afd5e56f-a379-49e2-839a-186dcb64715c\"},\"status\":{\"conditions\":[{\"lastProbeTime\":null,\"lastTransitionTime\":\"2024-10-09T09:44:23Z\",\"status\":\"False\",\"type\":\"PodReadyToStartContainers\"},{\"lastProbeTime\":null,\"lastTransitionTime\":\"2024-10-09T09:44:23Z\",\"status\":\"True\",\"type\":\"Initialized\"},{\"lastProbeTime\":null,\"lastTransitionTime\":\"2024-10-09T09:44:23Z\",\"message\":\"containers with unready status: [regular-1]\",\"reason\":\"ContainersNotReady\",\"status\":\"False\",\"type\":\"Ready\"},{\"lastProbeTime\":null,\"lastTransitionTime\":\"2024-10-09T09:44:23Z\",\"message\":\"containers with unready status: [regular-1]\",\"reason\":\"ContainersNotReady\",\"status\":\"False\",\"type\":\"ContainersReady\"},{\"lastProbeTime\":null,\"lastTransitionTime\":\"2024-10-09T09:44:23Z\",\"status\":\"True\",\"type\":\"PodScheduled\"}],\"containerStatuses\":[{\"image\":\"registry.k8s.io/e2e-test-images/busybox:1.36.1-1\",\"imageID\":\"\",\"lastState\":{},\"name\":\"regular-1\",\"ready\":false,\"restartCount\":0,\"started\":false,\"state\":{\"waiting\":{\"reason\":\"ContainerCreating\"}},\"volumeMounts\":[{\"mountPath\":\"/persistent\",\"name\":\"persistent\"}]}],\"hostIP\":\"82.112.230.236\",\"hostIPs\":[{\"ip\":\"82.112.230.236\"}],\"startTime\":\"2024-10-09T09:44:23Z\"}}"
I1009 09:44:23.985543  106124 kubelet.go:2423] "SyncLoop RECONCILE" source="api" pods=["prestop-hook-test-3521/test-pod"]
I1009 09:44:23.985544  106124 status_manager.go:881] "Status for pod updated successfully" pod="prestop-hook-test-3521/test-pod" statusVersion=1 status={"phase":"Pending","conditions":[{"type":"PodReadyToStartContainers","status":"False","lastProbeTime":null,"lastTransitionTime":"2024-10-09T09:44:23Z"},{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-10-09T09:44:23Z"},{"type":"Ready","status":"False","lastProbeTime":null,"lastTransitionTime":"2024-10-09T09:44:23Z","reason":"ContainersNotReady","message":"containers with unready status: [regular-1]"},{"type":"ContainersReady","status":"False","lastProbeTime":null,"lastTransitionTime":"2024-10-09T09:44:23Z","reason":"ContainersNotReady","message":"containers with unready status: [regular-1]"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-10-09T09:44:23Z"}],"hostIP":"82.112.230.236","hostIPs":[{"ip":"82.112.230.236"}],"startTime":"2024-10-09T09:44:23Z","containerStatuses":[{"name":"regular-1","state":{"waiting":{"reason":"ContainerCreating"}},"lastState":{},"ready":false,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/busybox:1.36.1-1","imageID":"","started":false,"volumeMounts":[{"name":"persistent","mountPath":"/persistent"}]}],"qosClass":"Burstable"}
I1009 09:44:24.055084  106124 desired_state_of_world.go:308] "expected volume SELinux label context" volume="persistent" label=""
I1009 09:44:24.055126  106124 desired_state_of_world.go:328] "volume does not support SELinux context mount, clearing the expected label" volume="persistent"
I1009 09:44:24.055161  106124 desired_state_of_world_populator.go:329] "Added volume to desired state" pod="prestop-hook-test-3521/test-pod" volumeName="persistent" volumeSpecName="persistent"
I1009 09:44:24.061310  106124 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"persistent\" (UniqueName: \"kubernetes.io/empty-dir/afd5e56f-a379-49e2-839a-186dcb64715c-persistent\") pod \"test-pod\" (UID: \"afd5e56f-a379-49e2-839a-186dcb64715c\") " pod="prestop-hook-test-3521/test-pod"
I1009 09:44:24.161679  106124 reconciler_common.go:213] "Starting operationExecutor.MountVolume for volume \"persistent\" (UniqueName: \"kubernetes.io/empty-dir/afd5e56f-a379-49e2-839a-186dcb64715c-persistent\") pod \"test-pod\" (UID: \"afd5e56f-a379-49e2-839a-186dcb64715c\") " pod="prestop-hook-test-3521/test-pod"
I1009 09:44:24.161781  106124 reconciler_common.go:224] "operationExecutor.MountVolume started for volume \"persistent\" (UniqueName: \"kubernetes.io/empty-dir/afd5e56f-a379-49e2-839a-186dcb64715c-persistent\") pod \"test-pod\" (UID: \"afd5e56f-a379-49e2-839a-186dcb64715c\") " pod="prestop-hook-test-3521/test-pod"
I1009 09:44:24.162133  106124 quota_linux.go:276] SupportsQuotas called, but quotas disabled
I1009 09:44:24.162153  106124 empty_dir.go:305] assignQuota called, hasQuotas = false userNamespacesEnabled = false
I1009 09:44:24.162174  106124 operation_generator.go:637] "MountVolume.SetUp succeeded for volume \"persistent\" (UniqueName: \"kubernetes.io/empty-dir/afd5e56f-a379-49e2-839a-186dcb64715c-persistent\") pod \"test-pod\" (UID: \"afd5e56f-a379-49e2-839a-186dcb64715c\") " pod="prestop-hook-test-3521/test-pod"
I1009 09:44:24.268769  106124 volume_manager.go:440] "All volumes are attached and mounted for pod" pod="prestop-hook-test-3521/test-pod"
I1009 09:44:24.268957  106124 util.go:30] "No sandbox for pod can be found. Need to start a new one" pod="prestop-hook-test-3521/test-pod"
I1009 09:44:24.268983  106124 kuberuntime_manager.go:1055] "computePodActions got for pod" podActions="KillPod: true, CreateSandbox: true, UpdatePodResources: false, Attempt: 0, InitContainersToStart: [], ContainersToStart: [0], EphemeralContainersToStart: [],ContainersToUpdate: map[], ContainersToKill: map[]" pod="prestop-hook-test-3521/test-pod"
I1009 09:44:24.269035  106124 kuberuntime_manager.go:1064] "SyncPod received new pod, will create a sandbox for it" pod="prestop-hook-test-3521/test-pod"
I1009 09:44:24.269062  106124 kuberuntime_manager.go:1071] "Stopping PodSandbox for pod, will start new one" pod="prestop-hook-test-3521/test-pod"
I1009 09:44:24.269080  106124 kuberuntime_manager.go:1126] "Creating PodSandbox for pod" pod="prestop-hook-test-3521/test-pod"
I1009 09:44:24.342014  106124 factory.go:279] Factory "systemd" was unable to handle container "/kubepods/burstable/podafd5e56f-a379-49e2-839a-186dcb64715c/87c8ae07b7f2916ceb558e07dbf26071bedda92948368099046f4f5430169077"
I1009 09:44:24.343376  106124 factory.go:275] Using factory "containerd" for container "/kubepods/burstable/podafd5e56f-a379-49e2-839a-186dcb64715c/87c8ae07b7f2916ceb558e07dbf26071bedda92948368099046f4f5430169077"
I1009 09:44:24.371195  106124 manager.go:981] Added container: "/kubepods/burstable/podafd5e56f-a379-49e2-839a-186dcb64715c/87c8ae07b7f2916ceb558e07dbf26071bedda92948368099046f4f5430169077" (aliases: [87c8ae07b7f2916ceb558e07dbf26071bedda92948368099046f4f5430169077 /kubepods/burstable/podafd5e56f-a379-49e2-839a-186dcb64715c/87c8ae07b7f2916ceb558e07dbf26071bedda92948368099046f4f5430169077], namespace: "containerd")
I1009 09:44:24.371472  106124 handler.go:325] Added event &{/kubepods/burstable/podafd5e56f-a379-49e2-839a-186dcb64715c/87c8ae07b7f2916ceb558e07dbf26071bedda92948368099046f4f5430169077 2024-10-09 09:44:24.340664996 +0000 UTC containerCreation {<nil>}}
I1009 09:44:24.371507  106124 container.go:529] Start housekeeping for container "/kubepods/burstable/podafd5e56f-a379-49e2-839a-186dcb64715c/87c8ae07b7f2916ceb558e07dbf26071bedda92948368099046f4f5430169077"
I1009 09:44:24.381214  106124 kuberuntime_manager.go:1178] "Created PodSandbox for pod" podSandboxID="87c8ae07b7f2916ceb558e07dbf26071bedda92948368099046f4f5430169077" pod="prestop-hook-test-3521/test-pod"
I1009 09:44:24.381899  106124 kuberuntime_manager.go:1201] "Determined the ip for pod after sandbox changed" IPs=["10.10.0.97"] pod="prestop-hook-test-3521/test-pod"
I1009 09:44:24.382042  106124 kuberuntime_manager.go:1251] "Creating container in pod" containerType="container" container="&Container{Name:regular-1,Image:registry.k8s.io/e2e-test-images/busybox:1.36.1-1,Command:[sh -c touch /persistent/regular-1.log; cat /persistent/regular-1.log >> /proc/1/fd/1; echo `date -u +%FT$(nmeter -d0 '%3t' | head -n1)Z` 'regular-1 Starting 0' | tee -a /persistent/regular-1.log >> /proc/1/fd/1; _term() { sleep 15; echo `date -u +%FT$(nmeter -d0 '%3t' | head -n1)Z` 'regular-1 Exiting' | tee -a /persistent/regular-1.log >> /proc/1/fd/1; exit 0; }; trap _term TERM; touch started; echo `date -u +%FT$(nmeter -d0 '%3t' | head -n1)Z` 'regular-1 Started' | tee -a /persistent/regular-1.log >> /proc/1/fd/1; echo `date -u +%FT$(nmeter -d0 '%3t' | head -n1)Z` 'regular-1 Delaying 100' | tee -a /persistent/regular-1.log >> /proc/1/fd/1; exec sleep 100 & wait $!; echo `date -u +%FT$(nmeter -d0 '%3t' | head -n1)Z` 'regular-1 Exiting'  | tee -a /persistent/regular-1.log >> /proc/1/fd/1; exit 0],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{memory: {{36700160 0} {<nil>} 35Mi BinarySI},},Requests:ResourceList{memory: {{15728640 0} {<nil>} 15Mi BinarySI},},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:persistent,ReadOnly:false,MountPath:/persistent,SubPath:,MountPropagation:nil,SubPathExpr:,RecursiveReadOnly:nil,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:&Lifecycle{PostStart:nil,PreStop:&LifecycleHandler{Exec:&ExecAction{Command:[sh -c touch /persistent/regular-1.log; echo `date -u +%FT$(nmeter -d0 '%3t' | head -n1)Z` 'PreStop-regular-1 Starting 0' | tee -a /persistent/regular-1.log >> /proc/1/fd/1; _term() { sleep 0; echo `date -u +%FT$(nmeter -d0 '%3t' | head -n1)Z` 'PreStop-regular-1 Exiting' | tee -a /persistent/regular-1.log >> /proc/1/fd/1; exit 0; }; trap _term TERM; touch started; echo `date -u +%FT$(nmeter -d0 '%3t' | head -n1)Z` 'PreStop-regular-1 Started' | tee -a /persistent/regular-1.log >> /proc/1/fd/1; echo `date -u +%FT$(nmeter -d0 '%3t' | head -n1)Z` 'PreStop-regular-1 Delaying 1' | tee -a /persistent/regular-1.log >> /proc/1/fd/1; exec sleep 1 & wait $!; echo `date -u +%FT$(nmeter -d0 '%3t' | head -n1)Z` 'PreStop-regular-1 Exiting'  | tee -a /persistent/regular-1.log >> /proc/1/fd/1; exit 0],},HTTPGet:nil,TCPSocket:nil,Sleep:nil,},},TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:&Probe{ProbeHandler:ProbeHandler{Exec:&ExecAction{Command:[sh -c exit 1],},HTTPGet:nil,TCPSocket:nil,GRPC:nil,},InitialDelaySeconds:10,TimeoutSeconds:1,PeriodSeconds:10,SuccessThreshold:1,FailureThreshold:1,TerminationGracePeriodSeconds:nil,},ResizePolicy:[]ContainerResizePolicy{},RestartPolicy:nil,}" pod="prestop-hook-test-3521/test-pod"
I1009 09:44:24.383352  106124 kubelet_pods.go:261] "Creating hosts mount for container" pod="prestop-hook-test-3521/test-pod" containerName="regular-1" podIPs=["10.10.0.97"] path=true
I1009 09:44:24.383822  106124 event.go:389] "Event occurred" object="prestop-hook-test-3521/test-pod" fieldPath="spec.containers{regular-1}" kind="Pod" apiVersion="v1" type="Normal" reason="Pulled" message="Container image \"registry.k8s.io/e2e-test-images/busybox:1.36.1-1\" already present on machine"
I1009 09:44:24.398231  106124 event.go:389] "Event occurred" object="prestop-hook-test-3521/test-pod" fieldPath="spec.containers{regular-1}" kind="Pod" apiVersion="v1" type="Normal" reason="Created" message="Created container: regular-1"
I1009 09:44:24.417839  106124 factory.go:279] Factory "systemd" was unable to handle container "/kubepods/burstable/podafd5e56f-a379-49e2-839a-186dcb64715c/08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5"
I1009 09:44:24.418503  106124 factory.go:275] Using factory "containerd" for container "/kubepods/burstable/podafd5e56f-a379-49e2-839a-186dcb64715c/08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5"
I1009 09:44:24.441066  106124 manager.go:981] Added container: "/kubepods/burstable/podafd5e56f-a379-49e2-839a-186dcb64715c/08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5" (aliases: [08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5 /kubepods/burstable/podafd5e56f-a379-49e2-839a-186dcb64715c/08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5], namespace: "containerd")
I1009 09:44:24.441503  106124 handler.go:325] Added event &{/kubepods/burstable/podafd5e56f-a379-49e2-839a-186dcb64715c/08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5 2024-10-09 09:44:24.41666556 +0000 UTC containerCreation {<nil>}}
I1009 09:44:24.441565  106124 container.go:529] Start housekeeping for container "/kubepods/burstable/podafd5e56f-a379-49e2-839a-186dcb64715c/08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5"
I1009 09:44:24.452586  106124 kubelet.go:1767] "SyncPod exit" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c" isTerminal=false
I1009 09:44:24.452627  106124 pod_workers.go:1338] "Processing pod event done" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c" updateType="sync"
I1009 09:44:24.452879  106124 event.go:389] "Event occurred" object="prestop-hook-test-3521/test-pod" fieldPath="spec.containers{regular-1}" kind="Pod" apiVersion="v1" type="Normal" reason="Started" message="Started container regular-1"
I1009 09:44:24.872215  106124 kubelet.go:2509] "SyncLoop (housekeeping)"
I1009 09:44:24.876535  106124 kubelet_pods.go:1151] "Clean up pod workers for terminated pods"
I1009 09:44:24.877596  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=false
I1009 09:44:24.877616  106124 kubelet_pods.go:1201] "Clean up probes for terminated pods"
I1009 09:44:24.877621  106124 kubelet_pods.go:1205] "Clean up orphaned pod statuses"
I1009 09:44:24.877628  106124 kubelet_pods.go:1209] "Clean up orphaned pod user namespace allocations"
I1009 09:44:24.877656  106124 kubelet_pods.go:1221] "Clean up orphaned pod directories"
I1009 09:44:24.877952  106124 kubelet_volumes.go:163] "Cleaned up orphaned pod volumes dir" podUID="c7e58e54-59be-492a-8089-bf628cce8a30" path="/var/lib/kubelet/pods/c7e58e54-59be-492a-8089-bf628cce8a30/volumes"
I1009 09:44:24.878257  106124 kubelet_volumes.go:250] "Orphaned pod found, removing" podUID="c7e58e54-59be-492a-8089-bf628cce8a30"
I1009 09:44:24.878291  106124 kubelet_pods.go:1232] "Clean up orphaned mirror pods"
I1009 09:44:24.878335  106124 kubelet_pods.go:1374] "Clean up orphaned pod cgroups"
I1009 09:44:24.878344  106124 kubelet.go:2517] "SyncLoop (housekeeping) end" duration="6ms"
I1009 09:44:24.879151  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:44:24.879184  106124 generic.go:187] "GenericPLEG" podUID="afd5e56f-a379-49e2-839a-186dcb64715c" containerID="08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5" oldState="non-existent" newState="running"
I1009 09:44:24.879192  106124 generic.go:187] "GenericPLEG" podUID="afd5e56f-a379-49e2-839a-186dcb64715c" containerID="87c8ae07b7f2916ceb558e07dbf26071bedda92948368099046f4f5430169077" oldState="non-existent" newState="running"
I1009 09:44:24.880223  106124 kuberuntime_manager.go:1537] "getSandboxIDByPodUID got sandbox IDs for pod" podSandboxID=["87c8ae07b7f2916ceb558e07dbf26071bedda92948368099046f4f5430169077"] pod="prestop-hook-test-3521/test-pod"
I1009 09:44:24.884489  106124 generic.go:463] "PLEG: Write status" pod="prestop-hook-test-3521/test-pod"
I1009 09:44:24.884556  106124 kubelet.go:2442] "SyncLoop (PLEG): event for pod" pod="prestop-hook-test-3521/test-pod" event={"ID":"afd5e56f-a379-49e2-839a-186dcb64715c","Type":"ContainerStarted","Data":"08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5"}
I1009 09:44:24.884586  106124 pod_workers.go:963] "Notifying pod of pending update" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c" workType="sync"
I1009 09:44:24.884618  106124 kubelet.go:2442] "SyncLoop (PLEG): event for pod" pod="prestop-hook-test-3521/test-pod" event={"ID":"afd5e56f-a379-49e2-839a-186dcb64715c","Type":"ContainerStarted","Data":"87c8ae07b7f2916ceb558e07dbf26071bedda92948368099046f4f5430169077"}
I1009 09:44:24.884627  106124 pod_workers.go:963] "Notifying pod of pending update" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c" workType="sync"
I1009 09:44:24.884641  106124 pod_workers.go:1233] "Processing pod event" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c" updateType="sync"
I1009 09:44:24.884655  106124 kubelet.go:1761] "SyncPod enter" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c"
I1009 09:44:24.884663  106124 kubelet_pods.go:1774] "Generating pod status" podIsTerminal=false pod="prestop-hook-test-3521/test-pod"
I1009 09:44:24.884704  106124 kubelet_pods.go:1787] "Got phase for pod" pod="prestop-hook-test-3521/test-pod" oldPhase="Pending" phase="Running"
I1009 09:44:24.884814  106124 status_manager.go:227] "Syncing updated statuses"
I1009 09:44:24.884907  106124 volume_manager.go:404] "Waiting for volumes to attach and mount for pod" pod="prestop-hook-test-3521/test-pod"
I1009 09:44:24.884935  106124 volume_manager.go:440] "All volumes are attached and mounted for pod" pod="prestop-hook-test-3521/test-pod"
I1009 09:44:24.884979  106124 kuberuntime_manager.go:1055] "computePodActions got for pod" podActions="KillPod: false, CreateSandbox: false, UpdatePodResources: false, Attempt: 0, InitContainersToStart: [], ContainersToStart: [], EphemeralContainersToStart: [],ContainersToUpdate: map[], ContainersToKill: map[]" pod="prestop-hook-test-3521/test-pod"
I1009 09:44:24.885058  106124 kubelet.go:1767] "SyncPod exit" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c" isTerminal=false
I1009 09:44:24.885080  106124 pod_workers.go:1338] "Processing pod event done" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c" updateType="sync"
I1009 09:44:24.891965  106124 config.go:292] "Setting pods for source" source="api"
I1009 09:44:24.892033  106124 status_manager.go:872] "Patch status for pod" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c" patch="{\"metadata\":{\"uid\":\"afd5e56f-a379-49e2-839a-186dcb64715c\"},\"status\":{\"$setElementOrder/conditions\":[{\"type\":\"PodReadyToStartContainers\"},{\"type\":\"Initialized\"},{\"type\":\"Ready\"},{\"type\":\"ContainersReady\"},{\"type\":\"PodScheduled\"}],\"conditions\":[{\"lastTransitionTime\":\"2024-10-09T09:44:24Z\",\"status\":\"True\",\"type\":\"PodReadyToStartContainers\"}],\"containerStatuses\":[{\"containerID\":\"containerd://08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5\",\"image\":\"registry.k8s.io/e2e-test-images/busybox:1.36.1-1\",\"imageID\":\"registry.k8s.io/e2e-test-images/busybox@sha256:a9155b13325b2abef48e71de77bb8ac015412a566829f621d06bfae5c699b1b9\",\"lastState\":{},\"name\":\"regular-1\",\"ready\":false,\"restartCount\":0,\"started\":false,\"state\":{\"running\":{\"startedAt\":\"2024-10-09T09:44:24Z\"}},\"volumeMounts\":[{\"mountPath\":\"/persistent\",\"name\":\"persistent\"}]}],\"phase\":\"Running\",\"podIP\":\"10.10.0.97\",\"podIPs\":[{\"ip\":\"10.10.0.97\"}]}}"
I1009 09:44:24.892100  106124 kubelet.go:2423] "SyncLoop RECONCILE" source="api" pods=["prestop-hook-test-3521/test-pod"]
I1009 09:44:24.892067  106124 status_manager.go:881] "Status for pod updated successfully" pod="prestop-hook-test-3521/test-pod" statusVersion=2 status={"phase":"Running","conditions":[{"type":"PodReadyToStartContainers","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-10-09T09:44:24Z"},{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-10-09T09:44:23Z"},{"type":"Ready","status":"False","lastProbeTime":null,"lastTransitionTime":"2024-10-09T09:44:23Z","reason":"ContainersNotReady","message":"containers with unready status: [regular-1]"},{"type":"ContainersReady","status":"False","lastProbeTime":null,"lastTransitionTime":"2024-10-09T09:44:23Z","reason":"ContainersNotReady","message":"containers with unready status: [regular-1]"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-10-09T09:44:23Z"}],"hostIP":"82.112.230.236","hostIPs":[{"ip":"82.112.230.236"}],"podIP":"10.10.0.97","podIPs":[{"ip":"10.10.0.97"}],"startTime":"2024-10-09T09:44:23Z","containerStatuses":[{"name":"regular-1","state":{"running":{"startedAt":"2024-10-09T09:44:24Z"}},"lastState":{},"ready":false,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/busybox:1.36.1-1","imageID":"registry.k8s.io/e2e-test-images/busybox@sha256:a9155b13325b2abef48e71de77bb8ac015412a566829f621d06bfae5c699b1b9","containerID":"containerd://08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5","started":false,"volumeMounts":[{"name":"persistent","mountPath":"/persistent"}]}],"qosClass":"Burstable"}
I1009 09:44:24.892119  106124 pod_startup_latency_tracker.go:172] "Mark when the pod was running for the first time" pod="prestop-hook-test-3521/test-pod" rv="90"
I1009 09:44:24.960610  106124 desired_state_of_world.go:308] "expected volume SELinux label context" volume="persistent" label=""
I1009 09:44:24.960657  106124 desired_state_of_world_populator.go:329] "Added volume to desired state" pod="prestop-hook-test-3521/test-pod" volumeName="persistent" volumeSpecName="persistent"
I1009 09:44:25.885864  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:44:26.872546  106124 kubelet.go:2509] "SyncLoop (housekeeping)"
I1009 09:44:26.873734  106124 kubelet_pods.go:1151] "Clean up pod workers for terminated pods"
I1009 09:44:26.874775  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=false
I1009 09:44:26.874792  106124 kubelet_pods.go:1201] "Clean up probes for terminated pods"
I1009 09:44:26.874798  106124 kubelet_pods.go:1205] "Clean up orphaned pod statuses"
I1009 09:44:26.874803  106124 kubelet_pods.go:1209] "Clean up orphaned pod user namespace allocations"
I1009 09:44:26.874823  106124 kubelet_pods.go:1221] "Clean up orphaned pod directories"
I1009 09:44:26.874869  106124 kubelet_pods.go:1232] "Clean up orphaned mirror pods"
I1009 09:44:26.874894  106124 kubelet_pods.go:1374] "Clean up orphaned pod cgroups"
I1009 09:44:26.874902  106124 kubelet.go:2517] "SyncLoop (housekeeping) end" duration="2ms"
I1009 09:44:26.887013  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:44:27.324659  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/kubelet.service"
I1009 09:44:27.324686  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/kubelet.service"
I1009 09:44:27.324694  106124 factory.go:272] Factory "raw" can handle container "/system.slice/kubelet.service", but ignoring.
I1009 09:44:27.324702  106124 manager.go:929] ignoring container "/system.slice/kubelet.service"
I1009 09:44:27.885247  106124 kubelet.go:2898] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:; Handlers: , Features: nil"
I1009 09:44:27.888548  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:44:28.872022  106124 kubelet.go:2509] "SyncLoop (housekeeping)"
I1009 09:44:28.873578  106124 kubelet_pods.go:1151] "Clean up pod workers for terminated pods"
I1009 09:44:28.874518  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=false
I1009 09:44:28.874535  106124 kubelet_pods.go:1201] "Clean up probes for terminated pods"
I1009 09:44:28.874542  106124 kubelet_pods.go:1205] "Clean up orphaned pod statuses"
I1009 09:44:28.874565  106124 kubelet_pods.go:1209] "Clean up orphaned pod user namespace allocations"
I1009 09:44:28.874577  106124 kubelet_pods.go:1221] "Clean up orphaned pod directories"
I1009 09:44:28.874621  106124 kubelet_pods.go:1232] "Clean up orphaned mirror pods"
I1009 09:44:28.874648  106124 kubelet_pods.go:1374] "Clean up orphaned pod cgroups"
I1009 09:44:28.874657  106124 kubelet.go:2517] "SyncLoop (housekeeping) end" duration="3ms"
I1009 09:44:28.890097  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:44:29.892059  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:44:30.872025  106124 kubelet.go:2509] "SyncLoop (housekeeping)"
I1009 09:44:30.873271  106124 kubelet_pods.go:1151] "Clean up pod workers for terminated pods"
I1009 09:44:30.874100  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=false
I1009 09:44:30.874117  106124 kubelet_pods.go:1201] "Clean up probes for terminated pods"
I1009 09:44:30.874123  106124 kubelet_pods.go:1205] "Clean up orphaned pod statuses"
I1009 09:44:30.874130  106124 kubelet_pods.go:1209] "Clean up orphaned pod user namespace allocations"
I1009 09:44:30.874137  106124 kubelet_pods.go:1221] "Clean up orphaned pod directories"
I1009 09:44:30.874170  106124 kubelet_pods.go:1232] "Clean up orphaned mirror pods"
I1009 09:44:30.874195  106124 kubelet_pods.go:1374] "Clean up orphaned pod cgroups"
I1009 09:44:30.874204  106124 kubelet.go:2517] "SyncLoop (housekeeping) end" duration="2ms"
I1009 09:44:30.893712  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:44:31.896053  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:44:32.849950  106124 config.go:292] "Setting pods for source" source="file"
I1009 09:44:32.872448  106124 kubelet.go:2509] "SyncLoop (housekeeping)"
I1009 09:44:32.872483  106124 status_manager.go:230] "Syncing all statuses"
I1009 09:44:32.873941  106124 kubelet_pods.go:1151] "Clean up pod workers for terminated pods"
I1009 09:44:32.875100  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=false
I1009 09:44:32.875138  106124 kubelet_pods.go:1201] "Clean up probes for terminated pods"
I1009 09:44:32.875146  106124 kubelet_pods.go:1205] "Clean up orphaned pod statuses"
I1009 09:44:32.875154  106124 kubelet_pods.go:1209] "Clean up orphaned pod user namespace allocations"
I1009 09:44:32.875174  106124 kubelet_pods.go:1221] "Clean up orphaned pod directories"
I1009 09:44:32.875223  106124 kubelet_pods.go:1232] "Clean up orphaned mirror pods"
I1009 09:44:32.875250  106124 kubelet_pods.go:1374] "Clean up orphaned pod cgroups"
I1009 09:44:32.875260  106124 kubelet.go:2517] "SyncLoop (housekeeping) end" duration="3ms"
I1009 09:44:32.884327  106124 container_log_manager.go:238] "Starting container log rotation sequence"
I1009 09:44:32.884365  106124 eviction_manager.go:251] "Eviction manager: synchronize housekeeping"
I1009 09:44:32.884380  106124 eviction_manager.go:280] "FileSystem detection" DedicatedImageFs=false SplitImageFs=false
I1009 09:44:32.885000  106124 container_log_manager.go:252] "Adding new entry to the queue for processing" id="08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5" name="regular-1" labels={"io.kubernetes.container.name":"regular-1","io.kubernetes.pod.name":"test-pod","io.kubernetes.pod.namespace":"prestop-hook-test-3521","io.kubernetes.pod.uid":"afd5e56f-a379-49e2-839a-186dcb64715c"}
I1009 09:44:32.885738  106124 kubelet.go:2898] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:; Handlers: , Features: nil"
I1009 09:44:32.890925  106124 helpers.go:972] "Eviction manager:" log="observations" signal="allocatableMemory.available" resourceName="memory" available="16371212Ki" capacity="16376164Ki" time="2024-10-09 09:44:32.890849787 +0000 UTC m=+10.096364293"
I1009 09:44:32.890971  106124 helpers.go:972] "Eviction manager:" log="observations" signal="nodefs.available" resourceName="ephemeral-storage" available="162422412Ki" capacity="202051056Ki" time="2024-10-09 09:44:32.884965317 +0000 UTC m=+10.090479813"
I1009 09:44:32.890981  106124 helpers.go:972] "Eviction manager:" log="observations" signal="nodefs.inodesFree" resourceName="inodes" available="24743220" capacity="26083328" time="2024-10-09 09:44:32.884965317 +0000 UTC m=+10.090479813"
I1009 09:44:32.890989  106124 helpers.go:972] "Eviction manager:" log="observations" signal="containerfs.available" resourceName="ephemeral-storage" available="162422412Ki" capacity="202051056Ki" time="2024-10-09 09:44:32.0981564 +0000 UTC"
I1009 09:44:32.890997  106124 helpers.go:972] "Eviction manager:" log="observations" signal="containerfs.inodesFree" resourceName="inodes" available="24743220" capacity="26083328" time="2024-10-09 09:44:32.0981564 +0000 UTC"
I1009 09:44:32.891003  106124 helpers.go:972] "Eviction manager:" log="observations" signal="pid.available" resourceName="pids" available="127323" capacity="127664" time="2024-10-09 09:44:32.890563994 +0000 UTC m=+10.096078491"
I1009 09:44:32.891011  106124 helpers.go:972] "Eviction manager:" log="observations" signal="memory.available" resourceName="memory" available="12065920Ki" capacity="16376164Ki" time="2024-10-09 09:44:32.884965317 +0000 UTC m=+10.090479813"
I1009 09:44:32.891018  106124 helpers.go:972] "Eviction manager:" log="observations" signal="imagefs.available" resourceName="ephemeral-storage" available="162422412Ki" capacity="202051056Ki" time="2024-10-09 09:44:32.0981564 +0000 UTC"
I1009 09:44:32.891024  106124 helpers.go:972] "Eviction manager:" log="observations" signal="imagefs.inodesFree" resourceName="inodes" available="24743220" capacity="26083328" time="2024-10-09 09:44:32.0981564 +0000 UTC"
I1009 09:44:32.891051  106124 eviction_manager.go:359] "Eviction manager: no resources are starved"
I1009 09:44:32.897731  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:44:33.134891  106124 interface.go:432] Looking for default routes with IPv4 addresses
I1009 09:44:33.134927  106124 interface.go:437] Default route transits interface "eth0"
I1009 09:44:33.135060  106124 interface.go:209] Interface eth0 is up
I1009 09:44:33.135113  106124 interface.go:257] Interface "eth0" has 3 addresses :[82.112.230.236/24 2a02:4780:12:eebf::1/48 fe80::be24:11ff:fe5a:b1d8/64].
I1009 09:44:33.135132  106124 interface.go:224] Checking addr  82.112.230.236/24.
I1009 09:44:33.135156  106124 interface.go:231] IP found 82.112.230.236
I1009 09:44:33.135163  106124 interface.go:263] Found valid IPv4 address 82.112.230.236 for interface "eth0".
I1009 09:44:33.135167  106124 interface.go:443] Found active IP 82.112.230.236 
I1009 09:44:33.548272  106124 handler.go:293] error while reading "/proc/106124/fd/23" link: readlink /proc/106124/fd/23: no such file or directory
I1009 09:44:33.682357  106124 status_manager.go:386] "Container startup unchanged" pod="prestop-hook-test-3521/test-pod" containerID="containerd://08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5"
I1009 09:44:33.682402  106124 kubelet.go:2531] "SyncLoop (probe)" probe="startup" status="unhealthy" pod="prestop-hook-test-3521/test-pod"
I1009 09:44:33.682424  106124 pod_workers.go:963] "Notifying pod of pending update" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c" workType="sync"
I1009 09:44:33.682510  106124 pod_workers.go:1233] "Processing pod event" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c" updateType="sync"
I1009 09:44:33.682536  106124 kubelet.go:1761] "SyncPod enter" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c"
I1009 09:44:33.682545  106124 kubelet_pods.go:1774] "Generating pod status" podIsTerminal=false pod="prestop-hook-test-3521/test-pod"
I1009 09:44:33.682577  106124 kubelet_pods.go:1787] "Got phase for pod" pod="prestop-hook-test-3521/test-pod" oldPhase="Running" phase="Running"
I1009 09:44:33.682660  106124 status_manager.go:691] "Ignoring same status for pod" pod="prestop-hook-test-3521/test-pod" status={"phase":"Running","conditions":[{"type":"PodReadyToStartContainers","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-10-09T09:44:24Z"},{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-10-09T09:44:23Z"},{"type":"Ready","status":"False","lastProbeTime":null,"lastTransitionTime":"2024-10-09T09:44:23Z","reason":"ContainersNotReady","message":"containers with unready status: [regular-1]"},{"type":"ContainersReady","status":"False","lastProbeTime":null,"lastTransitionTime":"2024-10-09T09:44:23Z","reason":"ContainersNotReady","message":"containers with unready status: [regular-1]"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-10-09T09:44:23Z"}],"hostIP":"82.112.230.236","hostIPs":[{"ip":"82.112.230.236"}],"podIP":"10.10.0.97","podIPs":[{"ip":"10.10.0.97"}],"startTime":"2024-10-09T09:44:23Z","containerStatuses":[{"name":"regular-1","state":{"running":{"startedAt":"2024-10-09T09:44:24Z"}},"lastState":{},"ready":false,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/busybox:1.36.1-1","imageID":"registry.k8s.io/e2e-test-images/busybox@sha256:a9155b13325b2abef48e71de77bb8ac015412a566829f621d06bfae5c699b1b9","containerID":"containerd://08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5","started":false,"volumeMounts":[{"name":"persistent","mountPath":"/persistent"}]}],"qosClass":"Burstable"}
I1009 09:44:33.682866  106124 volume_manager.go:404] "Waiting for volumes to attach and mount for pod" pod="prestop-hook-test-3521/test-pod"
I1009 09:44:33.682891  106124 volume_manager.go:440] "All volumes are attached and mounted for pod" pod="prestop-hook-test-3521/test-pod"
I1009 09:44:33.682922  106124 kuberuntime_manager.go:1055] "computePodActions got for pod" podActions="KillPod: false, CreateSandbox: false, UpdatePodResources: false, Attempt: 0, InitContainersToStart: [], ContainersToStart: [], EphemeralContainersToStart: [],ContainersToUpdate: map[], ContainersToKill: map[]" pod="prestop-hook-test-3521/test-pod"
I1009 09:44:33.682986  106124 kubelet.go:1767] "SyncPod exit" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c" isTerminal=false
I1009 09:44:33.683004  106124 pod_workers.go:1338] "Processing pod event done" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c" updateType="sync"
I1009 09:44:33.715690  106124 desired_state_of_world.go:308] "expected volume SELinux label context" volume="persistent" label=""
I1009 09:44:33.715728  106124 desired_state_of_world_populator.go:329] "Added volume to desired state" pod="prestop-hook-test-3521/test-pod" volumeName="persistent" volumeSpecName="persistent"
I1009 09:44:33.900106  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:44:34.872475  106124 kubelet.go:2509] "SyncLoop (housekeeping)"
I1009 09:44:34.874003  106124 kubelet_pods.go:1151] "Clean up pod workers for terminated pods"
I1009 09:44:34.875016  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=false
I1009 09:44:34.875061  106124 kubelet_pods.go:1201] "Clean up probes for terminated pods"
I1009 09:44:34.875068  106124 kubelet_pods.go:1205] "Clean up orphaned pod statuses"
I1009 09:44:34.875076  106124 kubelet_pods.go:1209] "Clean up orphaned pod user namespace allocations"
I1009 09:44:34.875084  106124 kubelet_pods.go:1221] "Clean up orphaned pod directories"
I1009 09:44:34.875154  106124 kubelet_pods.go:1232] "Clean up orphaned mirror pods"
I1009 09:44:34.875195  106124 kubelet_pods.go:1374] "Clean up orphaned pod cgroups"
I1009 09:44:34.875207  106124 kubelet.go:2517] "SyncLoop (housekeeping) end" duration="3ms"
I1009 09:44:34.901404  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:44:35.902744  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:44:36.872428  106124 kubelet.go:2509] "SyncLoop (housekeeping)"
I1009 09:44:36.873688  106124 kubelet_pods.go:1151] "Clean up pod workers for terminated pods"
I1009 09:44:36.874919  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=false
I1009 09:44:36.874943  106124 kubelet_pods.go:1201] "Clean up probes for terminated pods"
I1009 09:44:36.874950  106124 kubelet_pods.go:1205] "Clean up orphaned pod statuses"
I1009 09:44:36.874956  106124 kubelet_pods.go:1209] "Clean up orphaned pod user namespace allocations"
I1009 09:44:36.874963  106124 kubelet_pods.go:1221] "Clean up orphaned pod directories"
I1009 09:44:36.875000  106124 kubelet_pods.go:1232] "Clean up orphaned mirror pods"
I1009 09:44:36.875025  106124 kubelet_pods.go:1374] "Clean up orphaned pod cgroups"
I1009 09:44:36.875034  106124 kubelet.go:2517] "SyncLoop (housekeeping) end" duration="3ms"
I1009 09:44:36.904785  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:44:37.575026  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/kubelet.service"
I1009 09:44:37.575054  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/kubelet.service"
I1009 09:44:37.575061  106124 factory.go:272] Factory "raw" can handle container "/system.slice/kubelet.service", but ignoring.
I1009 09:44:37.575069  106124 manager.go:929] ignoring container "/system.slice/kubelet.service"
I1009 09:44:37.886902  106124 kubelet.go:2898] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:; Handlers: , Features: nil"
I1009 09:44:37.906580  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:44:38.872006  106124 kubelet.go:2509] "SyncLoop (housekeeping)"
I1009 09:44:38.873553  106124 kubelet_pods.go:1151] "Clean up pod workers for terminated pods"
I1009 09:44:38.874639  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=false
I1009 09:44:38.874668  106124 kubelet_pods.go:1201] "Clean up probes for terminated pods"
I1009 09:44:38.874676  106124 kubelet_pods.go:1205] "Clean up orphaned pod statuses"
I1009 09:44:38.874682  106124 kubelet_pods.go:1209] "Clean up orphaned pod user namespace allocations"
I1009 09:44:38.874690  106124 kubelet_pods.go:1221] "Clean up orphaned pod directories"
I1009 09:44:38.874740  106124 kubelet_pods.go:1232] "Clean up orphaned mirror pods"
I1009 09:44:38.874767  106124 kubelet_pods.go:1374] "Clean up orphaned pod cgroups"
I1009 09:44:38.874778  106124 kubelet.go:2517] "SyncLoop (housekeeping) end" duration="3ms"
I1009 09:44:38.908309  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:44:39.909748  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:44:40.872166  106124 kubelet.go:2509] "SyncLoop (housekeeping)"
I1009 09:44:40.873989  106124 kubelet_pods.go:1151] "Clean up pod workers for terminated pods"
I1009 09:44:40.875192  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=false
I1009 09:44:40.875210  106124 kubelet_pods.go:1201] "Clean up probes for terminated pods"
I1009 09:44:40.875215  106124 kubelet_pods.go:1205] "Clean up orphaned pod statuses"
I1009 09:44:40.875221  106124 kubelet_pods.go:1209] "Clean up orphaned pod user namespace allocations"
I1009 09:44:40.875228  106124 kubelet_pods.go:1221] "Clean up orphaned pod directories"
I1009 09:44:40.875265  106124 kubelet_pods.go:1232] "Clean up orphaned mirror pods"
I1009 09:44:40.875296  106124 kubelet_pods.go:1374] "Clean up orphaned pod cgroups"
I1009 09:44:40.875305  106124 kubelet.go:2517] "SyncLoop (housekeeping) end" duration="3ms"
I1009 09:44:40.911720  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:44:41.913790  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:44:42.849781  106124 config.go:292] "Setting pods for source" source="file"
I1009 09:44:42.871514  106124 status_manager.go:230] "Syncing all statuses"
I1009 09:44:42.871534  106124 kubelet.go:2509] "SyncLoop (housekeeping)"
I1009 09:44:42.873122  106124 kubelet_pods.go:1151] "Clean up pod workers for terminated pods"
I1009 09:44:42.874802  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=false
I1009 09:44:42.874822  106124 kubelet_pods.go:1201] "Clean up probes for terminated pods"
I1009 09:44:42.874827  106124 kubelet_pods.go:1205] "Clean up orphaned pod statuses"
I1009 09:44:42.874833  106124 kubelet_pods.go:1209] "Clean up orphaned pod user namespace allocations"
I1009 09:44:42.874840  106124 kubelet_pods.go:1221] "Clean up orphaned pod directories"
I1009 09:44:42.874881  106124 kubelet_pods.go:1232] "Clean up orphaned mirror pods"
I1009 09:44:42.874905  106124 kubelet_pods.go:1374] "Clean up orphaned pod cgroups"
I1009 09:44:42.874914  106124 kubelet.go:2517] "SyncLoop (housekeeping) end" duration="3ms"
I1009 09:44:42.885828  106124 container_log_manager.go:238] "Starting container log rotation sequence"
I1009 09:44:42.886576  106124 container_log_manager.go:252] "Adding new entry to the queue for processing" id="08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5" name="regular-1" labels={"io.kubernetes.container.name":"regular-1","io.kubernetes.pod.name":"test-pod","io.kubernetes.pod.namespace":"prestop-hook-test-3521","io.kubernetes.pod.uid":"afd5e56f-a379-49e2-839a-186dcb64715c"}
I1009 09:44:42.887618  106124 kubelet.go:2898] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:; Handlers: , Features: nil"
I1009 09:44:42.891849  106124 eviction_manager.go:251] "Eviction manager: synchronize housekeeping"
I1009 09:44:42.891880  106124 eviction_manager.go:280] "FileSystem detection" DedicatedImageFs=false SplitImageFs=false
I1009 09:44:42.899076  106124 helpers.go:972] "Eviction manager:" log="observations" signal="nodefs.available" resourceName="ephemeral-storage" available="162422396Ki" capacity="202051056Ki" time="2024-10-09 09:44:42.89253035 +0000 UTC m=+20.098044846"
I1009 09:44:42.899118  106124 helpers.go:972] "Eviction manager:" log="observations" signal="imagefs.inodesFree" resourceName="inodes" available="24743220" capacity="26083328" time="2024-10-09 09:44:42.09779165 +0000 UTC"
I1009 09:44:42.899125  106124 helpers.go:972] "Eviction manager:" log="observations" signal="memory.available" resourceName="memory" available="12065196Ki" capacity="16376164Ki" time="2024-10-09 09:44:42.89253035 +0000 UTC m=+20.098044846"
I1009 09:44:42.899132  106124 helpers.go:972] "Eviction manager:" log="observations" signal="allocatableMemory.available" resourceName="memory" available="16371212Ki" capacity="16376164Ki" time="2024-10-09 09:44:42.898943123 +0000 UTC m=+20.104457629"
I1009 09:44:42.899153  106124 helpers.go:972] "Eviction manager:" log="observations" signal="containerfs.available" resourceName="ephemeral-storage" available="162422396Ki" capacity="202051056Ki" time="2024-10-09 09:44:42.09779165 +0000 UTC"
I1009 09:44:42.899158  106124 helpers.go:972] "Eviction manager:" log="observations" signal="containerfs.inodesFree" resourceName="inodes" available="24743220" capacity="26083328" time="2024-10-09 09:44:42.09779165 +0000 UTC"
I1009 09:44:42.899163  106124 helpers.go:972] "Eviction manager:" log="observations" signal="pid.available" resourceName="pids" available="127323" capacity="127664" time="2024-10-09 09:44:42.898632081 +0000 UTC m=+20.104146577"
I1009 09:44:42.899168  106124 helpers.go:972] "Eviction manager:" log="observations" signal="nodefs.inodesFree" resourceName="inodes" available="24743220" capacity="26083328" time="2024-10-09 09:44:42.89253035 +0000 UTC m=+20.098044846"
I1009 09:44:42.899174  106124 helpers.go:972] "Eviction manager:" log="observations" signal="imagefs.available" resourceName="ephemeral-storage" available="162422396Ki" capacity="202051056Ki" time="2024-10-09 09:44:42.09779165 +0000 UTC"
I1009 09:44:42.899203  106124 eviction_manager.go:359] "Eviction manager: no resources are starved"
I1009 09:44:42.915943  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:44:43.502804  106124 interface.go:432] Looking for default routes with IPv4 addresses
I1009 09:44:43.502838  106124 interface.go:437] Default route transits interface "eth0"
I1009 09:44:43.502996  106124 interface.go:209] Interface eth0 is up
I1009 09:44:43.503073  106124 interface.go:257] Interface "eth0" has 3 addresses :[82.112.230.236/24 2a02:4780:12:eebf::1/48 fe80::be24:11ff:fe5a:b1d8/64].
I1009 09:44:43.503090  106124 interface.go:224] Checking addr  82.112.230.236/24.
I1009 09:44:43.503097  106124 interface.go:231] IP found 82.112.230.236
I1009 09:44:43.503101  106124 interface.go:263] Found valid IPv4 address 82.112.230.236 for interface "eth0".
I1009 09:44:43.503113  106124 interface.go:443] Found active IP 82.112.230.236 
I1009 09:44:43.683014  106124 prober.go:140] "Exec-Probe runProbe" pod="prestop-hook-test-3521/test-pod" containerName="regular-1" execCommand=["sh","-c","exit 1"]
I1009 09:44:43.711222  106124 exec.go:64] Exec probe response: ""
I1009 09:44:43.711272  106124 prober.go:107] "Probe failed" probeType="Startup" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c" containerName="regular-1" probeResult="failure" output=""
I1009 09:44:43.711359  106124 status_manager.go:386] "Container startup unchanged" pod="prestop-hook-test-3521/test-pod" containerID="containerd://08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5"
I1009 09:44:43.711367  106124 kubelet.go:2531] "SyncLoop (probe)" probe="startup" status="unhealthy" pod="prestop-hook-test-3521/test-pod"
I1009 09:44:43.711378  106124 pod_workers.go:963] "Notifying pod of pending update" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c" workType="sync"
I1009 09:44:43.711406  106124 pod_workers.go:1233] "Processing pod event" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c" updateType="sync"
I1009 09:44:43.711421  106124 kubelet.go:1761] "SyncPod enter" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c"
I1009 09:44:43.711430  106124 kubelet_pods.go:1774] "Generating pod status" podIsTerminal=false pod="prestop-hook-test-3521/test-pod"
I1009 09:44:43.711435  106124 event.go:389] "Event occurred" object="prestop-hook-test-3521/test-pod" fieldPath="spec.containers{regular-1}" kind="Pod" apiVersion="v1" type="Warning" reason="Unhealthy" message="Startup probe failed: "
I1009 09:44:43.711531  106124 kubelet_pods.go:1787] "Got phase for pod" pod="prestop-hook-test-3521/test-pod" oldPhase="Running" phase="Running"
I1009 09:44:43.711624  106124 status_manager.go:691] "Ignoring same status for pod" pod="prestop-hook-test-3521/test-pod" status={"phase":"Running","conditions":[{"type":"PodReadyToStartContainers","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-10-09T09:44:24Z"},{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-10-09T09:44:23Z"},{"type":"Ready","status":"False","lastProbeTime":null,"lastTransitionTime":"2024-10-09T09:44:23Z","reason":"ContainersNotReady","message":"containers with unready status: [regular-1]"},{"type":"ContainersReady","status":"False","lastProbeTime":null,"lastTransitionTime":"2024-10-09T09:44:23Z","reason":"ContainersNotReady","message":"containers with unready status: [regular-1]"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-10-09T09:44:23Z"}],"hostIP":"82.112.230.236","hostIPs":[{"ip":"82.112.230.236"}],"podIP":"10.10.0.97","podIPs":[{"ip":"10.10.0.97"}],"startTime":"2024-10-09T09:44:23Z","containerStatuses":[{"name":"regular-1","state":{"running":{"startedAt":"2024-10-09T09:44:24Z"}},"lastState":{},"ready":false,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/busybox:1.36.1-1","imageID":"registry.k8s.io/e2e-test-images/busybox@sha256:a9155b13325b2abef48e71de77bb8ac015412a566829f621d06bfae5c699b1b9","containerID":"containerd://08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5","started":false,"volumeMounts":[{"name":"persistent","mountPath":"/persistent"}]}],"qosClass":"Burstable"}
I1009 09:44:43.711775  106124 volume_manager.go:404] "Waiting for volumes to attach and mount for pod" pod="prestop-hook-test-3521/test-pod"
I1009 09:44:43.711797  106124 volume_manager.go:440] "All volumes are attached and mounted for pod" pod="prestop-hook-test-3521/test-pod"
I1009 09:44:43.711828  106124 kuberuntime_manager.go:1027] "Message for Container of pod" containerName="regular-1" containerStatusID={"Type":"containerd","ID":"08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5"} pod="prestop-hook-test-3521/test-pod" containerMessage="Container regular-1 failed startup probe"
I1009 09:44:43.711857  106124 kuberuntime_manager.go:1055] "computePodActions got for pod" podActions="KillPod: true, CreateSandbox: false, UpdatePodResources: false, Attempt: 0, InitContainersToStart: [], ContainersToStart: [], EphemeralContainersToStart: [],ContainersToUpdate: map[], ContainersToKill: map[{containerd 08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5}:{0xc0012dde00 regular-1 Container regular-1 failed startup probe StartupProbe}]" pod="prestop-hook-test-3521/test-pod"
I1009 09:44:43.711873  106124 kuberuntime_manager.go:1073] "Stopping PodSandbox for pod, because all other containers are dead" pod="prestop-hook-test-3521/test-pod"
I1009 09:44:43.711906  106124 kuberuntime_container.go:683] "Running preStop hook" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c" containerName="regular-1" containerID="containerd://08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5"
I1009 09:44:43.711937  106124 event.go:389] "Event occurred" object="prestop-hook-test-3521/test-pod" fieldPath="spec.containers{regular-1}" kind="Pod" apiVersion="v1" type="Normal" reason="Killing" message="Stopping container regular-1"
I1009 09:44:43.779338  106124 desired_state_of_world.go:308] "expected volume SELinux label context" volume="persistent" label=""
I1009 09:44:43.779398  106124 desired_state_of_world_populator.go:329] "Added volume to desired state" pod="prestop-hook-test-3521/test-pod" volumeName="persistent" volumeSpecName="persistent"
I1009 09:44:43.918035  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:44:44.759914  106124 kuberuntime_container.go:703] "PreStop hook completed" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c" containerName="regular-1" containerID="containerd://08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5"
I1009 09:44:44.759967  106124 kuberuntime_container.go:808] "Killing container with a grace period" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c" containerName="regular-1" containerID="containerd://08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5" gracePeriod=29
E1009 09:44:44.767187  106124 log.go:32] "StopContainer from runtime service failed" err=<
	rpc error: code = Unknown desc = failed to stop container "08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5": unknown error after kill: runc did not terminate successfully: exit status 1: unable to signal init: permission denied
	: unknown
 > containerID="08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5"
E1009 09:44:44.767265  106124 kuberuntime_container.go:813] "Container termination failed with gracePeriod" err=<
	rpc error: code = Unknown desc = failed to stop container "08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5": unknown error after kill: runc did not terminate successfully: exit status 1: unable to signal init: permission denied
	: unknown
 > pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c" containerName="regular-1" containerID="containerd://08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5" gracePeriod=29
E1009 09:44:44.767294  106124 kuberuntime_container.go:851] "Kill container failed" err=<
	rpc error: code = Unknown desc = failed to stop container "08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5": unknown error after kill: runc did not terminate successfully: exit status 1: unable to signal init: permission denied
	: unknown
 > pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c" containerName="regular-1" containerID={"Type":"containerd","ID":"08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5"}
E1009 09:44:44.774140  106124 log.go:32] "StopPodSandbox from runtime service failed" err=<
	rpc error: code = Unknown desc = failed to stop container "08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5": failed to kill container "08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5": unknown error after kill: runc did not terminate successfully: exit status 1: unable to signal init: permission denied
	: unknown
 > podSandboxID="87c8ae07b7f2916ceb558e07dbf26071bedda92948368099046f4f5430169077"
E1009 09:44:44.774219  106124 kuberuntime_manager.go:1479] "Failed to stop sandbox" podSandboxID={"Type":"containerd","ID":"87c8ae07b7f2916ceb558e07dbf26071bedda92948368099046f4f5430169077"}
E1009 09:44:44.774268  106124 kuberuntime_manager.go:1079] "killPodWithSyncResult failed" err="[failed to \"KillContainer\" for \"regular-1\" with KillContainerError: \"rpc error: code = Unknown desc = failed to stop container \\\"08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5\\\": unknown error after kill: runc did not terminate successfully: exit status 1: unable to signal init: permission denied\\n: unknown\", failed to \"KillPodSandbox\" for \"afd5e56f-a379-49e2-839a-186dcb64715c\" with KillPodSandboxError: \"rpc error: code = Unknown desc = failed to stop container \\\"08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5\\\": failed to kill container \\\"08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5\\\": unknown error after kill: runc did not terminate successfully: exit status 1: unable to signal init: permission denied\\n: unknown\"]"
I1009 09:44:44.774315  106124 kubelet.go:1767] "SyncPod exit" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c" isTerminal=false
E1009 09:44:44.774328  106124 pod_workers.go:1301] "Error syncing pod, skipping" err="[failed to \"KillContainer\" for \"regular-1\" with KillContainerError: \"rpc error: code = Unknown desc = failed to stop container \\\"08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5\\\": unknown error after kill: runc did not terminate successfully: exit status 1: unable to signal init: permission denied\\n: unknown\", failed to \"KillPodSandbox\" for \"afd5e56f-a379-49e2-839a-186dcb64715c\" with KillPodSandboxError: \"rpc error: code = Unknown desc = failed to stop container \\\"08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5\\\": failed to kill container \\\"08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5\\\": unknown error after kill: runc did not terminate successfully: exit status 1: unable to signal init: permission denied\\n: unknown\"]" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c"
I1009 09:44:44.774378  106124 pod_workers.go:1338] "Processing pod event done" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c" updateType="sync"
I1009 09:44:44.872353  106124 kubelet.go:2509] "SyncLoop (housekeeping)"
I1009 09:44:44.873966  106124 kubelet_pods.go:1151] "Clean up pod workers for terminated pods"
I1009 09:44:44.875087  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=false
I1009 09:44:44.875103  106124 kubelet_pods.go:1201] "Clean up probes for terminated pods"
I1009 09:44:44.875109  106124 kubelet_pods.go:1205] "Clean up orphaned pod statuses"
I1009 09:44:44.875115  106124 kubelet_pods.go:1209] "Clean up orphaned pod user namespace allocations"
I1009 09:44:44.875148  106124 kubelet_pods.go:1221] "Clean up orphaned pod directories"
I1009 09:44:44.875189  106124 kubelet_pods.go:1232] "Clean up orphaned mirror pods"
I1009 09:44:44.875228  106124 kubelet_pods.go:1374] "Clean up orphaned pod cgroups"
I1009 09:44:44.875241  106124 kubelet.go:2517] "SyncLoop (housekeeping) end" duration="3ms"
I1009 09:44:44.922054  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:44:45.923998  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:44:45.939144  106124 handler.go:293] error while reading "/proc/106124/fd/23" link: readlink /proc/106124/fd/23: no such file or directory
I1009 09:44:46.872119  106124 kubelet.go:2509] "SyncLoop (housekeeping)"
I1009 09:44:46.873615  106124 kubelet_pods.go:1151] "Clean up pod workers for terminated pods"
I1009 09:44:46.874945  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=false
I1009 09:44:46.874987  106124 kubelet_pods.go:1201] "Clean up probes for terminated pods"
I1009 09:44:46.874996  106124 kubelet_pods.go:1205] "Clean up orphaned pod statuses"
I1009 09:44:46.875006  106124 kubelet_pods.go:1209] "Clean up orphaned pod user namespace allocations"
I1009 09:44:46.875014  106124 kubelet_pods.go:1221] "Clean up orphaned pod directories"
I1009 09:44:46.875086  106124 kubelet_pods.go:1232] "Clean up orphaned mirror pods"
I1009 09:44:46.875126  106124 kubelet_pods.go:1374] "Clean up orphaned pod cgroups"
I1009 09:44:46.875139  106124 kubelet.go:2517] "SyncLoop (housekeeping) end" duration="3ms"
I1009 09:44:46.925936  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:44:47.824970  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/kubelet.service"
I1009 09:44:47.825002  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/kubelet.service"
I1009 09:44:47.825011  106124 factory.go:272] Factory "raw" can handle container "/system.slice/kubelet.service", but ignoring.
I1009 09:44:47.825021  106124 manager.go:929] ignoring container "/system.slice/kubelet.service"
I1009 09:44:47.889419  106124 kubelet.go:2898] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:; Handlers: , Features: nil"
I1009 09:44:47.927380  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:44:48.871513  106124 kubelet.go:2509] "SyncLoop (housekeeping)"
I1009 09:44:48.873014  106124 kubelet_pods.go:1151] "Clean up pod workers for terminated pods"
I1009 09:44:48.874053  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=false
I1009 09:44:48.874076  106124 kubelet_pods.go:1201] "Clean up probes for terminated pods"
I1009 09:44:48.874101  106124 kubelet_pods.go:1205] "Clean up orphaned pod statuses"
I1009 09:44:48.874106  106124 kubelet_pods.go:1209] "Clean up orphaned pod user namespace allocations"
I1009 09:44:48.874114  106124 kubelet_pods.go:1221] "Clean up orphaned pod directories"
I1009 09:44:48.874152  106124 kubelet_pods.go:1232] "Clean up orphaned mirror pods"
I1009 09:44:48.874178  106124 kubelet_pods.go:1374] "Clean up orphaned pod cgroups"
I1009 09:44:48.874186  106124 kubelet.go:2517] "SyncLoop (housekeeping) end" duration="3ms"
I1009 09:44:48.929613  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:44:49.931987  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:44:50.872578  106124 kubelet.go:2509] "SyncLoop (housekeeping)"
I1009 09:44:50.873806  106124 kubelet_pods.go:1151] "Clean up pod workers for terminated pods"
I1009 09:44:50.874750  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=false
I1009 09:44:50.874787  106124 kubelet_pods.go:1201] "Clean up probes for terminated pods"
I1009 09:44:50.874793  106124 kubelet_pods.go:1205] "Clean up orphaned pod statuses"
I1009 09:44:50.874800  106124 kubelet_pods.go:1209] "Clean up orphaned pod user namespace allocations"
I1009 09:44:50.874807  106124 kubelet_pods.go:1221] "Clean up orphaned pod directories"
I1009 09:44:50.874859  106124 kubelet_pods.go:1232] "Clean up orphaned mirror pods"
I1009 09:44:50.874885  106124 kubelet_pods.go:1374] "Clean up orphaned pod cgroups"
I1009 09:44:50.874895  106124 kubelet.go:2517] "SyncLoop (housekeeping) end" duration="2ms"
I1009 09:44:50.933423  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:44:51.935397  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:44:52.849832  106124 config.go:292] "Setting pods for source" source="file"
I1009 09:44:52.871787  106124 kubelet.go:2509] "SyncLoop (housekeeping)"
I1009 09:44:52.871786  106124 status_manager.go:230] "Syncing all statuses"
I1009 09:44:52.873206  106124 kubelet_pods.go:1151] "Clean up pod workers for terminated pods"
I1009 09:44:52.874386  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=false
I1009 09:44:52.874407  106124 kubelet_pods.go:1201] "Clean up probes for terminated pods"
I1009 09:44:52.874414  106124 kubelet_pods.go:1205] "Clean up orphaned pod statuses"
I1009 09:44:52.874423  106124 kubelet_pods.go:1209] "Clean up orphaned pod user namespace allocations"
I1009 09:44:52.874431  106124 kubelet_pods.go:1221] "Clean up orphaned pod directories"
I1009 09:44:52.874508  106124 kubelet_pods.go:1232] "Clean up orphaned mirror pods"
I1009 09:44:52.874544  106124 kubelet_pods.go:1374] "Clean up orphaned pod cgroups"
I1009 09:44:52.874556  106124 kubelet.go:2517] "SyncLoop (housekeeping) end" duration="3ms"
I1009 09:44:52.886708  106124 container_log_manager.go:238] "Starting container log rotation sequence"
I1009 09:44:52.887315  106124 container_log_manager.go:252] "Adding new entry to the queue for processing" id="08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5" name="regular-1" labels={"io.kubernetes.container.name":"regular-1","io.kubernetes.pod.name":"test-pod","io.kubernetes.pod.namespace":"prestop-hook-test-3521","io.kubernetes.pod.uid":"afd5e56f-a379-49e2-839a-186dcb64715c"}
I1009 09:44:52.890472  106124 kubelet.go:2898] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:; Handlers: , Features: nil"
I1009 09:44:52.899748  106124 eviction_manager.go:251] "Eviction manager: synchronize housekeeping"
I1009 09:44:52.899795  106124 eviction_manager.go:280] "FileSystem detection" DedicatedImageFs=false SplitImageFs=false
I1009 09:44:52.906340  106124 helpers.go:972] "Eviction manager:" log="observations" signal="pid.available" resourceName="pids" available="127323" capacity="127664" time="2024-10-09 09:44:52.905953845 +0000 UTC m=+30.111468332"
I1009 09:44:52.906375  106124 helpers.go:972] "Eviction manager:" log="observations" signal="allocatableMemory.available" resourceName="memory" available="16371212Ki" capacity="16376164Ki" time="2024-10-09 09:44:52.906229427 +0000 UTC m=+30.111743933"
I1009 09:44:52.906394  106124 helpers.go:972] "Eviction manager:" log="observations" signal="nodefs.inodesFree" resourceName="inodes" available="24743220" capacity="26083328" time="2024-10-09 09:44:52.900421977 +0000 UTC m=+30.105936483"
I1009 09:44:52.906400  106124 helpers.go:972] "Eviction manager:" log="observations" signal="containerfs.available" resourceName="ephemeral-storage" available="162422356Ki" capacity="202051056Ki" time="2024-10-09 09:44:52.098300107 +0000 UTC"
I1009 09:44:52.906405  106124 helpers.go:972] "Eviction manager:" log="observations" signal="containerfs.inodesFree" resourceName="inodes" available="24743220" capacity="26083328" time="2024-10-09 09:44:52.098300107 +0000 UTC"
I1009 09:44:52.906409  106124 helpers.go:972] "Eviction manager:" log="observations" signal="memory.available" resourceName="memory" available="12063344Ki" capacity="16376164Ki" time="2024-10-09 09:44:52.900421977 +0000 UTC m=+30.105936483"
I1009 09:44:52.906414  106124 helpers.go:972] "Eviction manager:" log="observations" signal="nodefs.available" resourceName="ephemeral-storage" available="162422356Ki" capacity="202051056Ki" time="2024-10-09 09:44:52.900421977 +0000 UTC m=+30.105936483"
I1009 09:44:52.906418  106124 helpers.go:972] "Eviction manager:" log="observations" signal="imagefs.available" resourceName="ephemeral-storage" available="162422356Ki" capacity="202051056Ki" time="2024-10-09 09:44:52.098300107 +0000 UTC"
I1009 09:44:52.906424  106124 helpers.go:972] "Eviction manager:" log="observations" signal="imagefs.inodesFree" resourceName="inodes" available="24743220" capacity="26083328" time="2024-10-09 09:44:52.098300107 +0000 UTC"
I1009 09:44:52.906441  106124 eviction_manager.go:359] "Eviction manager: no resources are starved"
I1009 09:44:52.937658  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:44:53.815978  106124 interface.go:432] Looking for default routes with IPv4 addresses
I1009 09:44:53.816014  106124 interface.go:437] Default route transits interface "eth0"
I1009 09:44:53.816172  106124 interface.go:209] Interface eth0 is up
I1009 09:44:53.816231  106124 interface.go:257] Interface "eth0" has 3 addresses :[82.112.230.236/24 2a02:4780:12:eebf::1/48 fe80::be24:11ff:fe5a:b1d8/64].
I1009 09:44:53.816248  106124 interface.go:224] Checking addr  82.112.230.236/24.
I1009 09:44:53.816256  106124 interface.go:231] IP found 82.112.230.236
I1009 09:44:53.816263  106124 interface.go:263] Found valid IPv4 address 82.112.230.236 for interface "eth0".
I1009 09:44:53.816272  106124 interface.go:443] Found active IP 82.112.230.236 
I1009 09:44:53.939874  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:44:54.872199  106124 kubelet.go:2509] "SyncLoop (housekeeping)"
I1009 09:44:54.873752  106124 kubelet_pods.go:1151] "Clean up pod workers for terminated pods"
I1009 09:44:54.874964  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=false
I1009 09:44:54.875015  106124 kubelet_pods.go:1201] "Clean up probes for terminated pods"
I1009 09:44:54.875026  106124 kubelet_pods.go:1205] "Clean up orphaned pod statuses"
I1009 09:44:54.875037  106124 kubelet_pods.go:1209] "Clean up orphaned pod user namespace allocations"
I1009 09:44:54.875049  106124 kubelet_pods.go:1221] "Clean up orphaned pod directories"
I1009 09:44:54.875121  106124 kubelet_pods.go:1232] "Clean up orphaned mirror pods"
I1009 09:44:54.875165  106124 kubelet_pods.go:1374] "Clean up orphaned pod cgroups"
I1009 09:44:54.875183  106124 kubelet.go:2517] "SyncLoop (housekeeping) end" duration="3ms"
I1009 09:44:54.941678  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:44:55.943644  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:44:55.973715  106124 handler.go:293] error while reading "/proc/106124/fd/23" link: readlink /proc/106124/fd/23: no such file or directory
I1009 09:44:56.872201  106124 kubelet.go:2461] "SyncLoop (SYNC) pods" total=1 pods=["prestop-hook-test-3521/test-pod"]
I1009 09:44:56.872259  106124 pod_workers.go:963] "Notifying pod of pending update" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c" workType="sync"
I1009 09:44:56.872295  106124 kubelet.go:2509] "SyncLoop (housekeeping)"
I1009 09:44:56.872388  106124 pod_workers.go:1233] "Processing pod event" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c" updateType="sync"
I1009 09:44:56.872415  106124 kubelet.go:1761] "SyncPod enter" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c"
I1009 09:44:56.872425  106124 kubelet_pods.go:1774] "Generating pod status" podIsTerminal=false pod="prestop-hook-test-3521/test-pod"
I1009 09:44:56.872525  106124 kubelet_pods.go:1787] "Got phase for pod" pod="prestop-hook-test-3521/test-pod" oldPhase="Running" phase="Running"
I1009 09:44:56.872616  106124 status_manager.go:691] "Ignoring same status for pod" pod="prestop-hook-test-3521/test-pod" status={"phase":"Running","conditions":[{"type":"PodReadyToStartContainers","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-10-09T09:44:24Z"},{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-10-09T09:44:23Z"},{"type":"Ready","status":"False","lastProbeTime":null,"lastTransitionTime":"2024-10-09T09:44:23Z","reason":"ContainersNotReady","message":"containers with unready status: [regular-1]"},{"type":"ContainersReady","status":"False","lastProbeTime":null,"lastTransitionTime":"2024-10-09T09:44:23Z","reason":"ContainersNotReady","message":"containers with unready status: [regular-1]"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-10-09T09:44:23Z"}],"hostIP":"82.112.230.236","hostIPs":[{"ip":"82.112.230.236"}],"podIP":"10.10.0.97","podIPs":[{"ip":"10.10.0.97"}],"startTime":"2024-10-09T09:44:23Z","containerStatuses":[{"name":"regular-1","state":{"running":{"startedAt":"2024-10-09T09:44:24Z"}},"lastState":{},"ready":false,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/busybox:1.36.1-1","imageID":"registry.k8s.io/e2e-test-images/busybox@sha256:a9155b13325b2abef48e71de77bb8ac015412a566829f621d06bfae5c699b1b9","containerID":"containerd://08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5","started":false,"volumeMounts":[{"name":"persistent","mountPath":"/persistent"}]}],"qosClass":"Burstable"}
I1009 09:44:56.872776  106124 volume_manager.go:404] "Waiting for volumes to attach and mount for pod" pod="prestop-hook-test-3521/test-pod"
I1009 09:44:56.872800  106124 volume_manager.go:440] "All volumes are attached and mounted for pod" pod="prestop-hook-test-3521/test-pod"
I1009 09:44:56.872848  106124 kuberuntime_manager.go:1027] "Message for Container of pod" containerName="regular-1" containerStatusID={"Type":"containerd","ID":"08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5"} pod="prestop-hook-test-3521/test-pod" containerMessage="Container regular-1 failed startup probe"
I1009 09:44:56.872860  106124 kuberuntime_manager.go:1055] "computePodActions got for pod" podActions="KillPod: true, CreateSandbox: false, UpdatePodResources: false, Attempt: 0, InitContainersToStart: [], ContainersToStart: [], EphemeralContainersToStart: [],ContainersToUpdate: map[], ContainersToKill: map[{containerd 08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5}:{0xc0012dde00 regular-1 Container regular-1 failed startup probe StartupProbe}]" pod="prestop-hook-test-3521/test-pod"
I1009 09:44:56.872884  106124 kuberuntime_manager.go:1073] "Stopping PodSandbox for pod, because all other containers are dead" pod="prestop-hook-test-3521/test-pod"
I1009 09:44:56.872921  106124 kuberuntime_container.go:683] "Running preStop hook" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c" containerName="regular-1" containerID="containerd://08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5"
I1009 09:44:56.873041  106124 event.go:389] "Event occurred" object="prestop-hook-test-3521/test-pod" fieldPath="spec.containers{regular-1}" kind="Pod" apiVersion="v1" type="Normal" reason="Killing" message="Stopping container regular-1"
I1009 09:44:56.873614  106124 kubelet_pods.go:1151] "Clean up pod workers for terminated pods"
I1009 09:44:56.874714  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=false
I1009 09:44:56.874760  106124 kubelet_pods.go:1201] "Clean up probes for terminated pods"
I1009 09:44:56.874766  106124 kubelet_pods.go:1205] "Clean up orphaned pod statuses"
I1009 09:44:56.874772  106124 kubelet_pods.go:1209] "Clean up orphaned pod user namespace allocations"
I1009 09:44:56.874778  106124 kubelet_pods.go:1221] "Clean up orphaned pod directories"
I1009 09:44:56.874812  106124 kubelet_pods.go:1232] "Clean up orphaned mirror pods"
I1009 09:44:56.874852  106124 kubelet_pods.go:1374] "Clean up orphaned pod cgroups"
I1009 09:44:56.874860  106124 kubelet.go:2517] "SyncLoop (housekeeping) end" duration="3ms"
I1009 09:44:56.945596  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:44:56.971780  106124 desired_state_of_world.go:308] "expected volume SELinux label context" volume="persistent" label=""
I1009 09:44:56.971822  106124 desired_state_of_world_populator.go:329] "Added volume to desired state" pod="prestop-hook-test-3521/test-pod" volumeName="persistent" volumeSpecName="persistent"
I1009 09:44:57.891498  106124 kubelet.go:2898] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:; Handlers: , Features: nil"
I1009 09:44:57.928311  106124 kuberuntime_container.go:703] "PreStop hook completed" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c" containerName="regular-1" containerID="containerd://08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5"
I1009 09:44:57.928354  106124 kuberuntime_container.go:808] "Killing container with a grace period" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c" containerName="regular-1" containerID="containerd://08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5" gracePeriod=29
I1009 09:44:57.947279  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:44:58.075045  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/kubelet.service"
I1009 09:44:58.075098  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/kubelet.service"
I1009 09:44:58.075108  106124 factory.go:272] Factory "raw" can handle container "/system.slice/kubelet.service", but ignoring.
I1009 09:44:58.075119  106124 manager.go:929] ignoring container "/system.slice/kubelet.service"
I1009 09:44:58.872573  106124 kubelet.go:2509] "SyncLoop (housekeeping)"
I1009 09:44:58.873928  106124 kubelet_pods.go:1151] "Clean up pod workers for terminated pods"
I1009 09:44:58.875045  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=false
I1009 09:44:58.875091  106124 kubelet_pods.go:1201] "Clean up probes for terminated pods"
I1009 09:44:58.875098  106124 kubelet_pods.go:1205] "Clean up orphaned pod statuses"
I1009 09:44:58.875107  106124 kubelet_pods.go:1209] "Clean up orphaned pod user namespace allocations"
I1009 09:44:58.875118  106124 kubelet_pods.go:1221] "Clean up orphaned pod directories"
I1009 09:44:58.875195  106124 kubelet_pods.go:1232] "Clean up orphaned mirror pods"
I1009 09:44:58.875238  106124 kubelet_pods.go:1374] "Clean up orphaned pod cgroups"
I1009 09:44:58.875255  106124 kubelet.go:2517] "SyncLoop (housekeeping) end" duration="3ms"
I1009 09:44:58.949243  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:44:59.951406  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:45:00.872160  106124 kubelet.go:2509] "SyncLoop (housekeeping)"
I1009 09:45:00.873912  106124 kubelet_pods.go:1151] "Clean up pod workers for terminated pods"
I1009 09:45:00.875569  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=false
I1009 09:45:00.875607  106124 kubelet_pods.go:1201] "Clean up probes for terminated pods"
I1009 09:45:00.875613  106124 kubelet_pods.go:1205] "Clean up orphaned pod statuses"
I1009 09:45:00.875620  106124 kubelet_pods.go:1209] "Clean up orphaned pod user namespace allocations"
I1009 09:45:00.875628  106124 kubelet_pods.go:1221] "Clean up orphaned pod directories"
I1009 09:45:00.875693  106124 kubelet_pods.go:1232] "Clean up orphaned mirror pods"
I1009 09:45:00.875724  106124 kubelet_pods.go:1374] "Clean up orphaned pod cgroups"
I1009 09:45:00.875735  106124 kubelet.go:2517] "SyncLoop (housekeeping) end" duration="4ms"
I1009 09:45:00.954444  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:45:01.076563  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/monarx-agent.service"
I1009 09:45:01.077414  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/monarx-agent.service"
I1009 09:45:01.077430  106124 factory.go:272] Factory "raw" can handle container "/system.slice/monarx-agent.service", but ignoring.
I1009 09:45:01.077442  106124 manager.go:929] ignoring container "/system.slice/monarx-agent.service"
I1009 09:45:01.968317  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:45:02.851233  106124 config.go:292] "Setting pods for source" source="file"
I1009 09:45:02.871611  106124 kubelet.go:2509] "SyncLoop (housekeeping)"
I1009 09:45:02.871668  106124 status_manager.go:230] "Syncing all statuses"
I1009 09:45:02.872957  106124 kubelet_pods.go:1151] "Clean up pod workers for terminated pods"
I1009 09:45:02.874530  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=false
I1009 09:45:02.874569  106124 kubelet_pods.go:1201] "Clean up probes for terminated pods"
I1009 09:45:02.874576  106124 kubelet_pods.go:1205] "Clean up orphaned pod statuses"
I1009 09:45:02.874584  106124 kubelet_pods.go:1209] "Clean up orphaned pod user namespace allocations"
I1009 09:45:02.874595  106124 kubelet_pods.go:1221] "Clean up orphaned pod directories"
I1009 09:45:02.874659  106124 kubelet_pods.go:1232] "Clean up orphaned mirror pods"
I1009 09:45:02.874693  106124 kubelet_pods.go:1374] "Clean up orphaned pod cgroups"
I1009 09:45:02.874705  106124 kubelet.go:2517] "SyncLoop (housekeeping) end" duration="3ms"
I1009 09:45:02.888325  106124 container_log_manager.go:238] "Starting container log rotation sequence"
I1009 09:45:02.889361  106124 container_log_manager.go:252] "Adding new entry to the queue for processing" id="08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5" name="regular-1" labels={"io.kubernetes.container.name":"regular-1","io.kubernetes.pod.name":"test-pod","io.kubernetes.pod.namespace":"prestop-hook-test-3521","io.kubernetes.pod.uid":"afd5e56f-a379-49e2-839a-186dcb64715c"}
I1009 09:45:02.892598  106124 kubelet.go:2898] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:; Handlers: , Features: nil"
I1009 09:45:02.908001  106124 eviction_manager.go:251] "Eviction manager: synchronize housekeeping"
I1009 09:45:02.908043  106124 eviction_manager.go:280] "FileSystem detection" DedicatedImageFs=false SplitImageFs=false
I1009 09:45:02.917719  106124 helpers.go:972] "Eviction manager:" log="observations" signal="nodefs.inodesFree" resourceName="inodes" available="24743220" capacity="26083328" time="2024-10-09 09:45:02.908675487 +0000 UTC m=+40.114189983"
I1009 09:45:02.917771  106124 helpers.go:972] "Eviction manager:" log="observations" signal="containerfs.inodesFree" resourceName="inodes" available="24743220" capacity="26083328" time="2024-10-09 09:45:02.09987454 +0000 UTC"
I1009 09:45:02.917783  106124 helpers.go:972] "Eviction manager:" log="observations" signal="imagefs.inodesFree" resourceName="inodes" available="24743220" capacity="26083328" time="2024-10-09 09:45:02.09987454 +0000 UTC"
I1009 09:45:02.917842  106124 helpers.go:972] "Eviction manager:" log="observations" signal="containerfs.available" resourceName="ephemeral-storage" available="162422328Ki" capacity="202051056Ki" time="2024-10-09 09:45:02.09987454 +0000 UTC"
I1009 09:45:02.917852  106124 helpers.go:972] "Eviction manager:" log="observations" signal="pid.available" resourceName="pids" available="127323" capacity="127664" time="2024-10-09 09:45:02.917258844 +0000 UTC m=+40.122773340"
I1009 09:45:02.917861  106124 helpers.go:972] "Eviction manager:" log="observations" signal="memory.available" resourceName="memory" available="12063492Ki" capacity="16376164Ki" time="2024-10-09 09:45:02.908675487 +0000 UTC m=+40.114189983"
I1009 09:45:02.917868  106124 helpers.go:972] "Eviction manager:" log="observations" signal="allocatableMemory.available" resourceName="memory" available="16371212Ki" capacity="16376164Ki" time="2024-10-09 09:45:02.917624237 +0000 UTC m=+40.123138733"
I1009 09:45:02.917874  106124 helpers.go:972] "Eviction manager:" log="observations" signal="nodefs.available" resourceName="ephemeral-storage" available="162422328Ki" capacity="202051056Ki" time="2024-10-09 09:45:02.908675487 +0000 UTC m=+40.114189983"
I1009 09:45:02.917881  106124 helpers.go:972] "Eviction manager:" log="observations" signal="imagefs.available" resourceName="ephemeral-storage" available="162422328Ki" capacity="202051056Ki" time="2024-10-09 09:45:02.09987454 +0000 UTC"
I1009 09:45:02.917904  106124 eviction_manager.go:359] "Eviction manager: no resources are starved"
I1009 09:45:02.973981  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:45:03.840553  106124 interface.go:432] Looking for default routes with IPv4 addresses
I1009 09:45:03.840588  106124 interface.go:437] Default route transits interface "eth0"
I1009 09:45:03.840734  106124 interface.go:209] Interface eth0 is up
I1009 09:45:03.840787  106124 interface.go:257] Interface "eth0" has 3 addresses :[82.112.230.236/24 2a02:4780:12:eebf::1/48 fe80::be24:11ff:fe5a:b1d8/64].
I1009 09:45:03.840804  106124 interface.go:224] Checking addr  82.112.230.236/24.
I1009 09:45:03.840812  106124 interface.go:231] IP found 82.112.230.236
I1009 09:45:03.840819  106124 interface.go:263] Found valid IPv4 address 82.112.230.236 for interface "eth0".
I1009 09:45:03.840825  106124 interface.go:443] Found active IP 82.112.230.236 
I1009 09:45:03.976376  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:45:04.872348  106124 kubelet.go:2509] "SyncLoop (housekeeping)"
I1009 09:45:04.873826  106124 kubelet_pods.go:1151] "Clean up pod workers for terminated pods"
I1009 09:45:04.874961  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=false
I1009 09:45:04.874989  106124 kubelet_pods.go:1201] "Clean up probes for terminated pods"
I1009 09:45:04.874998  106124 kubelet_pods.go:1205] "Clean up orphaned pod statuses"
I1009 09:45:04.875005  106124 kubelet_pods.go:1209] "Clean up orphaned pod user namespace allocations"
I1009 09:45:04.875012  106124 kubelet_pods.go:1221] "Clean up orphaned pod directories"
I1009 09:45:04.875060  106124 kubelet_pods.go:1232] "Clean up orphaned mirror pods"
I1009 09:45:04.875100  106124 kubelet_pods.go:1374] "Clean up orphaned pod cgroups"
I1009 09:45:04.875111  106124 kubelet.go:2517] "SyncLoop (housekeeping) end" duration="3ms"
I1009 09:45:04.977942  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:45:05.979591  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:45:06.194894  106124 handler.go:293] error while reading "/proc/106124/fd/23" link: readlink /proc/106124/fd/23: no such file or directory
I1009 09:45:06.872428  106124 kubelet.go:2509] "SyncLoop (housekeeping)"
I1009 09:45:06.874060  106124 kubelet_pods.go:1151] "Clean up pod workers for terminated pods"
I1009 09:45:06.875559  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=false
I1009 09:45:06.875605  106124 kubelet_pods.go:1201] "Clean up probes for terminated pods"
I1009 09:45:06.875630  106124 kubelet_pods.go:1205] "Clean up orphaned pod statuses"
I1009 09:45:06.875639  106124 kubelet_pods.go:1209] "Clean up orphaned pod user namespace allocations"
I1009 09:45:06.875651  106124 kubelet_pods.go:1221] "Clean up orphaned pod directories"
I1009 09:45:06.875715  106124 kubelet_pods.go:1232] "Clean up orphaned mirror pods"
I1009 09:45:06.875746  106124 kubelet_pods.go:1374] "Clean up orphaned pod cgroups"
I1009 09:45:06.875758  106124 kubelet.go:2517] "SyncLoop (housekeeping) end" duration="3ms"
I1009 09:45:06.981434  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:45:07.894111  106124 kubelet.go:2898] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:; Handlers: , Features: nil"
I1009 09:45:07.983820  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:45:08.325345  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/kubelet.service"
I1009 09:45:08.325383  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/kubelet.service"
I1009 09:45:08.325392  106124 factory.go:272] Factory "raw" can handle container "/system.slice/kubelet.service", but ignoring.
I1009 09:45:08.325401  106124 manager.go:929] ignoring container "/system.slice/kubelet.service"
I1009 09:45:08.872551  106124 kubelet.go:2509] "SyncLoop (housekeeping)"
I1009 09:45:08.874147  106124 kubelet_pods.go:1151] "Clean up pod workers for terminated pods"
I1009 09:45:08.875316  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=false
I1009 09:45:08.875357  106124 kubelet_pods.go:1201] "Clean up probes for terminated pods"
I1009 09:45:08.875364  106124 kubelet_pods.go:1205] "Clean up orphaned pod statuses"
I1009 09:45:08.875371  106124 kubelet_pods.go:1209] "Clean up orphaned pod user namespace allocations"
I1009 09:45:08.875379  106124 kubelet_pods.go:1221] "Clean up orphaned pod directories"
I1009 09:45:08.875441  106124 kubelet_pods.go:1232] "Clean up orphaned mirror pods"
I1009 09:45:08.875503  106124 kubelet_pods.go:1374] "Clean up orphaned pod cgroups"
I1009 09:45:08.875518  106124 kubelet.go:2517] "SyncLoop (housekeeping) end" duration="3ms"
I1009 09:45:08.985099  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:45:09.987513  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:45:10.872167  106124 kubelet.go:2509] "SyncLoop (housekeeping)"
I1009 09:45:10.873585  106124 kubelet_pods.go:1151] "Clean up pod workers for terminated pods"
I1009 09:45:10.874694  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=false
I1009 09:45:10.874716  106124 kubelet_pods.go:1201] "Clean up probes for terminated pods"
I1009 09:45:10.874723  106124 kubelet_pods.go:1205] "Clean up orphaned pod statuses"
I1009 09:45:10.874731  106124 kubelet_pods.go:1209] "Clean up orphaned pod user namespace allocations"
I1009 09:45:10.874741  106124 kubelet_pods.go:1221] "Clean up orphaned pod directories"
I1009 09:45:10.874789  106124 kubelet_pods.go:1232] "Clean up orphaned mirror pods"
I1009 09:45:10.874821  106124 kubelet_pods.go:1374] "Clean up orphaned pod cgroups"
I1009 09:45:10.874833  106124 kubelet.go:2517] "SyncLoop (housekeeping) end" duration="3ms"
I1009 09:45:10.989446  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:45:11.991400  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:45:12.850092  106124 config.go:292] "Setting pods for source" source="file"
I1009 09:45:12.871843  106124 kubelet.go:2509] "SyncLoop (housekeeping)"
I1009 09:45:12.871866  106124 status_manager.go:230] "Syncing all statuses"
I1009 09:45:12.873080  106124 kubelet_pods.go:1151] "Clean up pod workers for terminated pods"
I1009 09:45:12.874021  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=false
I1009 09:45:12.874042  106124 kubelet_pods.go:1201] "Clean up probes for terminated pods"
I1009 09:45:12.874060  106124 kubelet_pods.go:1205] "Clean up orphaned pod statuses"
I1009 09:45:12.874066  106124 kubelet_pods.go:1209] "Clean up orphaned pod user namespace allocations"
I1009 09:45:12.874073  106124 kubelet_pods.go:1221] "Clean up orphaned pod directories"
I1009 09:45:12.874115  106124 kubelet_pods.go:1232] "Clean up orphaned mirror pods"
I1009 09:45:12.874147  106124 kubelet_pods.go:1374] "Clean up orphaned pod cgroups"
I1009 09:45:12.874155  106124 kubelet.go:2517] "SyncLoop (housekeeping) end" duration="2ms"
I1009 09:45:12.890344  106124 container_log_manager.go:238] "Starting container log rotation sequence"
I1009 09:45:12.891237  106124 container_log_manager.go:252] "Adding new entry to the queue for processing" id="08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5" name="regular-1" labels={"io.kubernetes.container.name":"regular-1","io.kubernetes.pod.name":"test-pod","io.kubernetes.pod.namespace":"prestop-hook-test-3521","io.kubernetes.pod.uid":"afd5e56f-a379-49e2-839a-186dcb64715c"}
I1009 09:45:12.895070  106124 kubelet.go:2898] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:; Handlers: , Features: nil"
I1009 09:45:12.918640  106124 eviction_manager.go:251] "Eviction manager: synchronize housekeeping"
I1009 09:45:12.918679  106124 eviction_manager.go:280] "FileSystem detection" DedicatedImageFs=false SplitImageFs=false
I1009 09:45:12.925479  106124 helpers.go:972] "Eviction manager:" log="observations" signal="memory.available" resourceName="memory" available="12063048Ki" capacity="16376164Ki" time="2024-10-09 09:45:12.919130522 +0000 UTC m=+50.124645018"
I1009 09:45:12.925518  106124 helpers.go:972] "Eviction manager:" log="observations" signal="allocatableMemory.available" resourceName="memory" available="16371212Ki" capacity="16376164Ki" time="2024-10-09 09:45:12.925344584 +0000 UTC m=+50.130859090"
I1009 09:45:12.925524  106124 helpers.go:972] "Eviction manager:" log="observations" signal="nodefs.inodesFree" resourceName="inodes" available="24743220" capacity="26083328" time="2024-10-09 09:45:12.919130522 +0000 UTC m=+50.124645018"
I1009 09:45:12.925530  106124 helpers.go:972] "Eviction manager:" log="observations" signal="imagefs.available" resourceName="ephemeral-storage" available="162422312Ki" capacity="202051056Ki" time="2024-10-09 09:45:12.098211404 +0000 UTC"
I1009 09:45:12.925535  106124 helpers.go:972] "Eviction manager:" log="observations" signal="imagefs.inodesFree" resourceName="inodes" available="24743220" capacity="26083328" time="2024-10-09 09:45:12.098211404 +0000 UTC"
I1009 09:45:12.925540  106124 helpers.go:972] "Eviction manager:" log="observations" signal="containerfs.available" resourceName="ephemeral-storage" available="162422312Ki" capacity="202051056Ki" time="2024-10-09 09:45:12.098211404 +0000 UTC"
I1009 09:45:12.925547  106124 helpers.go:972] "Eviction manager:" log="observations" signal="containerfs.inodesFree" resourceName="inodes" available="24743220" capacity="26083328" time="2024-10-09 09:45:12.098211404 +0000 UTC"
I1009 09:45:12.925554  106124 helpers.go:972] "Eviction manager:" log="observations" signal="pid.available" resourceName="pids" available="127324" capacity="127664" time="2024-10-09 09:45:12.925061662 +0000 UTC m=+50.130576157"
I1009 09:45:12.925561  106124 helpers.go:972] "Eviction manager:" log="observations" signal="nodefs.available" resourceName="ephemeral-storage" available="162422312Ki" capacity="202051056Ki" time="2024-10-09 09:45:12.919130522 +0000 UTC m=+50.124645018"
I1009 09:45:12.925583  106124 eviction_manager.go:359] "Eviction manager: no resources are starved"
I1009 09:45:12.993510  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:45:13.864285  106124 interface.go:432] Looking for default routes with IPv4 addresses
I1009 09:45:13.864319  106124 interface.go:437] Default route transits interface "eth0"
I1009 09:45:13.864527  106124 interface.go:209] Interface eth0 is up
I1009 09:45:13.864611  106124 interface.go:257] Interface "eth0" has 3 addresses :[82.112.230.236/24 2a02:4780:12:eebf::1/48 fe80::be24:11ff:fe5a:b1d8/64].
I1009 09:45:13.864629  106124 interface.go:224] Checking addr  82.112.230.236/24.
I1009 09:45:13.864637  106124 interface.go:231] IP found 82.112.230.236
I1009 09:45:13.864643  106124 interface.go:263] Found valid IPv4 address 82.112.230.236 for interface "eth0".
I1009 09:45:13.864649  106124 interface.go:443] Found active IP 82.112.230.236 
I1009 09:45:13.994860  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:45:14.871841  106124 kubelet.go:2509] "SyncLoop (housekeeping)"
I1009 09:45:14.873071  106124 kubelet_pods.go:1151] "Clean up pod workers for terminated pods"
I1009 09:45:14.873952  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=false
I1009 09:45:14.873974  106124 kubelet_pods.go:1201] "Clean up probes for terminated pods"
I1009 09:45:14.873982  106124 kubelet_pods.go:1205] "Clean up orphaned pod statuses"
I1009 09:45:14.873989  106124 kubelet_pods.go:1209] "Clean up orphaned pod user namespace allocations"
I1009 09:45:14.873998  106124 kubelet_pods.go:1221] "Clean up orphaned pod directories"
I1009 09:45:14.874042  106124 kubelet_pods.go:1232] "Clean up orphaned mirror pods"
I1009 09:45:14.874076  106124 kubelet_pods.go:1374] "Clean up orphaned pod cgroups"
I1009 09:45:14.874091  106124 kubelet.go:2517] "SyncLoop (housekeeping) end" duration="2ms"
I1009 09:45:14.997071  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:45:15.998970  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:45:16.872600  106124 kubelet.go:2509] "SyncLoop (housekeeping)"
I1009 09:45:16.873828  106124 kubelet_pods.go:1151] "Clean up pod workers for terminated pods"
I1009 09:45:16.874874  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=false
I1009 09:45:16.874913  106124 kubelet_pods.go:1201] "Clean up probes for terminated pods"
I1009 09:45:16.874921  106124 kubelet_pods.go:1205] "Clean up orphaned pod statuses"
I1009 09:45:16.874930  106124 kubelet_pods.go:1209] "Clean up orphaned pod user namespace allocations"
I1009 09:45:16.874941  106124 kubelet_pods.go:1221] "Clean up orphaned pod directories"
I1009 09:45:16.874993  106124 kubelet_pods.go:1232] "Clean up orphaned mirror pods"
I1009 09:45:16.875022  106124 kubelet_pods.go:1374] "Clean up orphaned pod cgroups"
I1009 09:45:16.875032  106124 kubelet.go:2517] "SyncLoop (housekeeping) end" duration="2ms"
I1009 09:45:17.002287  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:45:17.896265  106124 kubelet.go:2898] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:; Handlers: , Features: nil"
I1009 09:45:18.004391  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:45:18.575527  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/kubelet.service"
I1009 09:45:18.575574  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/kubelet.service"
I1009 09:45:18.575584  106124 factory.go:272] Factory "raw" can handle container "/system.slice/kubelet.service", but ignoring.
I1009 09:45:18.575592  106124 manager.go:929] ignoring container "/system.slice/kubelet.service"
I1009 09:45:18.872530  106124 kubelet.go:2509] "SyncLoop (housekeeping)"
I1009 09:45:18.874019  106124 kubelet_pods.go:1151] "Clean up pod workers for terminated pods"
I1009 09:45:18.875060  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=false
I1009 09:45:18.875080  106124 kubelet_pods.go:1201] "Clean up probes for terminated pods"
I1009 09:45:18.875087  106124 kubelet_pods.go:1205] "Clean up orphaned pod statuses"
I1009 09:45:18.875099  106124 kubelet_pods.go:1209] "Clean up orphaned pod user namespace allocations"
I1009 09:45:18.875109  106124 kubelet_pods.go:1221] "Clean up orphaned pod directories"
I1009 09:45:18.875170  106124 kubelet_pods.go:1232] "Clean up orphaned mirror pods"
I1009 09:45:18.875203  106124 kubelet_pods.go:1374] "Clean up orphaned pod cgroups"
I1009 09:45:18.875214  106124 kubelet.go:2517] "SyncLoop (housekeeping) end" duration="3ms"
I1009 09:45:19.007666  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:45:20.008994  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:45:20.872115  106124 kubelet.go:2509] "SyncLoop (housekeeping)"
I1009 09:45:20.873573  106124 kubelet_pods.go:1151] "Clean up pod workers for terminated pods"
I1009 09:45:20.874812  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=false
I1009 09:45:20.874859  106124 kubelet_pods.go:1201] "Clean up probes for terminated pods"
I1009 09:45:20.874867  106124 kubelet_pods.go:1205] "Clean up orphaned pod statuses"
I1009 09:45:20.874879  106124 kubelet_pods.go:1209] "Clean up orphaned pod user namespace allocations"
I1009 09:45:20.874889  106124 kubelet_pods.go:1221] "Clean up orphaned pod directories"
I1009 09:45:20.874952  106124 kubelet_pods.go:1232] "Clean up orphaned mirror pods"
I1009 09:45:20.874993  106124 kubelet_pods.go:1374] "Clean up orphaned pod cgroups"
I1009 09:45:20.875008  106124 kubelet.go:2517] "SyncLoop (housekeeping) end" duration="3ms"
I1009 09:45:21.010338  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:45:22.012318  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:45:22.849223  106124 config.go:292] "Setting pods for source" source="file"
I1009 09:45:22.860178  106124 kuberuntime_container.go:1302] "Removing container" containerID="a4fe23cc464877e9d3bc6c1826e24fa4b80f81e9eb51fd13324ddd4492e45e26"
I1009 09:45:22.860225  106124 scope.go:117] "RemoveContainer" containerID="a4fe23cc464877e9d3bc6c1826e24fa4b80f81e9eb51fd13324ddd4492e45e26"
I1009 09:45:22.867715  106124 kuberuntime_gc.go:175] "Removing sandbox" sandboxID="d2140c7c68378b3ca1e26ec4ba9259a41b6f0b815b2c7dfef672e7467f4b897e"
I1009 09:45:22.871440  106124 status_manager.go:230] "Syncing all statuses"
I1009 09:45:22.871468  106124 kubelet.go:2509] "SyncLoop (housekeeping)"
I1009 09:45:22.872778  106124 kubelet_pods.go:1151] "Clean up pod workers for terminated pods"
I1009 09:45:22.873567  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=false
I1009 09:45:22.873582  106124 kubelet_pods.go:1201] "Clean up probes for terminated pods"
I1009 09:45:22.873587  106124 kubelet_pods.go:1205] "Clean up orphaned pod statuses"
I1009 09:45:22.873593  106124 kubelet_pods.go:1209] "Clean up orphaned pod user namespace allocations"
I1009 09:45:22.873599  106124 kubelet_pods.go:1221] "Clean up orphaned pod directories"
I1009 09:45:22.873635  106124 kubelet_pods.go:1232] "Clean up orphaned mirror pods"
I1009 09:45:22.873667  106124 kubelet_pods.go:1374] "Clean up orphaned pod cgroups"
I1009 09:45:22.873682  106124 kubelet.go:2517] "SyncLoop (housekeeping) end" duration="2ms"
I1009 09:45:22.880992  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/lxd-installer.socket"
I1009 09:45:22.881023  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/lxd-installer.socket"
I1009 09:45:22.881032  106124 factory.go:272] Factory "raw" can handle container "/system.slice/lxd-installer.socket", but ignoring.
I1009 09:45:22.881042  106124 manager.go:929] ignoring container "/system.slice/lxd-installer.socket"
I1009 09:45:22.881047  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/cloud-init-local.service"
I1009 09:45:22.881052  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/cloud-init-local.service"
I1009 09:45:22.881058  106124 factory.go:272] Factory "raw" can handle container "/system.slice/cloud-init-local.service", but ignoring.
I1009 09:45:22.881064  106124 manager.go:929] ignoring container "/system.slice/cloud-init-local.service"
I1009 09:45:22.881074  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/systemd-udevd.service"
I1009 09:45:22.881093  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/systemd-udevd.service"
I1009 09:45:22.881099  106124 factory.go:272] Factory "raw" can handle container "/system.slice/systemd-udevd.service", but ignoring.
I1009 09:45:22.881105  106124 manager.go:929] ignoring container "/system.slice/systemd-udevd.service"
I1009 09:45:22.881111  106124 factory.go:279] Factory "systemd" was unable to handle container "/user.slice/user-0.slice/user@0.service/init.scope"
I1009 09:45:22.881115  106124 factory.go:279] Factory "containerd" was unable to handle container "/user.slice/user-0.slice/user@0.service/init.scope"
I1009 09:45:22.881123  106124 factory.go:272] Factory "raw" can handle container "/user.slice/user-0.slice/user@0.service/init.scope", but ignoring.
I1009 09:45:22.881129  106124 manager.go:929] ignoring container "/user.slice/user-0.slice/user@0.service/init.scope"
I1009 09:45:22.881134  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/cloud-final.service"
I1009 09:45:22.881139  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/cloud-final.service"
I1009 09:45:22.881142  106124 factory.go:272] Factory "raw" can handle container "/system.slice/cloud-final.service", but ignoring.
I1009 09:45:22.881153  106124 manager.go:929] ignoring container "/system.slice/cloud-final.service"
I1009 09:45:22.881163  106124 factory.go:279] Factory "systemd" was unable to handle container "/user.slice/user-0.slice/user@0.service/app.slice/dbus.socket"
I1009 09:45:22.881170  106124 factory.go:279] Factory "containerd" was unable to handle container "/user.slice/user-0.slice/user@0.service/app.slice/dbus.socket"
I1009 09:45:22.881174  106124 factory.go:272] Factory "raw" can handle container "/user.slice/user-0.slice/user@0.service/app.slice/dbus.socket", but ignoring.
I1009 09:45:22.881180  106124 manager.go:929] ignoring container "/user.slice/user-0.slice/user@0.service/app.slice/dbus.socket"
I1009 09:45:22.881187  106124 factory.go:279] Factory "systemd" was unable to handle container "/user.slice"
I1009 09:45:22.881192  106124 factory.go:279] Factory "containerd" was unable to handle container "/user.slice"
I1009 09:45:22.881202  106124 factory.go:272] Factory "raw" can handle container "/user.slice", but ignoring.
I1009 09:45:22.881208  106124 manager.go:929] ignoring container "/user.slice"
I1009 09:45:22.881214  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/containerd.service"
I1009 09:45:22.881219  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/containerd.service"
I1009 09:45:22.881224  106124 factory.go:272] Factory "raw" can handle container "/system.slice/containerd.service", but ignoring.
I1009 09:45:22.881230  106124 manager.go:929] ignoring container "/system.slice/containerd.service"
I1009 09:45:22.881235  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/systemd-networkd.service"
I1009 09:45:22.881238  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/systemd-networkd.service"
I1009 09:45:22.881241  106124 factory.go:272] Factory "raw" can handle container "/system.slice/systemd-networkd.service", but ignoring.
I1009 09:45:22.881245  106124 manager.go:929] ignoring container "/system.slice/systemd-networkd.service"
I1009 09:45:22.881249  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/orthanc.service"
I1009 09:45:22.881252  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/orthanc.service"
I1009 09:45:22.881255  106124 factory.go:272] Factory "raw" can handle container "/system.slice/orthanc.service", but ignoring.
I1009 09:45:22.881258  106124 manager.go:929] ignoring container "/system.slice/orthanc.service"
I1009 09:45:22.881263  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/qemu-guest-agent.service"
I1009 09:45:22.881279  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/qemu-guest-agent.service"
I1009 09:45:22.881286  106124 factory.go:272] Factory "raw" can handle container "/system.slice/qemu-guest-agent.service", but ignoring.
I1009 09:45:22.881292  106124 manager.go:929] ignoring container "/system.slice/qemu-guest-agent.service"
I1009 09:45:22.881296  106124 factory.go:279] Factory "systemd" was unable to handle container "/user.slice/user-0.slice/session-78.scope"
I1009 09:45:22.881301  106124 factory.go:279] Factory "containerd" was unable to handle container "/user.slice/user-0.slice/session-78.scope"
I1009 09:45:22.881311  106124 factory.go:272] Factory "raw" can handle container "/user.slice/user-0.slice/session-78.scope", but ignoring.
I1009 09:45:22.881317  106124 manager.go:929] ignoring container "/user.slice/user-0.slice/session-78.scope"
I1009 09:45:22.881322  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice"
I1009 09:45:22.881326  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice"
I1009 09:45:22.881331  106124 factory.go:272] Factory "raw" can handle container "/system.slice", but ignoring.
I1009 09:45:22.881335  106124 manager.go:929] ignoring container "/system.slice"
I1009 09:45:22.881338  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/system-serial\\x2dgetty.slice/serial-getty@ttyS0.service"
I1009 09:45:22.881343  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/system-serial\\x2dgetty.slice/serial-getty@ttyS0.service"
I1009 09:45:22.881347  106124 factory.go:272] Factory "raw" can handle container "/system.slice/system-serial\\x2dgetty.slice/serial-getty@ttyS0.service", but ignoring.
I1009 09:45:22.881351  106124 manager.go:929] ignoring container "/system.slice/system-serial\\x2dgetty.slice/serial-getty@ttyS0.service"
I1009 09:45:22.881355  106124 factory.go:272] Factory "systemd" can handle container "/system.slice/boot-efi.mount", but ignoring.
I1009 09:45:22.881358  106124 manager.go:929] ignoring container "/system.slice/boot-efi.mount"
I1009 09:45:22.881362  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/system-getty.slice"
I1009 09:45:22.881365  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/system-getty.slice"
I1009 09:45:22.881369  106124 factory.go:272] Factory "raw" can handle container "/system.slice/system-getty.slice", but ignoring.
I1009 09:45:22.881374  106124 manager.go:929] ignoring container "/system.slice/system-getty.slice"
I1009 09:45:22.881379  106124 factory.go:272] Factory "systemd" can handle container "/proc-sys-fs-binfmt_misc.mount", but ignoring.
I1009 09:45:22.881384  106124 manager.go:929] ignoring container "/proc-sys-fs-binfmt_misc.mount"
I1009 09:45:22.881388  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/rsyslog.service"
I1009 09:45:22.881392  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/rsyslog.service"
I1009 09:45:22.881396  106124 factory.go:272] Factory "raw" can handle container "/system.slice/rsyslog.service", but ignoring.
I1009 09:45:22.881402  106124 manager.go:929] ignoring container "/system.slice/rsyslog.service"
I1009 09:45:22.881406  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/cloud-config.service"
I1009 09:45:22.881411  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/cloud-config.service"
I1009 09:45:22.881414  106124 factory.go:272] Factory "raw" can handle container "/system.slice/cloud-config.service", but ignoring.
I1009 09:45:22.881417  106124 manager.go:929] ignoring container "/system.slice/cloud-config.service"
I1009 09:45:22.881421  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/cloud-init.service"
I1009 09:45:22.881429  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/cloud-init.service"
I1009 09:45:22.881439  106124 factory.go:272] Factory "raw" can handle container "/system.slice/cloud-init.service", but ignoring.
I1009 09:45:22.881446  106124 manager.go:929] ignoring container "/system.slice/cloud-init.service"
I1009 09:45:22.881509  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/udisks2.service"
I1009 09:45:22.881518  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/udisks2.service"
I1009 09:45:22.881523  106124 factory.go:272] Factory "raw" can handle container "/system.slice/udisks2.service", but ignoring.
I1009 09:45:22.881529  106124 manager.go:929] ignoring container "/system.slice/udisks2.service"
I1009 09:45:22.881533  106124 factory.go:279] Factory "systemd" was unable to handle container "/user.slice/user-0.slice"
I1009 09:45:22.881537  106124 factory.go:279] Factory "containerd" was unable to handle container "/user.slice/user-0.slice"
I1009 09:45:22.881542  106124 factory.go:272] Factory "raw" can handle container "/user.slice/user-0.slice", but ignoring.
I1009 09:45:22.881548  106124 manager.go:929] ignoring container "/user.slice/user-0.slice"
I1009 09:45:22.881552  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/unattended-upgrades.service"
I1009 09:45:22.881557  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/unattended-upgrades.service"
I1009 09:45:22.881562  106124 factory.go:272] Factory "raw" can handle container "/system.slice/unattended-upgrades.service", but ignoring.
I1009 09:45:22.881567  106124 manager.go:929] ignoring container "/system.slice/unattended-upgrades.service"
I1009 09:45:22.881572  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/systemd-logind.service"
I1009 09:45:22.881576  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/systemd-logind.service"
I1009 09:45:22.881580  106124 factory.go:272] Factory "raw" can handle container "/system.slice/systemd-logind.service", but ignoring.
I1009 09:45:22.881585  106124 manager.go:929] ignoring container "/system.slice/systemd-logind.service"
I1009 09:45:22.881589  106124 factory.go:272] Factory "systemd" can handle container "/dev-hugepages.mount", but ignoring.
I1009 09:45:22.881594  106124 manager.go:929] ignoring container "/dev-hugepages.mount"
I1009 09:45:22.881598  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/polkit.service"
I1009 09:45:22.881602  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/polkit.service"
I1009 09:45:22.881606  106124 factory.go:272] Factory "raw" can handle container "/system.slice/polkit.service", but ignoring.
I1009 09:45:22.881612  106124 manager.go:929] ignoring container "/system.slice/polkit.service"
I1009 09:45:22.881616  106124 factory.go:279] Factory "systemd" was unable to handle container "/init.scope"
I1009 09:45:22.881620  106124 factory.go:279] Factory "containerd" was unable to handle container "/init.scope"
I1009 09:45:22.881624  106124 factory.go:272] Factory "raw" can handle container "/init.scope", but ignoring.
I1009 09:45:22.881630  106124 manager.go:929] ignoring container "/init.scope"
I1009 09:45:22.881634  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/nginx.service"
I1009 09:45:22.881639  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/nginx.service"
I1009 09:45:22.881643  106124 factory.go:272] Factory "raw" can handle container "/system.slice/nginx.service", but ignoring.
I1009 09:45:22.881649  106124 manager.go:929] ignoring container "/system.slice/nginx.service"
I1009 09:45:22.881653  106124 factory.go:279] Factory "systemd" was unable to handle container "/runtime.slice/kubelet-20241009T094422.service"
I1009 09:45:22.881666  106124 factory.go:279] Factory "containerd" was unable to handle container "/runtime.slice/kubelet-20241009T094422.service"
I1009 09:45:22.881671  106124 factory.go:272] Factory "raw" can handle container "/runtime.slice/kubelet-20241009T094422.service", but ignoring.
I1009 09:45:22.881676  106124 manager.go:929] ignoring container "/runtime.slice/kubelet-20241009T094422.service"
I1009 09:45:22.881680  106124 factory.go:272] Factory "systemd" can handle container "/sys-kernel-tracing.mount", but ignoring.
I1009 09:45:22.881684  106124 manager.go:929] ignoring container "/sys-kernel-tracing.mount"
I1009 09:45:22.881689  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/systemd-udevd.service/udev"
I1009 09:45:22.881693  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/systemd-udevd.service/udev"
I1009 09:45:22.881697  106124 factory.go:272] Factory "raw" can handle container "/system.slice/systemd-udevd.service/udev", but ignoring.
I1009 09:45:22.881702  106124 manager.go:929] ignoring container "/system.slice/systemd-udevd.service/udev"
I1009 09:45:22.881707  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/dbus.service"
I1009 09:45:22.881711  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/dbus.service"
I1009 09:45:22.881715  106124 factory.go:272] Factory "raw" can handle container "/system.slice/dbus.service", but ignoring.
I1009 09:45:22.881721  106124 manager.go:929] ignoring container "/system.slice/dbus.service"
I1009 09:45:22.881725  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/systemd-timesyncd.service"
I1009 09:45:22.881729  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/systemd-timesyncd.service"
I1009 09:45:22.881734  106124 factory.go:272] Factory "raw" can handle container "/system.slice/systemd-timesyncd.service", but ignoring.
I1009 09:45:22.881740  106124 manager.go:929] ignoring container "/system.slice/systemd-timesyncd.service"
I1009 09:45:22.881745  106124 factory.go:272] Factory "systemd" can handle container "/dev-mqueue.mount", but ignoring.
I1009 09:45:22.881750  106124 manager.go:929] ignoring container "/dev-mqueue.mount"
I1009 09:45:22.881755  106124 factory.go:279] Factory "systemd" was unable to handle container "/user.slice/user-0.slice/user@0.service"
I1009 09:45:22.881760  106124 factory.go:279] Factory "containerd" was unable to handle container "/user.slice/user-0.slice/user@0.service"
I1009 09:45:22.881765  106124 factory.go:272] Factory "raw" can handle container "/user.slice/user-0.slice/user@0.service", but ignoring.
I1009 09:45:22.881771  106124 manager.go:929] ignoring container "/user.slice/user-0.slice/user@0.service"
I1009 09:45:22.881775  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/ssh.socket"
I1009 09:45:22.881779  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/ssh.socket"
I1009 09:45:22.881783  106124 factory.go:272] Factory "raw" can handle container "/system.slice/ssh.socket", but ignoring.
I1009 09:45:22.881788  106124 manager.go:929] ignoring container "/system.slice/ssh.socket"
I1009 09:45:22.881792  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/system-modprobe.slice"
I1009 09:45:22.881796  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/system-modprobe.slice"
I1009 09:45:22.881801  106124 factory.go:272] Factory "raw" can handle container "/system.slice/system-modprobe.slice", but ignoring.
I1009 09:45:22.881807  106124 manager.go:929] ignoring container "/system.slice/system-modprobe.slice"
I1009 09:45:22.881811  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/ssh.service"
I1009 09:45:22.881815  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/ssh.service"
I1009 09:45:22.881825  106124 factory.go:272] Factory "raw" can handle container "/system.slice/ssh.service", but ignoring.
I1009 09:45:22.881830  106124 manager.go:929] ignoring container "/system.slice/ssh.service"
I1009 09:45:22.881834  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/multipathd.service"
I1009 09:45:22.881839  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/multipathd.service"
I1009 09:45:22.881844  106124 factory.go:272] Factory "raw" can handle container "/system.slice/multipathd.service", but ignoring.
I1009 09:45:22.881848  106124 manager.go:929] ignoring container "/system.slice/multipathd.service"
I1009 09:45:22.881853  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/ModemManager.service"
I1009 09:45:22.881856  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/ModemManager.service"
I1009 09:45:22.881861  106124 factory.go:272] Factory "raw" can handle container "/system.slice/ModemManager.service", but ignoring.
I1009 09:45:22.881867  106124 manager.go:929] ignoring container "/system.slice/ModemManager.service"
I1009 09:45:22.881872  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/systemd-resolved.service"
I1009 09:45:22.881876  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/systemd-resolved.service"
I1009 09:45:22.881881  106124 factory.go:272] Factory "raw" can handle container "/system.slice/systemd-resolved.service", but ignoring.
I1009 09:45:22.881886  106124 manager.go:929] ignoring container "/system.slice/systemd-resolved.service"
I1009 09:45:22.881890  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/system-getty.slice/getty@tty1.service"
I1009 09:45:22.881894  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/system-getty.slice/getty@tty1.service"
I1009 09:45:22.881899  106124 factory.go:272] Factory "raw" can handle container "/system.slice/system-getty.slice/getty@tty1.service", but ignoring.
I1009 09:45:22.881905  106124 manager.go:929] ignoring container "/system.slice/system-getty.slice/getty@tty1.service"
I1009 09:45:22.881909  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/system-serial\\x2dgetty.slice"
I1009 09:45:22.881914  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/system-serial\\x2dgetty.slice"
I1009 09:45:22.881919  106124 factory.go:272] Factory "raw" can handle container "/system.slice/system-serial\\x2dgetty.slice", but ignoring.
I1009 09:45:22.881924  106124 manager.go:929] ignoring container "/system.slice/system-serial\\x2dgetty.slice"
I1009 09:45:22.881929  106124 factory.go:279] Factory "systemd" was unable to handle container "/user.slice/user-0.slice/user@0.service/app.slice/gpg-agent-ssh.socket"
I1009 09:45:22.881934  106124 factory.go:279] Factory "containerd" was unable to handle container "/user.slice/user-0.slice/user@0.service/app.slice/gpg-agent-ssh.socket"
I1009 09:45:22.881939  106124 factory.go:272] Factory "raw" can handle container "/user.slice/user-0.slice/user@0.service/app.slice/gpg-agent-ssh.socket", but ignoring.
I1009 09:45:22.881944  106124 manager.go:929] ignoring container "/user.slice/user-0.slice/user@0.service/app.slice/gpg-agent-ssh.socket"
I1009 09:45:22.881950  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/cron.service"
I1009 09:45:22.881954  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/cron.service"
I1009 09:45:22.881959  106124 factory.go:272] Factory "raw" can handle container "/system.slice/cron.service", but ignoring.
I1009 09:45:22.881964  106124 manager.go:929] ignoring container "/system.slice/cron.service"
I1009 09:45:22.881968  106124 factory.go:272] Factory "systemd" can handle container "/sys-fs-fuse-connections.mount", but ignoring.
I1009 09:45:22.881974  106124 manager.go:929] ignoring container "/sys-fs-fuse-connections.mount"
I1009 09:45:22.881983  106124 factory.go:279] Factory "systemd" was unable to handle container "/user.slice/user-0.slice/session-66.scope"
I1009 09:45:22.881987  106124 factory.go:279] Factory "containerd" was unable to handle container "/user.slice/user-0.slice/session-66.scope"
I1009 09:45:22.881994  106124 factory.go:272] Factory "raw" can handle container "/user.slice/user-0.slice/session-66.scope", but ignoring.
I1009 09:45:22.881999  106124 manager.go:929] ignoring container "/user.slice/user-0.slice/session-66.scope"
I1009 09:45:22.882004  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/system-systemd\\x2dfsck.slice"
I1009 09:45:22.882008  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/system-systemd\\x2dfsck.slice"
I1009 09:45:22.882014  106124 factory.go:272] Factory "raw" can handle container "/system.slice/system-systemd\\x2dfsck.slice", but ignoring.
I1009 09:45:22.882020  106124 manager.go:929] ignoring container "/system.slice/system-systemd\\x2dfsck.slice"
I1009 09:45:22.882025  106124 factory.go:272] Factory "systemd" can handle container "/system.slice/boot.mount", but ignoring.
I1009 09:45:22.882028  106124 manager.go:929] ignoring container "/system.slice/boot.mount"
I1009 09:45:22.882032  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/systemd-journald.service"
I1009 09:45:22.882035  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/systemd-journald.service"
I1009 09:45:22.882038  106124 factory.go:272] Factory "raw" can handle container "/system.slice/systemd-journald.service", but ignoring.
I1009 09:45:22.882041  106124 manager.go:929] ignoring container "/system.slice/systemd-journald.service"
I1009 09:45:22.882045  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/snapd.socket"
I1009 09:45:22.882048  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/snapd.socket"
I1009 09:45:22.882051  106124 factory.go:272] Factory "raw" can handle container "/system.slice/snapd.socket", but ignoring.
I1009 09:45:22.882055  106124 manager.go:929] ignoring container "/system.slice/snapd.socket"
I1009 09:45:22.882058  106124 factory.go:272] Factory "systemd" can handle container "/sys-kernel-debug.mount", but ignoring.
I1009 09:45:22.882062  106124 manager.go:929] ignoring container "/sys-kernel-debug.mount"
I1009 09:45:22.882065  106124 factory.go:279] Factory "systemd" was unable to handle container "/user.slice/user-0.slice/user@0.service/app.slice"
I1009 09:45:22.882068  106124 factory.go:279] Factory "containerd" was unable to handle container "/user.slice/user-0.slice/user@0.service/app.slice"
I1009 09:45:22.882071  106124 factory.go:272] Factory "raw" can handle container "/user.slice/user-0.slice/user@0.service/app.slice", but ignoring.
I1009 09:45:22.882075  106124 manager.go:929] ignoring container "/user.slice/user-0.slice/user@0.service/app.slice"
I1009 09:45:22.882079  106124 factory.go:272] Factory "systemd" can handle container "/sys-kernel-config.mount", but ignoring.
I1009 09:45:22.882083  106124 manager.go:929] ignoring container "/sys-kernel-config.mount"
I1009 09:45:22.882086  106124 factory.go:279] Factory "systemd" was unable to handle container "/runtime.slice"
I1009 09:45:22.882089  106124 factory.go:279] Factory "containerd" was unable to handle container "/runtime.slice"
I1009 09:45:22.882092  106124 factory.go:272] Factory "raw" can handle container "/runtime.slice", but ignoring.
I1009 09:45:22.882095  106124 manager.go:929] ignoring container "/runtime.slice"
I1009 09:45:22.884440  106124 qos_container_manager_linux.go:383] "Updated QoS cgroup configuration"
I1009 09:45:22.887747  106124 oom_linux.go:65] attempting to set "/proc/106124/oom_score_adj" to "-999"
I1009 09:45:22.887852  106124 kuberuntime_gc.go:343] "Removing pod logs" podUID="c7e58e54-59be-492a-8089-bf628cce8a30"
I1009 09:45:22.888104  106124 kubelet.go:1457] "Container garbage collection succeeded"
I1009 09:45:22.891941  106124 container_log_manager.go:238] "Starting container log rotation sequence"
I1009 09:45:22.892408  106124 container_log_manager.go:252] "Adding new entry to the queue for processing" id="08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5" name="regular-1" labels={"io.kubernetes.container.name":"regular-1","io.kubernetes.pod.name":"test-pod","io.kubernetes.pod.namespace":"prestop-hook-test-3521","io.kubernetes.pod.uid":"afd5e56f-a379-49e2-839a-186dcb64715c"}
I1009 09:45:22.897727  106124 kubelet.go:2898] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:; Handlers: , Features: nil"
I1009 09:45:22.926585  106124 eviction_manager.go:251] "Eviction manager: synchronize housekeeping"
I1009 09:45:22.926625  106124 eviction_manager.go:280] "FileSystem detection" DedicatedImageFs=false SplitImageFs=false
I1009 09:45:22.932327  106124 helpers.go:972] "Eviction manager:" log="observations" signal="memory.available" resourceName="memory" available="12062172Ki" capacity="16376164Ki" time="2024-10-09 09:45:22.927141335 +0000 UTC m=+60.132655822"
I1009 09:45:22.932365  106124 helpers.go:972] "Eviction manager:" log="observations" signal="imagefs.available" resourceName="ephemeral-storage" available="162422292Ki" capacity="202051056Ki" time="2024-10-09 09:45:22.098264024 +0000 UTC"
I1009 09:45:22.932373  106124 helpers.go:972] "Eviction manager:" log="observations" signal="containerfs.inodesFree" resourceName="inodes" available="24743230" capacity="26083328" time="2024-10-09 09:45:22.098264024 +0000 UTC"
I1009 09:45:22.932381  106124 helpers.go:972] "Eviction manager:" log="observations" signal="imagefs.inodesFree" resourceName="inodes" available="24743230" capacity="26083328" time="2024-10-09 09:45:22.098264024 +0000 UTC"
I1009 09:45:22.932387  106124 helpers.go:972] "Eviction manager:" log="observations" signal="containerfs.available" resourceName="ephemeral-storage" available="162422292Ki" capacity="202051056Ki" time="2024-10-09 09:45:22.098264024 +0000 UTC"
I1009 09:45:22.932393  106124 helpers.go:972] "Eviction manager:" log="observations" signal="pid.available" resourceName="pids" available="127324" capacity="127664" time="2024-10-09 09:45:22.931942937 +0000 UTC m=+60.137457433"
I1009 09:45:22.932400  106124 helpers.go:972] "Eviction manager:" log="observations" signal="allocatableMemory.available" resourceName="memory" available="16371212Ki" capacity="16376164Ki" time="2024-10-09 09:45:22.932223949 +0000 UTC m=+60.137738455"
I1009 09:45:22.932406  106124 helpers.go:972] "Eviction manager:" log="observations" signal="nodefs.available" resourceName="ephemeral-storage" available="162422292Ki" capacity="202051056Ki" time="2024-10-09 09:45:22.927141335 +0000 UTC m=+60.132655822"
I1009 09:45:22.932413  106124 helpers.go:972] "Eviction manager:" log="observations" signal="nodefs.inodesFree" resourceName="inodes" available="24743230" capacity="26083328" time="2024-10-09 09:45:22.927141335 +0000 UTC m=+60.132655822"
I1009 09:45:22.932433  106124 eviction_manager.go:359] "Eviction manager: no resources are starved"
I1009 09:45:23.014258  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:45:23.014296  106124 generic.go:187] "GenericPLEG" podUID="c7e58e54-59be-492a-8089-bf628cce8a30" containerID="a4fe23cc464877e9d3bc6c1826e24fa4b80f81e9eb51fd13324ddd4492e45e26" oldState="exited" newState="non-existent"
I1009 09:45:23.014307  106124 generic.go:187] "GenericPLEG" podUID="c7e58e54-59be-492a-8089-bf628cce8a30" containerID="d2140c7c68378b3ca1e26ec4ba9259a41b6f0b815b2c7dfef672e7467f4b897e" oldState="exited" newState="non-existent"
I1009 09:45:23.014316  106124 generic.go:440] "PLEG: Delete status for pod" podUID="c7e58e54-59be-492a-8089-bf628cce8a30"
I1009 09:45:23.248917  106124 handler.go:293] error while reading "/proc/106124/fd/23" link: readlink /proc/106124/fd/23: no such file or directory
I1009 09:45:23.941910  106124 interface.go:432] Looking for default routes with IPv4 addresses
I1009 09:45:23.941960  106124 interface.go:437] Default route transits interface "eth0"
I1009 09:45:23.942129  106124 interface.go:209] Interface eth0 is up
I1009 09:45:23.942191  106124 interface.go:257] Interface "eth0" has 3 addresses :[82.112.230.236/24 2a02:4780:12:eebf::1/48 fe80::be24:11ff:fe5a:b1d8/64].
I1009 09:45:23.942209  106124 interface.go:224] Checking addr  82.112.230.236/24.
I1009 09:45:23.942217  106124 interface.go:231] IP found 82.112.230.236
I1009 09:45:23.942224  106124 interface.go:263] Found valid IPv4 address 82.112.230.236 for interface "eth0".
I1009 09:45:23.942230  106124 interface.go:443] Found active IP 82.112.230.236 
I1009 09:45:24.016631  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:45:24.871957  106124 kubelet.go:2509] "SyncLoop (housekeeping)"
I1009 09:45:24.873325  106124 kubelet_pods.go:1151] "Clean up pod workers for terminated pods"
I1009 09:45:24.874489  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=false
I1009 09:45:24.874530  106124 kubelet_pods.go:1201] "Clean up probes for terminated pods"
I1009 09:45:24.874538  106124 kubelet_pods.go:1205] "Clean up orphaned pod statuses"
I1009 09:45:24.874547  106124 kubelet_pods.go:1209] "Clean up orphaned pod user namespace allocations"
I1009 09:45:24.874556  106124 kubelet_pods.go:1221] "Clean up orphaned pod directories"
I1009 09:45:24.874619  106124 kubelet_pods.go:1232] "Clean up orphaned mirror pods"
I1009 09:45:24.874661  106124 kubelet_pods.go:1374] "Clean up orphaned pod cgroups"
I1009 09:45:24.874673  106124 kubelet.go:2517] "SyncLoop (housekeeping) end" duration="3ms"
I1009 09:45:25.019157  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:45:26.021206  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:45:26.872588  106124 kubelet.go:2509] "SyncLoop (housekeeping)"
I1009 09:45:26.873906  106124 kubelet_pods.go:1151] "Clean up pod workers for terminated pods"
I1009 09:45:26.874838  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=false
I1009 09:45:26.874860  106124 kubelet_pods.go:1201] "Clean up probes for terminated pods"
I1009 09:45:26.874869  106124 kubelet_pods.go:1205] "Clean up orphaned pod statuses"
I1009 09:45:26.874878  106124 kubelet_pods.go:1209] "Clean up orphaned pod user namespace allocations"
I1009 09:45:26.874888  106124 kubelet_pods.go:1221] "Clean up orphaned pod directories"
I1009 09:45:26.874939  106124 kubelet_pods.go:1232] "Clean up orphaned mirror pods"
I1009 09:45:26.874974  106124 kubelet_pods.go:1374] "Clean up orphaned pod cgroups"
I1009 09:45:26.874986  106124 kubelet.go:2517] "SyncLoop (housekeeping) end" duration="2ms"
E1009 09:45:26.939219  106124 log.go:32] "StopContainer from runtime service failed" err=<
	rpc error: code = Unknown desc = failed to kill container "08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5": unknown error after kill: runc did not terminate successfully: exit status 1: unable to signal init: permission denied
	: unknown
 > containerID="08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5"
E1009 09:45:26.939279  106124 kuberuntime_container.go:813] "Container termination failed with gracePeriod" err=<
	rpc error: code = Unknown desc = failed to kill container "08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5": unknown error after kill: runc did not terminate successfully: exit status 1: unable to signal init: permission denied
	: unknown
 > pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c" containerName="regular-1" containerID="containerd://08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5" gracePeriod=29
E1009 09:45:26.939316  106124 kuberuntime_container.go:851] "Kill container failed" err=<
	rpc error: code = Unknown desc = failed to kill container "08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5": unknown error after kill: runc did not terminate successfully: exit status 1: unable to signal init: permission denied
	: unknown
 > pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c" containerName="regular-1" containerID={"Type":"containerd","ID":"08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5"}
E1009 09:45:26.948103  106124 log.go:32] "StopPodSandbox from runtime service failed" err=<
	rpc error: code = Unknown desc = failed to stop container "08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5": failed to kill container "08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5": unknown error after kill: runc did not terminate successfully: exit status 1: unable to signal init: permission denied
	: unknown
 > podSandboxID="87c8ae07b7f2916ceb558e07dbf26071bedda92948368099046f4f5430169077"
E1009 09:45:26.948160  106124 kuberuntime_manager.go:1479] "Failed to stop sandbox" podSandboxID={"Type":"containerd","ID":"87c8ae07b7f2916ceb558e07dbf26071bedda92948368099046f4f5430169077"}
E1009 09:45:26.948198  106124 kuberuntime_manager.go:1079] "killPodWithSyncResult failed" err="[failed to \"KillContainer\" for \"regular-1\" with KillContainerError: \"rpc error: code = Unknown desc = failed to kill container \\\"08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5\\\": unknown error after kill: runc did not terminate successfully: exit status 1: unable to signal init: permission denied\\n: unknown\", failed to \"KillPodSandbox\" for \"afd5e56f-a379-49e2-839a-186dcb64715c\" with KillPodSandboxError: \"rpc error: code = Unknown desc = failed to stop container \\\"08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5\\\": failed to kill container \\\"08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5\\\": unknown error after kill: runc did not terminate successfully: exit status 1: unable to signal init: permission denied\\n: unknown\"]"
I1009 09:45:26.948233  106124 kubelet.go:1767] "SyncPod exit" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c" isTerminal=false
E1009 09:45:26.948249  106124 pod_workers.go:1301] "Error syncing pod, skipping" err="[failed to \"KillContainer\" for \"regular-1\" with KillContainerError: \"rpc error: code = Unknown desc = failed to kill container \\\"08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5\\\": unknown error after kill: runc did not terminate successfully: exit status 1: unable to signal init: permission denied\\n: unknown\", failed to \"KillPodSandbox\" for \"afd5e56f-a379-49e2-839a-186dcb64715c\" with KillPodSandboxError: \"rpc error: code = Unknown desc = failed to stop container \\\"08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5\\\": failed to kill container \\\"08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5\\\": unknown error after kill: runc did not terminate successfully: exit status 1: unable to signal init: permission denied\\n: unknown\"]" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c"
I1009 09:45:26.948275  106124 pod_workers.go:1338] "Processing pod event done" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c" updateType="sync"
I1009 09:45:27.023719  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:45:27.899358  106124 kubelet.go:2898] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:; Handlers: , Features: nil"
I1009 09:45:28.025880  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:45:28.825856  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/kubelet.service"
I1009 09:45:28.825890  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/kubelet.service"
I1009 09:45:28.825896  106124 factory.go:272] Factory "raw" can handle container "/system.slice/kubelet.service", but ignoring.
I1009 09:45:28.825907  106124 manager.go:929] ignoring container "/system.slice/kubelet.service"
I1009 09:45:28.872557  106124 kubelet.go:2509] "SyncLoop (housekeeping)"
I1009 09:45:28.876785  106124 kubelet_pods.go:1151] "Clean up pod workers for terminated pods"
I1009 09:45:28.878144  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=false
I1009 09:45:28.878171  106124 kubelet_pods.go:1201] "Clean up probes for terminated pods"
I1009 09:45:28.878180  106124 kubelet_pods.go:1205] "Clean up orphaned pod statuses"
I1009 09:45:28.878188  106124 kubelet_pods.go:1209] "Clean up orphaned pod user namespace allocations"
I1009 09:45:28.878197  106124 kubelet_pods.go:1221] "Clean up orphaned pod directories"
I1009 09:45:28.878245  106124 kubelet_pods.go:1232] "Clean up orphaned mirror pods"
I1009 09:45:28.878275  106124 kubelet_pods.go:1374] "Clean up orphaned pod cgroups"
I1009 09:45:28.878287  106124 kubelet.go:2517] "SyncLoop (housekeeping) end" duration="6ms"
I1009 09:45:29.027884  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:45:30.029711  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:45:30.872586  106124 kubelet.go:2509] "SyncLoop (housekeeping)"
I1009 09:45:30.873960  106124 kubelet_pods.go:1151] "Clean up pod workers for terminated pods"
I1009 09:45:30.874946  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=false
I1009 09:45:30.874968  106124 kubelet_pods.go:1201] "Clean up probes for terminated pods"
I1009 09:45:30.874975  106124 kubelet_pods.go:1205] "Clean up orphaned pod statuses"
I1009 09:45:30.874983  106124 kubelet_pods.go:1209] "Clean up orphaned pod user namespace allocations"
I1009 09:45:30.874993  106124 kubelet_pods.go:1221] "Clean up orphaned pod directories"
I1009 09:45:30.875034  106124 kubelet_pods.go:1232] "Clean up orphaned mirror pods"
I1009 09:45:30.875065  106124 kubelet_pods.go:1374] "Clean up orphaned pod cgroups"
I1009 09:45:30.875076  106124 kubelet.go:2517] "SyncLoop (housekeeping) end" duration="3ms"
I1009 09:45:31.031314  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:45:32.033621  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:45:32.849846  106124 config.go:292] "Setting pods for source" source="file"
I1009 09:45:32.871546  106124 kubelet.go:2509] "SyncLoop (housekeeping)"
I1009 09:45:32.871552  106124 status_manager.go:230] "Syncing all statuses"
I1009 09:45:32.873060  106124 kubelet_pods.go:1151] "Clean up pod workers for terminated pods"
I1009 09:45:32.874050  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=false
I1009 09:45:32.874072  106124 kubelet_pods.go:1201] "Clean up probes for terminated pods"
I1009 09:45:32.874079  106124 kubelet_pods.go:1205] "Clean up orphaned pod statuses"
I1009 09:45:32.874088  106124 kubelet_pods.go:1209] "Clean up orphaned pod user namespace allocations"
I1009 09:45:32.874098  106124 kubelet_pods.go:1221] "Clean up orphaned pod directories"
I1009 09:45:32.874201  106124 kubelet_pods.go:1232] "Clean up orphaned mirror pods"
I1009 09:45:32.874236  106124 kubelet_pods.go:1374] "Clean up orphaned pod cgroups"
I1009 09:45:32.874247  106124 kubelet.go:2517] "SyncLoop (housekeeping) end" duration="3ms"
I1009 09:45:32.892918  106124 container_log_manager.go:238] "Starting container log rotation sequence"
I1009 09:45:32.893648  106124 container_log_manager.go:252] "Adding new entry to the queue for processing" id="08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5" name="regular-1" labels={"io.kubernetes.container.name":"regular-1","io.kubernetes.pod.name":"test-pod","io.kubernetes.pod.namespace":"prestop-hook-test-3521","io.kubernetes.pod.uid":"afd5e56f-a379-49e2-839a-186dcb64715c"}
I1009 09:45:32.901107  106124 kubelet.go:2898] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:; Handlers: , Features: nil"
I1009 09:45:32.932857  106124 eviction_manager.go:251] "Eviction manager: synchronize housekeeping"
I1009 09:45:32.932901  106124 eviction_manager.go:280] "FileSystem detection" DedicatedImageFs=false SplitImageFs=false
I1009 09:45:32.939577  106124 helpers.go:972] "Eviction manager:" log="observations" signal="allocatableMemory.available" resourceName="memory" available="16371232Ki" capacity="16376164Ki" time="2024-10-09 09:45:32.939476546 +0000 UTC m=+70.144991052"
I1009 09:45:32.939614  106124 helpers.go:972] "Eviction manager:" log="observations" signal="nodefs.inodesFree" resourceName="inodes" available="24743251" capacity="26083328" time="2024-10-09 09:45:32.933587967 +0000 UTC m=+70.139102492"
I1009 09:45:32.939622  106124 helpers.go:972] "Eviction manager:" log="observations" signal="imagefs.inodesFree" resourceName="inodes" available="24743251" capacity="26083328" time="2024-10-09 09:45:32.097864698 +0000 UTC"
I1009 09:45:32.939628  106124 helpers.go:972] "Eviction manager:" log="observations" signal="containerfs.inodesFree" resourceName="inodes" available="24743251" capacity="26083328" time="2024-10-09 09:45:32.097864698 +0000 UTC"
I1009 09:45:32.939633  106124 helpers.go:972] "Eviction manager:" log="observations" signal="pid.available" resourceName="pids" available="127324" capacity="127664" time="2024-10-09 09:45:32.939196424 +0000 UTC m=+70.144710910"
I1009 09:45:32.939640  106124 helpers.go:972] "Eviction manager:" log="observations" signal="memory.available" resourceName="memory" available="12062020Ki" capacity="16376164Ki" time="2024-10-09 09:45:32.933587967 +0000 UTC m=+70.139102492"
I1009 09:45:32.939645  106124 helpers.go:972] "Eviction manager:" log="observations" signal="imagefs.available" resourceName="ephemeral-storage" available="162422328Ki" capacity="202051056Ki" time="2024-10-09 09:45:32.097864698 +0000 UTC"
I1009 09:45:32.939650  106124 helpers.go:972] "Eviction manager:" log="observations" signal="containerfs.available" resourceName="ephemeral-storage" available="162422328Ki" capacity="202051056Ki" time="2024-10-09 09:45:32.097864698 +0000 UTC"
I1009 09:45:32.939654  106124 helpers.go:972] "Eviction manager:" log="observations" signal="nodefs.available" resourceName="ephemeral-storage" available="162422328Ki" capacity="202051056Ki" time="2024-10-09 09:45:32.933587967 +0000 UTC m=+70.139102492"
I1009 09:45:32.939671  106124 eviction_manager.go:359] "Eviction manager: no resources are starved"
I1009 09:45:33.034921  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:45:33.959725  106124 interface.go:432] Looking for default routes with IPv4 addresses
I1009 09:45:33.959759  106124 interface.go:437] Default route transits interface "eth0"
I1009 09:45:33.959897  106124 interface.go:209] Interface eth0 is up
I1009 09:45:33.959956  106124 interface.go:257] Interface "eth0" has 3 addresses :[82.112.230.236/24 2a02:4780:12:eebf::1/48 fe80::be24:11ff:fe5a:b1d8/64].
I1009 09:45:33.959970  106124 interface.go:224] Checking addr  82.112.230.236/24.
I1009 09:45:33.959976  106124 interface.go:231] IP found 82.112.230.236
I1009 09:45:33.959980  106124 interface.go:263] Found valid IPv4 address 82.112.230.236 for interface "eth0".
I1009 09:45:33.959986  106124 interface.go:443] Found active IP 82.112.230.236 
I1009 09:45:34.036974  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:45:34.872449  106124 kubelet.go:2509] "SyncLoop (housekeeping)"
I1009 09:45:34.873783  106124 kubelet_pods.go:1151] "Clean up pod workers for terminated pods"
I1009 09:45:34.875146  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=false
I1009 09:45:34.875190  106124 kubelet_pods.go:1201] "Clean up probes for terminated pods"
I1009 09:45:34.875198  106124 kubelet_pods.go:1205] "Clean up orphaned pod statuses"
I1009 09:45:34.875206  106124 kubelet_pods.go:1209] "Clean up orphaned pod user namespace allocations"
I1009 09:45:34.875216  106124 kubelet_pods.go:1221] "Clean up orphaned pod directories"
I1009 09:45:34.875277  106124 kubelet_pods.go:1232] "Clean up orphaned mirror pods"
I1009 09:45:34.875313  106124 kubelet_pods.go:1374] "Clean up orphaned pod cgroups"
I1009 09:45:34.875327  106124 kubelet.go:2517] "SyncLoop (housekeeping) end" duration="3ms"
I1009 09:45:35.038627  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:45:36.040822  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:45:36.872367  106124 kubelet.go:2509] "SyncLoop (housekeeping)"
I1009 09:45:36.873589  106124 kubelet_pods.go:1151] "Clean up pod workers for terminated pods"
I1009 09:45:36.874814  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=false
I1009 09:45:36.874829  106124 kubelet_pods.go:1201] "Clean up probes for terminated pods"
I1009 09:45:36.874834  106124 kubelet_pods.go:1205] "Clean up orphaned pod statuses"
I1009 09:45:36.874841  106124 kubelet_pods.go:1209] "Clean up orphaned pod user namespace allocations"
I1009 09:45:36.874849  106124 kubelet_pods.go:1221] "Clean up orphaned pod directories"
I1009 09:45:36.874883  106124 kubelet_pods.go:1232] "Clean up orphaned mirror pods"
I1009 09:45:36.874907  106124 kubelet_pods.go:1374] "Clean up orphaned pod cgroups"
I1009 09:45:36.874916  106124 kubelet.go:2517] "SyncLoop (housekeeping) end" duration="3ms"
I1009 09:45:37.042733  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:45:37.872358  106124 kubelet.go:2461] "SyncLoop (SYNC) pods" total=1 pods=["prestop-hook-test-3521/test-pod"]
I1009 09:45:37.872426  106124 pod_workers.go:963] "Notifying pod of pending update" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c" workType="sync"
I1009 09:45:37.872511  106124 pod_workers.go:1233] "Processing pod event" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c" updateType="sync"
I1009 09:45:37.872540  106124 kubelet.go:1761] "SyncPod enter" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c"
I1009 09:45:37.872549  106124 kubelet_pods.go:1774] "Generating pod status" podIsTerminal=false pod="prestop-hook-test-3521/test-pod"
I1009 09:45:37.872598  106124 kubelet_pods.go:1787] "Got phase for pod" pod="prestop-hook-test-3521/test-pod" oldPhase="Running" phase="Running"
I1009 09:45:37.872694  106124 status_manager.go:691] "Ignoring same status for pod" pod="prestop-hook-test-3521/test-pod" status={"phase":"Running","conditions":[{"type":"PodReadyToStartContainers","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-10-09T09:44:24Z"},{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-10-09T09:44:23Z"},{"type":"Ready","status":"False","lastProbeTime":null,"lastTransitionTime":"2024-10-09T09:44:23Z","reason":"ContainersNotReady","message":"containers with unready status: [regular-1]"},{"type":"ContainersReady","status":"False","lastProbeTime":null,"lastTransitionTime":"2024-10-09T09:44:23Z","reason":"ContainersNotReady","message":"containers with unready status: [regular-1]"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-10-09T09:44:23Z"}],"hostIP":"82.112.230.236","hostIPs":[{"ip":"82.112.230.236"}],"podIP":"10.10.0.97","podIPs":[{"ip":"10.10.0.97"}],"startTime":"2024-10-09T09:44:23Z","containerStatuses":[{"name":"regular-1","state":{"running":{"startedAt":"2024-10-09T09:44:24Z"}},"lastState":{},"ready":false,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/busybox:1.36.1-1","imageID":"registry.k8s.io/e2e-test-images/busybox@sha256:a9155b13325b2abef48e71de77bb8ac015412a566829f621d06bfae5c699b1b9","containerID":"containerd://08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5","started":false,"volumeMounts":[{"name":"persistent","mountPath":"/persistent"}]}],"qosClass":"Burstable"}
I1009 09:45:37.872872  106124 volume_manager.go:404] "Waiting for volumes to attach and mount for pod" pod="prestop-hook-test-3521/test-pod"
I1009 09:45:37.872896  106124 volume_manager.go:440] "All volumes are attached and mounted for pod" pod="prestop-hook-test-3521/test-pod"
I1009 09:45:37.872929  106124 kuberuntime_manager.go:1027] "Message for Container of pod" containerName="regular-1" containerStatusID={"Type":"containerd","ID":"08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5"} pod="prestop-hook-test-3521/test-pod" containerMessage="Container regular-1 failed startup probe"
I1009 09:45:37.872956  106124 kuberuntime_manager.go:1055] "computePodActions got for pod" podActions="KillPod: true, CreateSandbox: false, UpdatePodResources: false, Attempt: 0, InitContainersToStart: [], ContainersToStart: [], EphemeralContainersToStart: [],ContainersToUpdate: map[], ContainersToKill: map[{containerd 08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5}:{0xc0012dde00 regular-1 Container regular-1 failed startup probe StartupProbe}]" pod="prestop-hook-test-3521/test-pod"
I1009 09:45:37.872982  106124 kuberuntime_manager.go:1073] "Stopping PodSandbox for pod, because all other containers are dead" pod="prestop-hook-test-3521/test-pod"
I1009 09:45:37.873016  106124 kuberuntime_container.go:683] "Running preStop hook" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c" containerName="regular-1" containerID="containerd://08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5"
I1009 09:45:37.873121  106124 event.go:389] "Event occurred" object="prestop-hook-test-3521/test-pod" fieldPath="spec.containers{regular-1}" kind="Pod" apiVersion="v1" type="Normal" reason="Killing" message="Stopping container regular-1"
I1009 09:45:37.901853  106124 kubelet.go:2898] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:; Handlers: , Features: nil"
I1009 09:45:37.911632  106124 desired_state_of_world.go:308] "expected volume SELinux label context" volume="persistent" label=""
I1009 09:45:37.911664  106124 desired_state_of_world_populator.go:329] "Added volume to desired state" pod="prestop-hook-test-3521/test-pod" volumeName="persistent" volumeSpecName="persistent"
I1009 09:45:38.044803  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:45:38.872573  106124 kubelet.go:2509] "SyncLoop (housekeeping)"
I1009 09:45:38.873856  106124 kubelet_pods.go:1151] "Clean up pod workers for terminated pods"
I1009 09:45:38.875074  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=false
I1009 09:45:38.875091  106124 kubelet_pods.go:1201] "Clean up probes for terminated pods"
I1009 09:45:38.875096  106124 kubelet_pods.go:1205] "Clean up orphaned pod statuses"
I1009 09:45:38.875102  106124 kubelet_pods.go:1209] "Clean up orphaned pod user namespace allocations"
I1009 09:45:38.875109  106124 kubelet_pods.go:1221] "Clean up orphaned pod directories"
I1009 09:45:38.875149  106124 kubelet_pods.go:1232] "Clean up orphaned mirror pods"
I1009 09:45:38.875174  106124 kubelet_pods.go:1374] "Clean up orphaned pod cgroups"
I1009 09:45:38.875182  106124 kubelet.go:2517] "SyncLoop (housekeeping) end" duration="3ms"
I1009 09:45:38.926779  106124 kuberuntime_container.go:703] "PreStop hook completed" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c" containerName="regular-1" containerID="containerd://08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5"
I1009 09:45:38.926820  106124 kuberuntime_container.go:808] "Killing container with a grace period" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c" containerName="regular-1" containerID="containerd://08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5" gracePeriod=29
I1009 09:45:39.046672  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:45:39.075089  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/kubelet.service"
I1009 09:45:39.075128  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/kubelet.service"
I1009 09:45:39.075139  106124 factory.go:272] Factory "raw" can handle container "/system.slice/kubelet.service", but ignoring.
I1009 09:45:39.075149  106124 manager.go:929] ignoring container "/system.slice/kubelet.service"
I1009 09:45:40.048819  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:45:40.872092  106124 kubelet.go:2509] "SyncLoop (housekeeping)"
I1009 09:45:40.873257  106124 kubelet_pods.go:1151] "Clean up pod workers for terminated pods"
I1009 09:45:40.874400  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=false
I1009 09:45:40.874443  106124 kubelet_pods.go:1201] "Clean up probes for terminated pods"
I1009 09:45:40.874450  106124 kubelet_pods.go:1205] "Clean up orphaned pod statuses"
I1009 09:45:40.874475  106124 kubelet_pods.go:1209] "Clean up orphaned pod user namespace allocations"
I1009 09:45:40.874482  106124 kubelet_pods.go:1221] "Clean up orphaned pod directories"
I1009 09:45:40.874542  106124 kubelet_pods.go:1232] "Clean up orphaned mirror pods"
I1009 09:45:40.874575  106124 kubelet_pods.go:1374] "Clean up orphaned pod cgroups"
I1009 09:45:40.874589  106124 kubelet.go:2517] "SyncLoop (housekeeping) end" duration="3ms"
I1009 09:45:41.051343  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:45:42.052954  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:45:42.146370  106124 handler.go:293] error while reading "/proc/106124/fd/23" link: readlink /proc/106124/fd/23: no such file or directory
I1009 09:45:42.849527  106124 config.go:292] "Setting pods for source" source="file"
I1009 09:45:42.872032  106124 status_manager.go:230] "Syncing all statuses"
I1009 09:45:42.872092  106124 kubelet.go:2509] "SyncLoop (housekeeping)"
I1009 09:45:42.873594  106124 kubelet_pods.go:1151] "Clean up pod workers for terminated pods"
I1009 09:45:42.874743  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=false
I1009 09:45:42.874764  106124 kubelet_pods.go:1201] "Clean up probes for terminated pods"
I1009 09:45:42.874772  106124 kubelet_pods.go:1205] "Clean up orphaned pod statuses"
I1009 09:45:42.874779  106124 kubelet_pods.go:1209] "Clean up orphaned pod user namespace allocations"
I1009 09:45:42.874786  106124 kubelet_pods.go:1221] "Clean up orphaned pod directories"
I1009 09:45:42.874832  106124 kubelet_pods.go:1232] "Clean up orphaned mirror pods"
I1009 09:45:42.874866  106124 kubelet_pods.go:1374] "Clean up orphaned pod cgroups"
I1009 09:45:42.874881  106124 kubelet.go:2517] "SyncLoop (housekeeping) end" duration="3ms"
I1009 09:45:42.894018  106124 container_log_manager.go:238] "Starting container log rotation sequence"
I1009 09:45:42.894707  106124 container_log_manager.go:252] "Adding new entry to the queue for processing" id="08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5" name="regular-1" labels={"io.kubernetes.container.name":"regular-1","io.kubernetes.pod.name":"test-pod","io.kubernetes.pod.namespace":"prestop-hook-test-3521","io.kubernetes.pod.uid":"afd5e56f-a379-49e2-839a-186dcb64715c"}
I1009 09:45:42.903225  106124 kubelet.go:2898] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:; Handlers: , Features: nil"
I1009 09:45:42.940170  106124 eviction_manager.go:251] "Eviction manager: synchronize housekeeping"
I1009 09:45:42.940209  106124 eviction_manager.go:280] "FileSystem detection" DedicatedImageFs=false SplitImageFs=false
I1009 09:45:42.947080  106124 helpers.go:972] "Eviction manager:" log="observations" signal="nodefs.inodesFree" resourceName="inodes" available="24743251" capacity="26083328" time="2024-10-09 09:45:42.940726108 +0000 UTC m=+80.146240604"
I1009 09:45:42.947120  106124 helpers.go:972] "Eviction manager:" log="observations" signal="containerfs.inodesFree" resourceName="inodes" available="24743251" capacity="26083328" time="2024-10-09 09:45:42.097934451 +0000 UTC"
I1009 09:45:42.947128  106124 helpers.go:972] "Eviction manager:" log="observations" signal="pid.available" resourceName="pids" available="127324" capacity="127664" time="2024-10-09 09:45:42.946731989 +0000 UTC m=+80.152246474"
I1009 09:45:42.947135  106124 helpers.go:972] "Eviction manager:" log="observations" signal="imagefs.inodesFree" resourceName="inodes" available="24743251" capacity="26083328" time="2024-10-09 09:45:42.097934451 +0000 UTC"
I1009 09:45:42.947155  106124 helpers.go:972] "Eviction manager:" log="observations" signal="containerfs.available" resourceName="ephemeral-storage" available="162422312Ki" capacity="202051056Ki" time="2024-10-09 09:45:42.097934451 +0000 UTC"
I1009 09:45:42.947163  106124 helpers.go:972] "Eviction manager:" log="observations" signal="memory.available" resourceName="memory" available="12061148Ki" capacity="16376164Ki" time="2024-10-09 09:45:42.940726108 +0000 UTC m=+80.146240604"
I1009 09:45:42.947170  106124 helpers.go:972] "Eviction manager:" log="observations" signal="allocatableMemory.available" resourceName="memory" available="16371232Ki" capacity="16376164Ki" time="2024-10-09 09:45:42.94699089 +0000 UTC m=+80.152505386"
I1009 09:45:42.947176  106124 helpers.go:972] "Eviction manager:" log="observations" signal="nodefs.available" resourceName="ephemeral-storage" available="162422312Ki" capacity="202051056Ki" time="2024-10-09 09:45:42.940726108 +0000 UTC m=+80.146240604"
I1009 09:45:42.947183  106124 helpers.go:972] "Eviction manager:" log="observations" signal="imagefs.available" resourceName="ephemeral-storage" available="162422312Ki" capacity="202051056Ki" time="2024-10-09 09:45:42.097934451 +0000 UTC"
I1009 09:45:42.947204  106124 eviction_manager.go:359] "Eviction manager: no resources are starved"
I1009 09:45:43.054768  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:45:44.056995  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:45:44.185876  106124 interface.go:432] Looking for default routes with IPv4 addresses
I1009 09:45:44.185905  106124 interface.go:437] Default route transits interface "eth0"
I1009 09:45:44.186039  106124 interface.go:209] Interface eth0 is up
I1009 09:45:44.186082  106124 interface.go:257] Interface "eth0" has 3 addresses :[82.112.230.236/24 2a02:4780:12:eebf::1/48 fe80::be24:11ff:fe5a:b1d8/64].
I1009 09:45:44.186095  106124 interface.go:224] Checking addr  82.112.230.236/24.
I1009 09:45:44.186100  106124 interface.go:231] IP found 82.112.230.236
I1009 09:45:44.186105  106124 interface.go:263] Found valid IPv4 address 82.112.230.236 for interface "eth0".
I1009 09:45:44.186114  106124 interface.go:443] Found active IP 82.112.230.236 
I1009 09:45:44.871888  106124 kubelet.go:2509] "SyncLoop (housekeeping)"
I1009 09:45:44.873472  106124 kubelet_pods.go:1151] "Clean up pod workers for terminated pods"
I1009 09:45:44.874617  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=false
I1009 09:45:44.874654  106124 kubelet_pods.go:1201] "Clean up probes for terminated pods"
I1009 09:45:44.874659  106124 kubelet_pods.go:1205] "Clean up orphaned pod statuses"
I1009 09:45:44.874665  106124 kubelet_pods.go:1209] "Clean up orphaned pod user namespace allocations"
I1009 09:45:44.874673  106124 kubelet_pods.go:1221] "Clean up orphaned pod directories"
I1009 09:45:44.874725  106124 kubelet_pods.go:1232] "Clean up orphaned mirror pods"
I1009 09:45:44.874762  106124 kubelet_pods.go:1374] "Clean up orphaned pod cgroups"
I1009 09:45:44.874779  106124 kubelet.go:2517] "SyncLoop (housekeeping) end" duration="3ms"
I1009 09:45:45.058070  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:45:46.060229  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:45:46.872201  106124 kubelet.go:2509] "SyncLoop (housekeeping)"
I1009 09:45:46.873412  106124 kubelet_pods.go:1151] "Clean up pod workers for terminated pods"
I1009 09:45:46.874597  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=false
I1009 09:45:46.874615  106124 kubelet_pods.go:1201] "Clean up probes for terminated pods"
I1009 09:45:46.874621  106124 kubelet_pods.go:1205] "Clean up orphaned pod statuses"
I1009 09:45:46.874627  106124 kubelet_pods.go:1209] "Clean up orphaned pod user namespace allocations"
I1009 09:45:46.874634  106124 kubelet_pods.go:1221] "Clean up orphaned pod directories"
I1009 09:45:46.874695  106124 kubelet_pods.go:1232] "Clean up orphaned mirror pods"
I1009 09:45:46.874721  106124 kubelet_pods.go:1374] "Clean up orphaned pod cgroups"
I1009 09:45:46.874729  106124 kubelet.go:2517] "SyncLoop (housekeeping) end" duration="3ms"
I1009 09:45:47.061762  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:45:47.904331  106124 kubelet.go:2898] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:; Handlers: , Features: nil"
I1009 09:45:48.063523  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:45:48.872371  106124 kubelet.go:2509] "SyncLoop (housekeeping)"
I1009 09:45:48.873765  106124 kubelet_pods.go:1151] "Clean up pod workers for terminated pods"
I1009 09:45:48.874751  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=false
I1009 09:45:48.874777  106124 kubelet_pods.go:1201] "Clean up probes for terminated pods"
I1009 09:45:48.874785  106124 kubelet_pods.go:1205] "Clean up orphaned pod statuses"
I1009 09:45:48.874792  106124 kubelet_pods.go:1209] "Clean up orphaned pod user namespace allocations"
I1009 09:45:48.874799  106124 kubelet_pods.go:1221] "Clean up orphaned pod directories"
I1009 09:45:48.874838  106124 kubelet_pods.go:1232] "Clean up orphaned mirror pods"
I1009 09:45:48.874866  106124 kubelet_pods.go:1374] "Clean up orphaned pod cgroups"
I1009 09:45:48.874875  106124 kubelet.go:2517] "SyncLoop (housekeeping) end" duration="3ms"
I1009 09:45:49.065676  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:45:49.325397  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/kubelet.service"
I1009 09:45:49.325428  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/kubelet.service"
I1009 09:45:49.325436  106124 factory.go:272] Factory "raw" can handle container "/system.slice/kubelet.service", but ignoring.
I1009 09:45:49.325445  106124 manager.go:929] ignoring container "/system.slice/kubelet.service"
I1009 09:45:50.067232  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:45:50.872541  106124 kubelet.go:2509] "SyncLoop (housekeeping)"
I1009 09:45:50.873839  106124 kubelet_pods.go:1151] "Clean up pod workers for terminated pods"
I1009 09:45:50.875031  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=false
I1009 09:45:50.875100  106124 kubelet_pods.go:1201] "Clean up probes for terminated pods"
I1009 09:45:50.875108  106124 kubelet_pods.go:1205] "Clean up orphaned pod statuses"
I1009 09:45:50.875116  106124 kubelet_pods.go:1209] "Clean up orphaned pod user namespace allocations"
I1009 09:45:50.875125  106124 kubelet_pods.go:1221] "Clean up orphaned pod directories"
I1009 09:45:50.875171  106124 kubelet_pods.go:1232] "Clean up orphaned mirror pods"
I1009 09:45:50.875202  106124 kubelet_pods.go:1374] "Clean up orphaned pod cgroups"
I1009 09:45:50.875214  106124 kubelet.go:2517] "SyncLoop (housekeeping) end" duration="3ms"
I1009 09:45:51.069472  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:45:52.072269  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:45:52.849796  106124 config.go:292] "Setting pods for source" source="file"
I1009 09:45:52.871556  106124 status_manager.go:230] "Syncing all statuses"
I1009 09:45:52.871670  106124 kubelet.go:2509] "SyncLoop (housekeeping)"
I1009 09:45:52.873239  106124 kubelet_pods.go:1151] "Clean up pod workers for terminated pods"
I1009 09:45:52.874576  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=false
I1009 09:45:52.874616  106124 kubelet_pods.go:1201] "Clean up probes for terminated pods"
I1009 09:45:52.874625  106124 kubelet_pods.go:1205] "Clean up orphaned pod statuses"
I1009 09:45:52.874632  106124 kubelet_pods.go:1209] "Clean up orphaned pod user namespace allocations"
I1009 09:45:52.874639  106124 kubelet_pods.go:1221] "Clean up orphaned pod directories"
I1009 09:45:52.874720  106124 kubelet_pods.go:1232] "Clean up orphaned mirror pods"
I1009 09:45:52.874759  106124 kubelet_pods.go:1374] "Clean up orphaned pod cgroups"
I1009 09:45:52.874774  106124 kubelet.go:2517] "SyncLoop (housekeeping) end" duration="3ms"
I1009 09:45:52.895878  106124 container_log_manager.go:238] "Starting container log rotation sequence"
I1009 09:45:52.896716  106124 container_log_manager.go:252] "Adding new entry to the queue for processing" id="08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5" name="regular-1" labels={"io.kubernetes.container.name":"regular-1","io.kubernetes.pod.name":"test-pod","io.kubernetes.pod.namespace":"prestop-hook-test-3521","io.kubernetes.pod.uid":"afd5e56f-a379-49e2-839a-186dcb64715c"}
I1009 09:45:52.905406  106124 kubelet.go:2898] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:; Handlers: , Features: nil"
I1009 09:45:52.947951  106124 eviction_manager.go:251] "Eviction manager: synchronize housekeeping"
I1009 09:45:52.948001  106124 eviction_manager.go:280] "FileSystem detection" DedicatedImageFs=false SplitImageFs=false
I1009 09:45:52.955011  106124 helpers.go:972] "Eviction manager:" log="observations" signal="imagefs.available" resourceName="ephemeral-storage" available="162422288Ki" capacity="202051056Ki" time="2024-10-09 09:45:52.097870566 +0000 UTC"
I1009 09:45:52.955059  106124 helpers.go:972] "Eviction manager:" log="observations" signal="containerfs.inodesFree" resourceName="inodes" available="24743251" capacity="26083328" time="2024-10-09 09:45:52.097870566 +0000 UTC"
I1009 09:45:52.955068  106124 helpers.go:972] "Eviction manager:" log="observations" signal="pid.available" resourceName="pids" available="127324" capacity="127664" time="2024-10-09 09:45:52.954585827 +0000 UTC m=+90.160100322"
I1009 09:45:52.955075  106124 helpers.go:972] "Eviction manager:" log="observations" signal="nodefs.inodesFree" resourceName="inodes" available="24743251" capacity="26083328" time="2024-10-09 09:45:52.948672937 +0000 UTC m=+90.154187443"
I1009 09:45:52.955081  106124 helpers.go:972] "Eviction manager:" log="observations" signal="allocatableMemory.available" resourceName="memory" available="16371232Ki" capacity="16376164Ki" time="2024-10-09 09:45:52.954901409 +0000 UTC m=+90.160415925"
I1009 09:45:52.955088  106124 helpers.go:972] "Eviction manager:" log="observations" signal="nodefs.available" resourceName="ephemeral-storage" available="162422288Ki" capacity="202051056Ki" time="2024-10-09 09:45:52.948672937 +0000 UTC m=+90.154187443"
I1009 09:45:52.955094  106124 helpers.go:972] "Eviction manager:" log="observations" signal="imagefs.inodesFree" resourceName="inodes" available="24743251" capacity="26083328" time="2024-10-09 09:45:52.097870566 +0000 UTC"
I1009 09:45:52.955100  106124 helpers.go:972] "Eviction manager:" log="observations" signal="containerfs.available" resourceName="ephemeral-storage" available="162422288Ki" capacity="202051056Ki" time="2024-10-09 09:45:52.097870566 +0000 UTC"
I1009 09:45:52.955106  106124 helpers.go:972] "Eviction manager:" log="observations" signal="memory.available" resourceName="memory" available="12059172Ki" capacity="16376164Ki" time="2024-10-09 09:45:52.948672937 +0000 UTC m=+90.154187443"
I1009 09:45:52.955127  106124 eviction_manager.go:359] "Eviction manager: no resources are starved"
I1009 09:45:53.074569  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:45:53.913371  106124 handler.go:293] error while reading "/proc/106124/fd/21" link: readlink /proc/106124/fd/21: no such file or directory
I1009 09:45:54.076591  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:45:54.375935  106124 interface.go:432] Looking for default routes with IPv4 addresses
I1009 09:45:54.375965  106124 interface.go:437] Default route transits interface "eth0"
I1009 09:45:54.376100  106124 interface.go:209] Interface eth0 is up
I1009 09:45:54.376149  106124 interface.go:257] Interface "eth0" has 3 addresses :[82.112.230.236/24 2a02:4780:12:eebf::1/48 fe80::be24:11ff:fe5a:b1d8/64].
I1009 09:45:54.376176  106124 interface.go:224] Checking addr  82.112.230.236/24.
I1009 09:45:54.376182  106124 interface.go:231] IP found 82.112.230.236
I1009 09:45:54.376186  106124 interface.go:263] Found valid IPv4 address 82.112.230.236 for interface "eth0".
I1009 09:45:54.376191  106124 interface.go:443] Found active IP 82.112.230.236 
I1009 09:45:54.872402  106124 kubelet.go:2509] "SyncLoop (housekeeping)"
I1009 09:45:54.873678  106124 kubelet_pods.go:1151] "Clean up pod workers for terminated pods"
I1009 09:45:54.874613  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=false
I1009 09:45:54.874665  106124 kubelet_pods.go:1201] "Clean up probes for terminated pods"
I1009 09:45:54.874670  106124 kubelet_pods.go:1205] "Clean up orphaned pod statuses"
I1009 09:45:54.874678  106124 kubelet_pods.go:1209] "Clean up orphaned pod user namespace allocations"
I1009 09:45:54.874685  106124 kubelet_pods.go:1221] "Clean up orphaned pod directories"
I1009 09:45:54.874727  106124 kubelet_pods.go:1232] "Clean up orphaned mirror pods"
I1009 09:45:54.874758  106124 kubelet_pods.go:1374] "Clean up orphaned pod cgroups"
I1009 09:45:54.874770  106124 kubelet.go:2517] "SyncLoop (housekeeping) end" duration="2ms"
I1009 09:45:55.078796  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:45:56.080274  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:45:56.871692  106124 kubelet.go:2509] "SyncLoop (housekeeping)"
I1009 09:45:56.872894  106124 kubelet_pods.go:1151] "Clean up pod workers for terminated pods"
I1009 09:45:56.874184  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=false
I1009 09:45:56.874209  106124 kubelet_pods.go:1201] "Clean up probes for terminated pods"
I1009 09:45:56.874218  106124 kubelet_pods.go:1205] "Clean up orphaned pod statuses"
I1009 09:45:56.874227  106124 kubelet_pods.go:1209] "Clean up orphaned pod user namespace allocations"
I1009 09:45:56.874239  106124 kubelet_pods.go:1221] "Clean up orphaned pod directories"
I1009 09:45:56.874288  106124 kubelet_pods.go:1232] "Clean up orphaned mirror pods"
I1009 09:45:56.874322  106124 kubelet_pods.go:1374] "Clean up orphaned pod cgroups"
I1009 09:45:56.874335  106124 kubelet.go:2517] "SyncLoop (housekeeping) end" duration="3ms"
I1009 09:45:57.082249  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:45:57.907224  106124 kubelet.go:2898] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:; Handlers: , Features: nil"
I1009 09:45:58.084640  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:45:58.872304  106124 kubelet.go:2509] "SyncLoop (housekeeping)"
I1009 09:45:58.873985  106124 kubelet_pods.go:1151] "Clean up pod workers for terminated pods"
I1009 09:45:58.875012  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=false
I1009 09:45:58.875032  106124 kubelet_pods.go:1201] "Clean up probes for terminated pods"
I1009 09:45:58.875039  106124 kubelet_pods.go:1205] "Clean up orphaned pod statuses"
I1009 09:45:58.875046  106124 kubelet_pods.go:1209] "Clean up orphaned pod user namespace allocations"
I1009 09:45:58.875055  106124 kubelet_pods.go:1221] "Clean up orphaned pod directories"
I1009 09:45:58.875092  106124 kubelet_pods.go:1232] "Clean up orphaned mirror pods"
I1009 09:45:58.875120  106124 kubelet_pods.go:1374] "Clean up orphaned pod cgroups"
I1009 09:45:58.875130  106124 kubelet.go:2517] "SyncLoop (housekeeping) end" duration="3ms"
I1009 09:45:59.086701  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:45:59.575203  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/kubelet.service"
I1009 09:45:59.575238  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/kubelet.service"
I1009 09:45:59.575246  106124 factory.go:272] Factory "raw" can handle container "/system.slice/kubelet.service", but ignoring.
I1009 09:45:59.575267  106124 manager.go:929] ignoring container "/system.slice/kubelet.service"
I1009 09:46:00.088900  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:46:00.872301  106124 kubelet.go:2509] "SyncLoop (housekeeping)"
I1009 09:46:00.873848  106124 kubelet_pods.go:1151] "Clean up pod workers for terminated pods"
I1009 09:46:00.875063  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=false
I1009 09:46:00.875084  106124 kubelet_pods.go:1201] "Clean up probes for terminated pods"
I1009 09:46:00.875093  106124 kubelet_pods.go:1205] "Clean up orphaned pod statuses"
I1009 09:46:00.875104  106124 kubelet_pods.go:1209] "Clean up orphaned pod user namespace allocations"
I1009 09:46:00.875113  106124 kubelet_pods.go:1221] "Clean up orphaned pod directories"
I1009 09:46:00.875157  106124 kubelet_pods.go:1232] "Clean up orphaned mirror pods"
I1009 09:46:00.875182  106124 kubelet_pods.go:1374] "Clean up orphaned pod cgroups"
I1009 09:46:00.875191  106124 kubelet.go:2517] "SyncLoop (housekeeping) end" duration="3ms"
I1009 09:46:01.090286  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:46:01.326296  106124 factory.go:279] Factory "systemd" was unable to handle container "/system.slice/monarx-agent.service"
I1009 09:46:01.326333  106124 factory.go:279] Factory "containerd" was unable to handle container "/system.slice/monarx-agent.service"
I1009 09:46:01.326342  106124 factory.go:272] Factory "raw" can handle container "/system.slice/monarx-agent.service", but ignoring.
I1009 09:46:01.326352  106124 manager.go:929] ignoring container "/system.slice/monarx-agent.service"
I1009 09:46:02.093288  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:46:02.849999  106124 config.go:292] "Setting pods for source" source="file"
I1009 09:46:02.871803  106124 kubelet.go:2509] "SyncLoop (housekeeping)"
I1009 09:46:02.871830  106124 status_manager.go:230] "Syncing all statuses"
I1009 09:46:02.874444  106124 kubelet_pods.go:1151] "Clean up pod workers for terminated pods"
I1009 09:46:02.876899  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=false
I1009 09:46:02.876943  106124 kubelet_pods.go:1201] "Clean up probes for terminated pods"
I1009 09:46:02.876951  106124 kubelet_pods.go:1205] "Clean up orphaned pod statuses"
I1009 09:46:02.876960  106124 kubelet_pods.go:1209] "Clean up orphaned pod user namespace allocations"
I1009 09:46:02.876969  106124 kubelet_pods.go:1221] "Clean up orphaned pod directories"
I1009 09:46:02.877035  106124 kubelet_pods.go:1232] "Clean up orphaned mirror pods"
I1009 09:46:02.877077  106124 kubelet_pods.go:1374] "Clean up orphaned pod cgroups"
I1009 09:46:02.877090  106124 kubelet.go:2517] "SyncLoop (housekeeping) end" duration="5ms"
I1009 09:46:02.897285  106124 container_log_manager.go:238] "Starting container log rotation sequence"
I1009 09:46:02.898251  106124 container_log_manager.go:252] "Adding new entry to the queue for processing" id="08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5" name="regular-1" labels={"io.kubernetes.container.name":"regular-1","io.kubernetes.pod.name":"test-pod","io.kubernetes.pod.namespace":"prestop-hook-test-3521","io.kubernetes.pod.uid":"afd5e56f-a379-49e2-839a-186dcb64715c"}
I1009 09:46:02.909026  106124 kubelet.go:2898] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:; Handlers: , Features: nil"
I1009 09:46:02.956266  106124 eviction_manager.go:251] "Eviction manager: synchronize housekeeping"
I1009 09:46:02.956318  106124 eviction_manager.go:280] "FileSystem detection" DedicatedImageFs=false SplitImageFs=false
I1009 09:46:02.963933  106124 helpers.go:972] "Eviction manager:" log="observations" signal="allocatableMemory.available" resourceName="memory" available="16371232Ki" capacity="16376164Ki" time="2024-10-09 09:46:02.963797868 +0000 UTC m=+100.169312364"
I1009 09:46:02.964001  106124 helpers.go:972] "Eviction manager:" log="observations" signal="nodefs.inodesFree" resourceName="inodes" available="24743251" capacity="26083328" time="2024-10-09 09:46:02.956944611 +0000 UTC m=+100.162459107"
I1009 09:46:02.964012  106124 helpers.go:972] "Eviction manager:" log="observations" signal="containerfs.available" resourceName="ephemeral-storage" available="162422272Ki" capacity="202051056Ki" time="2024-10-09 09:46:02.097828984 +0000 UTC"
I1009 09:46:02.964018  106124 helpers.go:972] "Eviction manager:" log="observations" signal="pid.available" resourceName="pids" available="127324" capacity="127664" time="2024-10-09 09:46:02.963448155 +0000 UTC m=+100.168962641"
I1009 09:46:02.964024  106124 helpers.go:972] "Eviction manager:" log="observations" signal="memory.available" resourceName="memory" available="12056812Ki" capacity="16376164Ki" time="2024-10-09 09:46:02.956944611 +0000 UTC m=+100.162459107"
I1009 09:46:02.964029  106124 helpers.go:972] "Eviction manager:" log="observations" signal="nodefs.available" resourceName="ephemeral-storage" available="162422272Ki" capacity="202051056Ki" time="2024-10-09 09:46:02.956944611 +0000 UTC m=+100.162459107"
I1009 09:46:02.964034  106124 helpers.go:972] "Eviction manager:" log="observations" signal="imagefs.available" resourceName="ephemeral-storage" available="162422272Ki" capacity="202051056Ki" time="2024-10-09 09:46:02.097828984 +0000 UTC"
I1009 09:46:02.964038  106124 helpers.go:972] "Eviction manager:" log="observations" signal="imagefs.inodesFree" resourceName="inodes" available="24743251" capacity="26083328" time="2024-10-09 09:46:02.097828984 +0000 UTC"
I1009 09:46:02.964044  106124 helpers.go:972] "Eviction manager:" log="observations" signal="containerfs.inodesFree" resourceName="inodes" available="24743251" capacity="26083328" time="2024-10-09 09:46:02.097828984 +0000 UTC"
I1009 09:46:02.964061  106124 eviction_manager.go:359] "Eviction manager: no resources are starved"
I1009 09:46:03.094986  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:46:04.098496  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:46:04.495217  106124 manager.go:1037] Destroyed container: "/kubepods/burstable/podafd5e56f-a379-49e2-839a-186dcb64715c/08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5" (aliases: [08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5 /kubepods/burstable/podafd5e56f-a379-49e2-839a-186dcb64715c/08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5], namespace: "containerd")
I1009 09:46:04.495277  106124 handler.go:325] Added event &{/kubepods/burstable/podafd5e56f-a379-49e2-839a-186dcb64715c/08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5 2024-10-09 09:46:04.495269733 +0000 UTC m=+101.700784228 containerDeletion {<nil>}}
I1009 09:46:04.567761  106124 kuberuntime_container.go:817] "Container exited normally" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c" containerName="regular-1" containerID="containerd://08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5"
I1009 09:46:04.591266  106124 manager.go:1037] Destroyed container: "/kubepods/burstable/podafd5e56f-a379-49e2-839a-186dcb64715c/87c8ae07b7f2916ceb558e07dbf26071bedda92948368099046f4f5430169077" (aliases: [87c8ae07b7f2916ceb558e07dbf26071bedda92948368099046f4f5430169077 /kubepods/burstable/podafd5e56f-a379-49e2-839a-186dcb64715c/87c8ae07b7f2916ceb558e07dbf26071bedda92948368099046f4f5430169077], namespace: "containerd")
I1009 09:46:04.591323  106124 handler.go:325] Added event &{/kubepods/burstable/podafd5e56f-a379-49e2-839a-186dcb64715c/87c8ae07b7f2916ceb558e07dbf26071bedda92948368099046f4f5430169077 2024-10-09 09:46:04.591316295 +0000 UTC m=+101.796830790 containerDeletion {<nil>}}
I1009 09:46:04.669486  106124 interface.go:432] Looking for default routes with IPv4 addresses
I1009 09:46:04.669535  106124 interface.go:437] Default route transits interface "eth0"
I1009 09:46:04.669635  106124 interface.go:209] Interface eth0 is up
I1009 09:46:04.669708  106124 interface.go:257] Interface "eth0" has 3 addresses :[82.112.230.236/24 2a02:4780:12:eebf::1/48 fe80::be24:11ff:fe5a:b1d8/64].
I1009 09:46:04.669723  106124 interface.go:224] Checking addr  82.112.230.236/24.
I1009 09:46:04.669729  106124 interface.go:231] IP found 82.112.230.236
I1009 09:46:04.669734  106124 interface.go:263] Found valid IPv4 address 82.112.230.236 for interface "eth0".
I1009 09:46:04.669738  106124 interface.go:443] Found active IP 82.112.230.236 
I1009 09:46:04.695385  106124 kubelet.go:1767] "SyncPod exit" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c" isTerminal=false
I1009 09:46:04.695449  106124 pod_workers.go:1338] "Processing pod event done" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c" updateType="sync"
I1009 09:46:04.872163  106124 kubelet.go:2509] "SyncLoop (housekeeping)"
I1009 09:46:04.873528  106124 kubelet_pods.go:1151] "Clean up pod workers for terminated pods"
I1009 09:46:04.874615  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=false
I1009 09:46:04.874672  106124 kubelet_pods.go:1201] "Clean up probes for terminated pods"
I1009 09:46:04.874682  106124 kubelet_pods.go:1205] "Clean up orphaned pod statuses"
I1009 09:46:04.874691  106124 kubelet_pods.go:1209] "Clean up orphaned pod user namespace allocations"
I1009 09:46:04.874702  106124 kubelet_pods.go:1221] "Clean up orphaned pod directories"
I1009 09:46:04.874783  106124 kubelet_pods.go:1232] "Clean up orphaned mirror pods"
I1009 09:46:04.874820  106124 kubelet_pods.go:1374] "Clean up orphaned pod cgroups"
I1009 09:46:04.874834  106124 kubelet.go:2517] "SyncLoop (housekeeping) end" duration="3ms"
I1009 09:46:05.100014  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:46:05.100063  106124 generic.go:187] "GenericPLEG" podUID="afd5e56f-a379-49e2-839a-186dcb64715c" containerID="08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5" oldState="running" newState="exited"
I1009 09:46:05.100078  106124 generic.go:187] "GenericPLEG" podUID="afd5e56f-a379-49e2-839a-186dcb64715c" containerID="87c8ae07b7f2916ceb558e07dbf26071bedda92948368099046f4f5430169077" oldState="running" newState="exited"
I1009 09:46:05.100576  106124 kuberuntime_manager.go:1537] "getSandboxIDByPodUID got sandbox IDs for pod" podSandboxID=["87c8ae07b7f2916ceb558e07dbf26071bedda92948368099046f4f5430169077"] pod="prestop-hook-test-3521/test-pod"
I1009 09:46:05.102350  106124 generic.go:463] "PLEG: Write status" pod="prestop-hook-test-3521/test-pod"
I1009 09:46:05.102389  106124 generic.go:338] "Generic (PLEG): container finished" podID="afd5e56f-a379-49e2-839a-186dcb64715c" containerID="08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5" exitCode=0
I1009 09:46:05.102417  106124 kubelet.go:2442] "SyncLoop (PLEG): event for pod" pod="prestop-hook-test-3521/test-pod" event={"ID":"afd5e56f-a379-49e2-839a-186dcb64715c","Type":"ContainerDied","Data":"08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5"}
I1009 09:46:05.102434  106124 pod_workers.go:963] "Notifying pod of pending update" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c" workType="sync"
I1009 09:46:05.102487  106124 kubelet.go:2442] "SyncLoop (PLEG): event for pod" pod="prestop-hook-test-3521/test-pod" event={"ID":"afd5e56f-a379-49e2-839a-186dcb64715c","Type":"ContainerDied","Data":"87c8ae07b7f2916ceb558e07dbf26071bedda92948368099046f4f5430169077"}
I1009 09:46:05.102502  106124 pod_workers.go:963] "Notifying pod of pending update" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c" workType="sync"
I1009 09:46:05.102549  106124 pod_container_deletor.go:80] "Container not found in pod's containers" containerID="87c8ae07b7f2916ceb558e07dbf26071bedda92948368099046f4f5430169077"
I1009 09:46:05.102563  106124 pod_workers.go:1233] "Processing pod event" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c" updateType="sync"
I1009 09:46:05.102591  106124 kubelet.go:1761] "SyncPod enter" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c"
I1009 09:46:05.102598  106124 kubelet_pods.go:1774] "Generating pod status" podIsTerminal=false pod="prestop-hook-test-3521/test-pod"
I1009 09:46:05.102631  106124 helpers.go:95] "Already ran container, do nothing" pod="prestop-hook-test-3521/test-pod" containerName="regular-1"
I1009 09:46:05.102640  106124 kubelet_pods.go:1787] "Got phase for pod" pod="prestop-hook-test-3521/test-pod" oldPhase="Running" phase="Succeeded"
I1009 09:46:05.102656  106124 util.go:48] "No ready sandbox for pod can be found. Need to start a new one" pod="prestop-hook-test-3521/test-pod"
I1009 09:46:05.102689  106124 kubelet.go:1767] "SyncPod exit" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c" isTerminal=true
I1009 09:46:05.102694  106124 pod_workers.go:1328] "Pod is terminal" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c" updateType="sync"
I1009 09:46:05.102702  106124 pod_workers.go:1373] "Pod indicated lifecycle completed naturally and should now terminate" podUID="afd5e56f-a379-49e2-839a-186dcb64715c"
I1009 09:46:05.102713  106124 pod_workers.go:1513] "Pending update already queued" podUID="afd5e56f-a379-49e2-839a-186dcb64715c"
I1009 09:46:05.102722  106124 pod_workers.go:1338] "Processing pod event done" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c" updateType="sync"
I1009 09:46:05.102727  106124 pod_workers.go:1233] "Processing pod event" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c" updateType="terminating"
I1009 09:46:05.102736  106124 status_manager.go:227] "Syncing updated statuses"
I1009 09:46:05.111378  106124 config.go:292] "Setting pods for source" source="api"
I1009 09:46:05.111591  106124 kubelet.go:2423] "SyncLoop RECONCILE" source="api" pods=["prestop-hook-test-3521/test-pod"]
I1009 09:46:05.111696  106124 status_manager.go:872] "Patch status for pod" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c" patch="{\"metadata\":{\"uid\":\"afd5e56f-a379-49e2-839a-186dcb64715c\"},\"status\":{\"$setElementOrder/conditions\":[{\"type\":\"PodReadyToStartContainers\"},{\"type\":\"Initialized\"},{\"type\":\"Ready\"},{\"type\":\"ContainersReady\"},{\"type\":\"PodScheduled\"}],\"conditions\":[{\"lastTransitionTime\":\"2024-10-09T09:46:05Z\",\"status\":\"False\",\"type\":\"PodReadyToStartContainers\"},{\"reason\":\"PodCompleted\",\"type\":\"Initialized\"},{\"message\":null,\"reason\":\"PodCompleted\",\"type\":\"Ready\"},{\"message\":null,\"reason\":\"PodCompleted\",\"type\":\"ContainersReady\"}],\"containerStatuses\":[{\"containerID\":\"containerd://08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5\",\"image\":\"registry.k8s.io/e2e-test-images/busybox:1.36.1-1\",\"imageID\":\"registry.k8s.io/e2e-test-images/busybox@sha256:a9155b13325b2abef48e71de77bb8ac015412a566829f621d06bfae5c699b1b9\",\"lastState\":{},\"name\":\"regular-1\",\"ready\":false,\"restartCount\":0,\"started\":false,\"state\":{\"terminated\":{\"containerID\":\"containerd://08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5\",\"exitCode\":0,\"finishedAt\":\"2024-10-09T09:46:04Z\",\"reason\":\"Completed\",\"startedAt\":\"2024-10-09T09:44:24Z\"}},\"volumeMounts\":[{\"mountPath\":\"/persistent\",\"name\":\"persistent\"}]}]}}"
I1009 09:46:05.111726  106124 status_manager.go:881] "Status for pod updated successfully" pod="prestop-hook-test-3521/test-pod" statusVersion=3 status={"phase":"Running","conditions":[{"type":"PodReadyToStartContainers","status":"False","lastProbeTime":null,"lastTransitionTime":"2024-10-09T09:46:05Z"},{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-10-09T09:44:23Z","reason":"PodCompleted"},{"type":"Ready","status":"False","lastProbeTime":null,"lastTransitionTime":"2024-10-09T09:44:23Z","reason":"PodCompleted"},{"type":"ContainersReady","status":"False","lastProbeTime":null,"lastTransitionTime":"2024-10-09T09:44:23Z","reason":"PodCompleted"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-10-09T09:44:23Z"}],"hostIP":"82.112.230.236","hostIPs":[{"ip":"82.112.230.236"}],"podIP":"10.10.0.97","podIPs":[{"ip":"10.10.0.97"}],"startTime":"2024-10-09T09:44:23Z","containerStatuses":[{"name":"regular-1","state":{"terminated":{"exitCode":0,"reason":"Completed","startedAt":"2024-10-09T09:44:24Z","finishedAt":"2024-10-09T09:46:04Z","containerID":"containerd://08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5"}},"lastState":{},"ready":false,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/busybox:1.36.1-1","imageID":"registry.k8s.io/e2e-test-images/busybox@sha256:a9155b13325b2abef48e71de77bb8ac015412a566829f621d06bfae5c699b1b9","containerID":"containerd://08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5","started":false,"volumeMounts":[{"name":"persistent","mountPath":"/persistent"}]}],"qosClass":"Burstable"}
I1009 09:46:05.871676  106124 kubelet.go:2461] "SyncLoop (SYNC) pods" total=1 pods=["prestop-hook-test-3521/test-pod"]
I1009 09:46:05.871734  106124 pod_workers.go:963] "Notifying pod of pending update" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c" workType="terminating"
I1009 09:46:06.104263  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:46:06.104339  106124 kubelet.go:2009] "SyncTerminatingPod enter" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c"
I1009 09:46:06.104352  106124 kubelet_pods.go:1774] "Generating pod status" podIsTerminal=false pod="prestop-hook-test-3521/test-pod"
I1009 09:46:06.104384  106124 helpers.go:95] "Already ran container, do nothing" pod="prestop-hook-test-3521/test-pod" containerName="regular-1"
I1009 09:46:06.104393  106124 kubelet_pods.go:1787] "Got phase for pod" pod="prestop-hook-test-3521/test-pod" oldPhase="Succeeded" phase="Succeeded"
I1009 09:46:06.104422  106124 util.go:48] "No ready sandbox for pod can be found. Need to start a new one" pod="prestop-hook-test-3521/test-pod"
I1009 09:46:06.104529  106124 status_manager.go:691] "Ignoring same status for pod" pod="prestop-hook-test-3521/test-pod" status={"phase":"Succeeded","conditions":[{"type":"PodReadyToStartContainers","status":"False","lastProbeTime":null,"lastTransitionTime":"2024-10-09T09:46:05Z"},{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-10-09T09:44:23Z","reason":"PodCompleted"},{"type":"Ready","status":"False","lastProbeTime":null,"lastTransitionTime":"2024-10-09T09:44:23Z","reason":"PodCompleted"},{"type":"ContainersReady","status":"False","lastProbeTime":null,"lastTransitionTime":"2024-10-09T09:44:23Z","reason":"PodCompleted"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-10-09T09:44:23Z"}],"hostIP":"82.112.230.236","hostIPs":[{"ip":"82.112.230.236"}],"podIP":"10.10.0.97","podIPs":[{"ip":"10.10.0.97"}],"startTime":"2024-10-09T09:44:23Z","containerStatuses":[{"name":"regular-1","state":{"terminated":{"exitCode":0,"reason":"Completed","startedAt":"2024-10-09T09:44:24Z","finishedAt":"2024-10-09T09:46:04Z","containerID":"containerd://08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5"}},"lastState":{},"ready":false,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/busybox:1.36.1-1","imageID":"registry.k8s.io/e2e-test-images/busybox@sha256:a9155b13325b2abef48e71de77bb8ac015412a566829f621d06bfae5c699b1b9","containerID":"containerd://08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5","started":false,"volumeMounts":[{"name":"persistent","mountPath":"/persistent"}]}],"qosClass":"Burstable"}
I1009 09:46:06.104562  106124 kubelet.go:2021] "Pod terminating with grace period" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c" gracePeriod=null
I1009 09:46:06.115362  106124 qos_container_manager_linux.go:383] "Updated QoS cgroup configuration"
I1009 09:46:06.115953  106124 kuberuntime_manager.go:1537] "getSandboxIDByPodUID got sandbox IDs for pod" podSandboxID=["87c8ae07b7f2916ceb558e07dbf26071bedda92948368099046f4f5430169077"] pod="prestop-hook-test-3521/test-pod"
I1009 09:46:06.117705  106124 kubelet.go:2071] "Post-termination container state" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c" containers=[{"Name":"regular-1","State":"exited","ExitCode":0,"FinishedAt":"2024-10-09T09:46:04.480051971Z"}]
I1009 09:46:06.117886  106124 kubelet_pods.go:1774] "Generating pod status" podIsTerminal=true pod="prestop-hook-test-3521/test-pod"
I1009 09:46:06.117932  106124 helpers.go:95] "Already ran container, do nothing" pod="prestop-hook-test-3521/test-pod" containerName="regular-1"
I1009 09:46:06.117943  106124 kubelet_pods.go:1787] "Got phase for pod" pod="prestop-hook-test-3521/test-pod" oldPhase="Succeeded" phase="Succeeded"
I1009 09:46:06.117997  106124 util.go:48] "No ready sandbox for pod can be found. Need to start a new one" pod="prestop-hook-test-3521/test-pod"
I1009 09:46:06.118069  106124 status_manager.go:691] "Ignoring same status for pod" pod="prestop-hook-test-3521/test-pod" status={"phase":"Succeeded","conditions":[{"type":"PodReadyToStartContainers","status":"False","lastProbeTime":null,"lastTransitionTime":"2024-10-09T09:46:05Z"},{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-10-09T09:44:23Z","reason":"PodCompleted"},{"type":"Ready","status":"False","lastProbeTime":null,"lastTransitionTime":"2024-10-09T09:44:23Z","reason":"PodCompleted"},{"type":"ContainersReady","status":"False","lastProbeTime":null,"lastTransitionTime":"2024-10-09T09:44:23Z","reason":"PodCompleted"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-10-09T09:44:23Z"}],"hostIP":"82.112.230.236","hostIPs":[{"ip":"82.112.230.236"}],"podIP":"10.10.0.97","podIPs":[{"ip":"10.10.0.97"}],"startTime":"2024-10-09T09:44:23Z","containerStatuses":[{"name":"regular-1","state":{"terminated":{"exitCode":0,"reason":"Completed","startedAt":"2024-10-09T09:44:24Z","finishedAt":"2024-10-09T09:46:04Z","containerID":"containerd://08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5"}},"lastState":{},"ready":false,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/busybox:1.36.1-1","imageID":"registry.k8s.io/e2e-test-images/busybox@sha256:a9155b13325b2abef48e71de77bb8ac015412a566829f621d06bfae5c699b1b9","containerID":"containerd://08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5","started":false,"volumeMounts":[{"name":"persistent","mountPath":"/persistent"}]}],"qosClass":"Burstable"}
I1009 09:46:06.118104  106124 kubelet.go:2094] "Pod termination stopped all running containers" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c"
I1009 09:46:06.118119  106124 kubelet.go:2096] "SyncTerminatingPod exit" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c"
I1009 09:46:06.118131  106124 pod_workers.go:1402] "Pod terminated all containers successfully" podUID="afd5e56f-a379-49e2-839a-186dcb64715c"
I1009 09:46:06.118143  106124 pod_workers.go:1513] "Pending update already queued" podUID="afd5e56f-a379-49e2-839a-186dcb64715c"
I1009 09:46:06.118151  106124 pod_workers.go:1338] "Processing pod event done" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c" updateType="terminating"
I1009 09:46:06.118161  106124 pod_workers.go:1233] "Processing pod event" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c" updateType="terminated"
I1009 09:46:06.167991  106124 desired_state_of_world_populator.go:254] "Removing volume from desired state" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c" volumeName="persistent"
I1009 09:46:06.268503  106124 reconciler_common.go:162] "operationExecutor.UnmountVolume started for volume \"persistent\" (UniqueName: \"kubernetes.io/empty-dir/afd5e56f-a379-49e2-839a-186dcb64715c-persistent\") pod \"afd5e56f-a379-49e2-839a-186dcb64715c\" (UID: \"afd5e56f-a379-49e2-839a-186dcb64715c\") "
I1009 09:46:06.268555  106124 subpath_linux.go:244] Cleaning up subpath mounts for /var/lib/kubelet/pods/afd5e56f-a379-49e2-839a-186dcb64715c/volume-subpaths/persistent
I1009 09:46:06.268815  106124 empty_dir_linux.go:99] Statfs_t of /var/lib/kubelet/pods/afd5e56f-a379-49e2-839a-186dcb64715c/volumes/kubernetes.io~empty-dir/persistent: {Type:61267 Bsize:4096 Blocks:50512764 Bfree:40609662 Bavail:40605566 Files:26083328 Ffree:24743258 Fsid:{Val:[-1066910170 637433747]} Namelen:255 Frsize:4096 Flags:4128 Spare:[0 0 0 0]}
I1009 09:46:06.268973  106124 operation_generator.go:803] UnmountVolume.TearDown succeeded for volume "kubernetes.io/empty-dir/afd5e56f-a379-49e2-839a-186dcb64715c-persistent" (OuterVolumeSpecName: "persistent") pod "afd5e56f-a379-49e2-839a-186dcb64715c" (UID: "afd5e56f-a379-49e2-839a-186dcb64715c"). InnerVolumeSpecName "persistent". PluginName "kubernetes.io/empty-dir", VolumeGidValue ""
I1009 09:46:06.369603  106124 reconciler_common.go:294] "Volume detached for volume \"persistent\" (UniqueName: \"kubernetes.io/empty-dir/afd5e56f-a379-49e2-839a-186dcb64715c-persistent\") on node \"srv579909\" DevicePath \"\""
I1009 09:46:06.871622  106124 kubelet.go:2461] "SyncLoop (SYNC) pods" total=1 pods=["prestop-hook-test-3521/test-pod"]
I1009 09:46:06.871685  106124 pod_workers.go:963] "Notifying pod of pending update" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c" workType="terminated"
I1009 09:46:06.871715  106124 kubelet.go:2509] "SyncLoop (housekeeping)"
I1009 09:46:06.872954  106124 kubelet_pods.go:1151] "Clean up pod workers for terminated pods"
I1009 09:46:06.874114  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=false
I1009 09:46:06.874162  106124 kubelet_pods.go:1201] "Clean up probes for terminated pods"
I1009 09:46:06.874168  106124 kubelet_pods.go:1205] "Clean up orphaned pod statuses"
I1009 09:46:06.874176  106124 kubelet_pods.go:1209] "Clean up orphaned pod user namespace allocations"
I1009 09:46:06.874184  106124 kubelet_pods.go:1221] "Clean up orphaned pod directories"
I1009 09:46:06.874253  106124 kubelet_pods.go:1232] "Clean up orphaned mirror pods"
I1009 09:46:06.874286  106124 kubelet_pods.go:1374] "Clean up orphaned pod cgroups"
I1009 09:46:06.874352  106124 kubelet_pods.go:2480] "Orphaned pod found, removing pod cgroups" podUID="afd5e56f-a379-49e2-839a-186dcb64715c"
I1009 09:46:06.874379  106124 kubelet.go:2517] "SyncLoop (housekeeping) end" duration="3ms"
I1009 09:46:06.879155  106124 manager.go:1037] Destroyed container: "/kubepods/burstable/podafd5e56f-a379-49e2-839a-186dcb64715c" (aliases: [], namespace: "")
I1009 09:46:06.879185  106124 handler.go:325] Added event &{/kubepods/burstable/podafd5e56f-a379-49e2-839a-186dcb64715c 2024-10-09 09:46:06.879179477 +0000 UTC m=+104.084693972 containerDeletion {<nil>}}
I1009 09:46:07.106447  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:46:07.106600  106124 kubelet.go:2154] "SyncTerminatedPod enter" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c"
I1009 09:46:07.106618  106124 kubelet_pods.go:1774] "Generating pod status" podIsTerminal=true pod="prestop-hook-test-3521/test-pod"
I1009 09:46:07.106654  106124 helpers.go:95] "Already ran container, do nothing" pod="prestop-hook-test-3521/test-pod" containerName="regular-1"
I1009 09:46:07.106668  106124 kubelet_pods.go:1787] "Got phase for pod" pod="prestop-hook-test-3521/test-pod" oldPhase="Succeeded" phase="Succeeded"
I1009 09:46:07.106692  106124 util.go:48] "No ready sandbox for pod can be found. Need to start a new one" pod="prestop-hook-test-3521/test-pod"
I1009 09:46:07.106759  106124 status_manager.go:691] "Ignoring same status for pod" pod="prestop-hook-test-3521/test-pod" status={"phase":"Succeeded","conditions":[{"type":"PodReadyToStartContainers","status":"False","lastProbeTime":null,"lastTransitionTime":"2024-10-09T09:46:05Z"},{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-10-09T09:44:23Z","reason":"PodCompleted"},{"type":"Ready","status":"False","lastProbeTime":null,"lastTransitionTime":"2024-10-09T09:44:23Z","reason":"PodCompleted"},{"type":"ContainersReady","status":"False","lastProbeTime":null,"lastTransitionTime":"2024-10-09T09:44:23Z","reason":"PodCompleted"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-10-09T09:44:23Z"}],"hostIP":"82.112.230.236","hostIPs":[{"ip":"82.112.230.236"}],"podIP":"10.10.0.97","podIPs":[{"ip":"10.10.0.97"}],"startTime":"2024-10-09T09:44:23Z","containerStatuses":[{"name":"regular-1","state":{"terminated":{"exitCode":0,"reason":"Completed","startedAt":"2024-10-09T09:44:24Z","finishedAt":"2024-10-09T09:46:04Z","containerID":"containerd://08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5"}},"lastState":{},"ready":false,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/busybox:1.36.1-1","imageID":"registry.k8s.io/e2e-test-images/busybox@sha256:a9155b13325b2abef48e71de77bb8ac015412a566829f621d06bfae5c699b1b9","containerID":"containerd://08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5","started":false,"volumeMounts":[{"name":"persistent","mountPath":"/persistent"}]}],"qosClass":"Burstable"}
I1009 09:46:07.106842  106124 volume_manager.go:449] "Waiting for volumes to unmount for pod" pod="prestop-hook-test-3521/test-pod"
I1009 09:46:07.106861  106124 volume_manager.go:477] "All volumes are unmounted for pod" pod="prestop-hook-test-3521/test-pod"
I1009 09:46:07.106868  106124 kubelet.go:2168] "Pod termination unmounted volumes" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c"
I1009 09:46:07.106960  106124 kubelet.go:2181] "Pod termination cleaned up volume paths" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c"
I1009 09:46:07.107049  106124 kubelet.go:2202] "Pod termination removed cgroups" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c"
I1009 09:46:07.107086  106124 kubelet.go:2209] "Pod is terminated and will need no more status updates" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c"
I1009 09:46:07.107093  106124 kubelet.go:2211] "SyncTerminatedPod exit" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c"
I1009 09:46:07.107099  106124 pod_workers.go:1463] "Pod is complete and the worker can now stop" podUID="afd5e56f-a379-49e2-839a-186dcb64715c"
I1009 09:46:07.107115  106124 pod_workers.go:1309] "Processing pod event done" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c" updateType="terminated"
I1009 09:46:07.107123  106124 pod_workers.go:951] "Pod worker has stopped" podUID="afd5e56f-a379-49e2-839a-186dcb64715c"
I1009 09:46:07.107136  106124 status_manager.go:227] "Syncing updated statuses"
I1009 09:46:07.114257  106124 config.go:292] "Setting pods for source" source="api"
I1009 09:46:07.114365  106124 kubelet.go:2423] "SyncLoop RECONCILE" source="api" pods=["prestop-hook-test-3521/test-pod"]
I1009 09:46:07.114383  106124 status_manager.go:872] "Patch status for pod" pod="prestop-hook-test-3521/test-pod" podUID="afd5e56f-a379-49e2-839a-186dcb64715c" patch="{\"metadata\":{\"uid\":\"afd5e56f-a379-49e2-839a-186dcb64715c\"},\"status\":{\"phase\":\"Succeeded\"}}"
I1009 09:46:07.114403  106124 status_manager.go:881] "Status for pod updated successfully" pod="prestop-hook-test-3521/test-pod" statusVersion=4 status={"phase":"Succeeded","conditions":[{"type":"PodReadyToStartContainers","status":"False","lastProbeTime":null,"lastTransitionTime":"2024-10-09T09:46:05Z"},{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-10-09T09:44:23Z","reason":"PodCompleted"},{"type":"Ready","status":"False","lastProbeTime":null,"lastTransitionTime":"2024-10-09T09:44:23Z","reason":"PodCompleted"},{"type":"ContainersReady","status":"False","lastProbeTime":null,"lastTransitionTime":"2024-10-09T09:44:23Z","reason":"PodCompleted"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-10-09T09:44:23Z"}],"hostIP":"82.112.230.236","hostIPs":[{"ip":"82.112.230.236"}],"podIP":"10.10.0.97","podIPs":[{"ip":"10.10.0.97"}],"startTime":"2024-10-09T09:44:23Z","containerStatuses":[{"name":"regular-1","state":{"terminated":{"exitCode":0,"reason":"Completed","startedAt":"2024-10-09T09:44:24Z","finishedAt":"2024-10-09T09:46:04Z","containerID":"containerd://08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5"}},"lastState":{},"ready":false,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/busybox:1.36.1-1","imageID":"registry.k8s.io/e2e-test-images/busybox@sha256:a9155b13325b2abef48e71de77bb8ac015412a566829f621d06bfae5c699b1b9","containerID":"containerd://08ad572f2e76e2c0a8838e5039d5d47a24769ae1ca481392dcc6c02a6a60bbd5","started":false,"volumeMounts":[{"name":"persistent","mountPath":"/persistent"}]}],"qosClass":"Burstable"}
I1009 09:46:07.910651  106124 kubelet.go:2898] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:; Handlers: , Features: nil"
I1009 09:46:08.108218  106124 kuberuntime_manager.go:432] "Retrieved pods from runtime" all=true
I1009 09:46:08.174566  106124 log.go:25] "Finished parsing log file" path="/var/log/pods/prestop-hook-test-3521_test-pod_afd5e56f-a379-49e2-839a-186dcb64715c/regular-1/0.log"
I1009 09:46:08.174618  106124 httplog.go:134] "HTTP" verb="GET" URI="/containerLogs/prestop-hook-test-3521/test-pod/regular-1" latency="1.53488ms" userAgent="Go-http-client/2.0" audit-ID="" srcIP="82.112.230.236:41964" resp=200
I1009 09:46:08.282935  106124 streamwatcher.go:111] Unexpected EOF during watch stream event decoding: unexpected EOF
I1009 09:46:08.282964  106124 streamwatcher.go:111] Unexpected EOF during watch stream event decoding: unexpected EOF
I1009 09:46:08.282937  106124 streamwatcher.go:111] Unexpected EOF during watch stream event decoding: unexpected EOF
I1009 09:46:08.283012  106124 reflector.go:871] k8s.io/client-go/informers/factory.go:160: Watch close - *v1.Node total 3 items received
I1009 09:46:08.283028  106124 reflector.go:871] pkg/kubelet/config/apiserver.go:66: Watch close - *v1.Pod total 6 items received
I1009 09:46:08.282951  106124 streamwatcher.go:111] Unexpected EOF during watch stream event decoding: unexpected EOF
I1009 09:46:08.283064  106124 reflector.go:871] k8s.io/client-go/informers/factory.go:160: Watch close - *v1.CSIDriver total 0 items received
I1009 09:46:08.282952  106124 streamwatcher.go:111] Unexpected EOF during watch stream event decoding: unexpected EOF
I1009 09:46:08.283186  106124 reflector.go:871] k8s.io/client-go/informers/factory.go:160: Watch close - *v1.RuntimeClass total 0 items received
I1009 09:46:08.282992  106124 reflector.go:871] k8s.io/client-go/informers/factory.go:160: Watch close - *v1.Service total 0 items received
